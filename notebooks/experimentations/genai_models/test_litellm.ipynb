{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4e67ef-738a-44f6-8f69-5df41ec65b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:49.507593Z",
     "iopub.status.busy": "2025-03-27T21:42:49.506447Z",
     "iopub.status.idle": "2025-03-27T21:42:49.517731Z",
     "shell.execute_reply": "2025-03-27T21:42:49.516091Z",
     "shell.execute_reply.started": "2025-03-27T21:42:49.507547Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s -- l.%(lineno)d: %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c913b6-9110-4fb0-a6b8-2f67bcfb92e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:50.057571Z",
     "iopub.status.busy": "2025-03-27T21:42:50.057279Z",
     "iopub.status.idle": "2025-03-27T21:42:50.068621Z",
     "shell.execute_reply": "2025-03-27T21:42:50.065330Z",
     "shell.execute_reply.started": "2025-03-27T21:42:50.057548Z"
    }
   },
   "outputs": [],
   "source": [
    "#system_prompt = \"You are a university-level physics professor teaching a graduate course in Physics.\"\n",
    "system_prompt = \"You are kindergarden teacher who introduces elementary physics concetps to a group of 5 year old in a language that they can understand.\"\n",
    "prompt = \"Explain nuclear fusion in 5 sentences or less.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225dea5-4737-4132-b26b-1ab60dd7141c",
   "metadata": {},
   "source": [
    "# Test GenAIModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac35b947-3a68-44e6-9a6d-a596cbb144c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:50.765170Z",
     "iopub.status.busy": "2025-03-27T21:42:50.764831Z",
     "iopub.status.idle": "2025-03-27T21:42:52.973920Z",
     "shell.execute_reply": "2025-03-27T21:42:52.972924Z",
     "shell.execute_reply.started": "2025-03-27T21:42:50.765149Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.genai_model.genai_model import GenAIModel\n",
    "from src.utils.list import flatten_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfff21ec-a912-433b-8d00-c096ee201ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:52.975435Z",
     "iopub.status.busy": "2025-03-27T21:42:52.975168Z",
     "iopub.status.idle": "2025-03-27T21:42:52.985263Z",
     "shell.execute_reply": "2025-03-27T21:42:52.983108Z",
     "shell.execute_reply.started": "2025-03-27T21:42:52.975416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp:free',\n",
       " 'gemini/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp-1219:free',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'openrouter/google/gemini-2.0-flash-exp:free']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = GenAIModel(model_type=\"gemini-2.0\", system_promt=system_prompt)\n",
    "_model.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63103a8f-7179-438e-bc59-5577a619846b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:52.987372Z",
     "iopub.status.busy": "2025-03-27T21:42:52.987067Z",
     "iopub.status.idle": "2025-03-27T21:42:53.002255Z",
     "shell.execute_reply": "2025-03-27T21:42:52.999208Z",
     "shell.execute_reply.started": "2025-03-27T21:42:52.987351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-exp-1206',\n",
       " 'openrouter/google/gemini-exp-1206:free',\n",
       " 'gemini/gemini-exp-1121',\n",
       " 'openrouter/google/gemini-exp-1121:free',\n",
       " 'gemini/gemini-exp-1114',\n",
       " 'openrouter/google/gemini-exp-1114:free',\n",
       " 'gemini/gemini-1.5-pro-002',\n",
       " 'gemini/gemini-1.5-pro-exp-0827',\n",
       " 'openrouter/meta-llama/llama-3.1-405b-instruct:free',\n",
       " 'gemini/gemini-1.5-pro-001',\n",
       " 'mistral/mistral-large-2411',\n",
       " 'mistral/mistral-large-2407',\n",
       " 'mistral/mistral-large-2402']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large = GenAIModel(model_type=\"large\", system_promt=system_prompt)\n",
    "model_large.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b8cd4e8-7dbc-4c66-bad8-b8614cdf1de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:53.005263Z",
     "iopub.status.busy": "2025-03-27T21:42:53.004892Z",
     "iopub.status.idle": "2025-03-27T21:42:59.037642Z",
     "shell.execute_reply": "2025-03-27T21:42:59.035062Z",
     "shell.execute_reply.started": "2025-03-27T21:42:53.005236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-56298c6a-e67f-469b-b6e3-94b214b14fc6', created=1743111773, model='gemini-exp-1206', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Okay class, listen up!\\n\\nImagine you have two tiny, tiny LEGO bricks. If you push them together *really, really* hard, so hard they smoosh into one bigger brick! When they smoosh together like that, POP! They make lots and lots of energy, like sunshine. That's kind of like how our big Sun makes its light and heat way up high. It's like a super-duper powerful smoosh happening all the time!\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=96, prompt_tokens=39, total_tokens=135, completion_tokens_details=None, prompt_tokens_details=None), vertex_ai_grounding_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large.completion(user_prompt=prompt, parameters={\"temperature\": 0.5, \"top_p\": 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710aa8-94c8-4f26-b71c-af2d8f71c755",
   "metadata": {},
   "source": [
    "# Test LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79bda238-758d-4ad8-9c82-12ff0cd5300d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:59.039325Z",
     "iopub.status.busy": "2025-03-27T21:42:59.039008Z",
     "iopub.status.idle": "2025-03-27T21:42:59.045387Z",
     "shell.execute_reply": "2025-03-27T21:42:59.043088Z",
     "shell.execute_reply.started": "2025-03-27T21:42:59.039270Z"
    }
   },
   "outputs": [],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbb2b57-06d0-4f17-b287-516d232a6a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:59.046456Z",
     "iopub.status.busy": "2025-03-27T21:42:59.046221Z",
     "iopub.status.idle": "2025-03-27T21:42:59.054086Z",
     "shell.execute_reply": "2025-03-27T21:42:59.052505Z",
     "shell.execute_reply.started": "2025-03-27T21:42:59.046436Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_models = {\n",
    "    \"Gemini\": \"gemini/gemini-1.5-pro-002\",\n",
    "    \"OpenRouter\": \"openrouter/meta-llama/llama-3.1-405b-instruct:free\",\n",
    "    \"Mistral\": \"mistral/mistral-large-2411\",\n",
    "    \"Groq\": \"groq/llama3-70b-8192\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cd3b494-33f0-4076-b57e-6a0ca957b30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:42:59.056656Z",
     "iopub.status.busy": "2025-03-27T21:42:59.056390Z",
     "iopub.status.idle": "2025-03-27T21:43:01.628483Z",
     "shell.execute_reply": "2025-03-27T21:43:01.626868Z",
     "shell.execute_reply.started": "2025-03-27T21:42:59.056634Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Using model gemini/gemini-1.5-pro-002 from Gemini:\n",
      "\n",
      "Imagine tiny bouncing balls, smaller than you can even see!  Sometimes, two of these balls zoom together *really* fast and stick, making a bigger ball.  When they stick, they get a little bit hotter and give off some sparkle.  The sun does this with its tiny balls, making light and heat for us!  It's like a big, sparkly hug!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"temperature\": 0.5}\n",
    "\n",
    "for provider, model in list_of_models.items():\n",
    "    print(\"=\"*25)\n",
    "    print(f\"Using model {model} from {provider}:\\n\")\n",
    "    try:\n",
    "        response_l = completion(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            **parameters\n",
    "        )\n",
    "        print(response_l['choices'][0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"The model failed, raising the following exception: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bba9c2-dab7-4830-82fd-1fc7658c252b",
   "metadata": {},
   "source": [
    "# Test fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b68ad5f-68c7-446a-bc2e-e9d2da8f78f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:01.630061Z",
     "iopub.status.busy": "2025-03-27T21:43:01.629659Z",
     "iopub.status.idle": "2025-03-27T21:43:02.740046Z",
     "shell.execute_reply": "2025-03-27T21:43:02.739005Z",
     "shell.execute_reply.started": "2025-03-27T21:43:01.630037Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 17:43:02,719 - asyncio - ERROR -- l.1785: Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-9' coro=<Logging.async_success_handler() running at /usr/local/lib/python3.11/site-packages/litellm/litellm_core_utils/litellm_logging.py:1515>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OH BOY, let's talk about STARS!\n",
      "\n",
      "You know how we need to combine blocks to make a big tower? Well, inside stars, tiny things called atoms combine to make even more energy! It's like a super powerful hug that makes the star super bright and hot! This special hug is called nuclear fusion. And that's why stars shine so brightly in the sky!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/asyncio/base_events.py:679: RuntimeWarning: coroutine 'Logging.async_success_handler' was never awaited\n",
      "  self._ready.clear()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "ll_models = list(list_of_models.values())\n",
    "response_l = completion(\n",
    "    model=ll_models[-1],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    fallbacks=ll_models[:-1],\n",
    ")\n",
    "print(response_l['choices'][0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11cce687-be34-441d-945f-18b593c3b32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:02.741225Z",
     "iopub.status.busy": "2025-03-27T21:43:02.740976Z",
     "iopub.status.idle": "2025-03-27T21:43:02.750883Z",
     "shell.execute_reply": "2025-03-27T21:43:02.749766Z",
     "shell.execute_reply.started": "2025-03-27T21:43:02.741207Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-d2440e83-e703-43d7-8331-0c78729f7c9f', created=1743111782, model='groq/llama3-70b-8192', object='chat.completion', system_fingerprint='fp_2e0feca3c9', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"OH BOY, let's talk about STARS!\\n\\nYou know how we need to combine blocks to make a big tower? Well, inside stars, tiny things called atoms combine to make even more energy! It's like a super powerful hug that makes the star super bright and hot! This special hug is called nuclear fusion. And that's why stars shine so brightly in the sky!\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=78, prompt_tokens=55, total_tokens=133, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.20339941, prompt_time=0.00136738, completion_time=0.315697004, total_time=0.317064384), x_groq={'id': 'req_01jqcrxzrhf8na6fg7c86mhknv'})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6da1891d-599d-4c80-be8b-b7b730385406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:02.752216Z",
     "iopub.status.busy": "2025-03-27T21:43:02.751801Z",
     "iopub.status.idle": "2025-03-27T21:43:02.763340Z",
     "shell.execute_reply": "2025-03-27T21:43:02.760692Z",
     "shell.execute_reply.started": "2025-03-27T21:43:02.752192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'groq/llama3-70b-8192'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21dba7-d218-4131-a014-49892a9af702",
   "metadata": {},
   "source": [
    "# Compare Gemini and Groq models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95993511-577f-4132-abda-1a21be446986",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e8545f-28c4-4e8c-a009-1476b7e480c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:02.767735Z",
     "iopub.status.busy": "2025-03-27T21:43:02.767365Z",
     "iopub.status.idle": "2025-03-27T21:43:03.661537Z",
     "shell.execute_reply": "2025-03-27T21:43:03.659999Z",
     "shell.execute_reply.started": "2025-03-27T21:43:02.767708Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b96bfb0-a3f4-447e-a5d9-c7b75ab23f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:03.663360Z",
     "iopub.status.busy": "2025-03-27T21:43:03.662580Z",
     "iopub.status.idle": "2025-03-27T21:43:03.671565Z",
     "shell.execute_reply": "2025-03-27T21:43:03.668463Z",
     "shell.execute_reply.started": "2025-03-27T21:43:03.663336Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gemini-1.5-flash\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2be53e0a-e5b4-414d-beb7-b94bb9ee0078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:03.675480Z",
     "iopub.status.busy": "2025-03-27T21:43:03.674017Z",
     "iopub.status.idle": "2025-03-27T21:43:04.665337Z",
     "shell.execute_reply": "2025-03-27T21:43:04.664514Z",
     "shell.execute_reply.started": "2025-03-27T21:43:03.675447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e492321-bf28-46a9-9297-2db44bded706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:04.666334Z",
     "iopub.status.busy": "2025-03-27T21:43:04.666124Z",
     "iopub.status.idle": "2025-03-27T21:43:05.423820Z",
     "shell.execute_reply": "2025-03-27T21:43:05.422953Z",
     "shell.execute_reply.started": "2025-03-27T21:43:04.666317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  with the goal of benefiting humanity.  Their work spans various AI fields, including natural language processing, computer vision, and reinforcement learning.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/gemini\n",
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ea8bc-dc58-4fcb-af05-0960f696b203",
   "metadata": {},
   "source": [
    "### Check reproducibility in the case temperature=0.0 and top_p < 1.0\n",
    "In the case top_p = 1.0, I would still get some stochasticity, probably since temperature=0.0 is approximated algorithmically (using eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d2e76f-6035-4fee-a34d-4d02035f93e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:05.424997Z",
     "iopub.status.busy": "2025-03-27T21:43:05.424680Z",
     "iopub.status.idle": "2025-03-27T21:43:06.202129Z",
     "shell.execute_reply": "2025-03-27T21:43:06.200704Z",
     "shell.execute_reply.started": "2025-03-27T21:43:05.424975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c79a17-1e4a-45df-a65f-599da71c07b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:06.203047Z",
     "iopub.status.busy": "2025-03-27T21:43:06.202790Z",
     "iopub.status.idle": "2025-03-27T21:43:07.024373Z",
     "shell.execute_reply": "2025-03-27T21:43:07.022655Z",
     "shell.execute_reply.started": "2025-03-27T21:43:06.203029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b7272d8-7d12-47f5-bc70-3bfc698766a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:07.028621Z",
     "iopub.status.busy": "2025-03-27T21:43:07.026915Z",
     "iopub.status.idle": "2025-03-27T21:43:07.946101Z",
     "shell.execute_reply": "2025-03-27T21:43:07.945060Z",
     "shell.execute_reply.started": "2025-03-27T21:43:07.028591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a329a4-ae1f-4b97-8987-2712976bafb6",
   "metadata": {},
   "source": [
    "## Compare Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47305b29-b45e-4181-b9b4-9581b878a088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:07.947147Z",
     "iopub.status.busy": "2025-03-27T21:43:07.946721Z",
     "iopub.status.idle": "2025-03-27T21:43:07.954249Z",
     "shell.execute_reply": "2025-03-27T21:43:07.951231Z",
     "shell.execute_reply.started": "2025-03-27T21:43:07.947083Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a035767f-fe04-4414-8b5e-9933d86287f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:07.956590Z",
     "iopub.status.busy": "2025-03-27T21:43:07.955964Z",
     "iopub.status.idle": "2025-03-27T21:43:08.791864Z",
     "shell.execute_reply": "2025-03-27T21:43:08.790437Z",
     "shell.execute_reply.started": "2025-03-27T21:43:07.956557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI is a leading artificial intelligence research organization that focuses on developing and promoting AI technologies that benefit humanity. Founded in 2015, OpenAI aims to create advanced AI systems that can learn, reason, and interact with humans in a safe and transparent manner. The organization is known for its development of various AI models, including language models like GPT, which can generate human-like text and converse with users in a natural way. OpenAI's mission is to ensure that the benefits of AI are shared by all people, and to prioritize the development of AI systems that are aligned with human values.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "    model=model_name,\n",
    "    **param\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f18051be-6b7c-4d85-b11d-4b08fc78715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-27T21:43:08.793575Z",
     "iopub.status.busy": "2025-03-27T21:43:08.793249Z",
     "iopub.status.idle": "2025-03-27T21:43:09.608297Z",
     "shell.execute_reply": "2025-03-27T21:43:09.607468Z",
     "shell.execute_reply.started": "2025-03-27T21:43:08.793549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"OpenAI is a leading artificial intelligence research organization that focuses on developing and promoting AI technologies that benefit humanity. Founded in 2015, OpenAI aims to create advanced AI systems that can learn, reason, and interact with humans in a safe and transparent manner. The organization is known for its development of various AI models, including language models like GPT, which can generate human-like text and converse with users in a natural way. OpenAI's mission is to ensure that the benefits of AI are shared by all people, and to prioritize the development of AI systems that are aligned with human values.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/groq\n",
    "response_l = completion(\n",
    "    model=f\"groq/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618955e-48ae-4f7c-8900-ca6d65fc79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87a7bf-e71d-43bb-bf78-1778ece36acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
