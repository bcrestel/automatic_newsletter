{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "083c77e8-4cef-4d45-8045-1829c042a493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:27.197797Z",
     "iopub.status.busy": "2025-02-05T04:41:27.197127Z",
     "iopub.status.idle": "2025-02-05T04:41:27.212499Z",
     "shell.execute_reply": "2025-02-05T04:41:27.210488Z",
     "shell.execute_reply.started": "2025-02-05T04:41:27.197766Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s -- l.%(lineno)d: %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f3ae490-c156-4fc4-889b-81b3ac40f6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:27.214801Z",
     "iopub.status.busy": "2025-02-05T04:41:27.214435Z",
     "iopub.status.idle": "2025-02-05T04:41:32.835775Z",
     "shell.execute_reply": "2025-02-05T04:41:32.834822Z",
     "shell.execute_reply.started": "2025-02-05T04:41:27.214777Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:41:31,812 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='raw.githubusercontent.com' port=443 local_address=None timeout=5 socket_options=None\n",
      "2025-02-04 23:41:31,838 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011eb19cd0>\n",
      "2025-02-04 23:41:31,840 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f011eb868d0> server_hostname='raw.githubusercontent.com' timeout=5\n",
      "2025-02-04 23:41:31,864 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011e7b1850>\n",
      "2025-02-04 23:41:31,865 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'GET']>\n",
      "2025-02-04 23:41:31,867 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:41:31,868 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'GET']>\n",
      "2025-02-04 23:41:31,868 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:41:31,869 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'GET']>\n",
      "2025-02-04 23:41:31,884 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Connection', b'keep-alive'), (b'Content-Length', b'15642'), (b'Cache-Control', b'max-age=300'), (b'Content-Security-Policy', b\"default-src 'none'; style-src 'unsafe-inline'; sandbox\"), (b'Content-Type', b'text/plain; charset=utf-8'), (b'ETag', b'W/\"82c7fbfeca854c87d7df143f84015bf144cd1595b96f6770159e9be6cfd56034\"'), (b'Strict-Transport-Security', b'max-age=31536000'), (b'X-Content-Type-Options', b'nosniff'), (b'X-Frame-Options', b'deny'), (b'X-XSS-Protection', b'1; mode=block'), (b'X-GitHub-Request-Id', b'7F77:13426:41F60D:49AB1E:67A2E012'), (b'Content-Encoding', b'gzip'), (b'Accept-Ranges', b'bytes'), (b'Date', b'Wed, 05 Feb 2025 04:41:31 GMT'), (b'Via', b'1.1 varnish'), (b'X-Served-By', b'cache-yul1970070-YUL'), (b'X-Cache', b'HIT'), (b'X-Cache-Hits', b'3'), (b'X-Timer', b'S1738730492.948801,VS0,VE0'), (b'Vary', b'Authorization,Accept-Encoding,Origin'), (b'Access-Control-Allow-Origin', b'*'), (b'Cross-Origin-Resource-Policy', b'cross-origin'), (b'X-Fastly-Request-ID', b'c6669a29bce8914be3d6ab11f20d487ba0ae666d'), (b'Expires', b'Wed, 05 Feb 2025 04:46:31 GMT'), (b'Source-Age', b'291')])\n",
      "2025-02-04 23:41:31,887 - httpx - INFO -- l.1027: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:41:31,888 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'GET']>\n",
      "2025-02-04 23:41:31,892 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:41:31,893 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:41:31,894 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "2025-02-04 23:41:31,896 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:41:31,901 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:41:32 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:99 - [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm.proxy.enterprise'\n",
      "2025-02-04 23:41:32,597 - LiteLLM - DEBUG -- l.99: [Non-Blocking] Unable to import GenericAPILogger - LiteLLM Enterprise Feature - No module named 'litellm.proxy.enterprise'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.newsletters.main import runner as runner_newsletters\n",
    "from src.scoring.main import runner as runner_scoring\n",
    "from src.saving.main import runner as runner_saving\n",
    "from src.reporting.main import runner as runner_reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d09ad-1a60-4df2-9a1f-3d7a9f31d746",
   "metadata": {},
   "source": [
    "# Newsletters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "056d06c7-0d24-43bc-aef6-238f57aa2875",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:32.840627Z",
     "iopub.status.busy": "2025-02-05T04:41:32.840258Z",
     "iopub.status.idle": "2025-02-05T04:41:41.293719Z",
     "shell.execute_reply": "2025-02-05T04:41:41.293089Z",
     "shell.execute_reply.started": "2025-02-05T04:41:32.840603Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:41:32,847 - googleapiclient.discovery_cache - INFO -- l.49: file_cache is only supported with oauth2client<4.0.0\n",
      "2025-02-04 23:41:32,852 - src.newsletters.main - INFO -- l.31: Query emails\n",
      "2025-02-04 23:41:32,853 - src.gmail - DEBUG -- l.44: Fetch email for sender TLDR AI <dan@tldrnewsletter.com> from 2024-11-29 until 2024-12-02.\n",
      "2025-02-04 23:41:32,857 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages?q=after%3A1732856400+before%3A1733201999+from%3ATLDR+AI+%3Cdan%40tldrnewsletter.com%3E&alt=json\n",
      "2025-02-04 23:41:32,858 - google_auth_httplib2 - DEBUG -- l.118: Making request: POST https://oauth2.googleapis.com/token\n",
      "2025-02-04 23:41:33,317 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/19387c6f6bdf98de?alt=json\n",
      "2025-02-04 23:41:33,448 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/193871f73323b0e6?alt=json\n",
      "2025-02-04 23:41:33,556 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/19378480b1d8b929?alt=json\n",
      "2025-02-04 23:41:33,681 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/19377ae6d00bdb0c?alt=json\n",
      "2025-02-04 23:41:33,782 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/1937799e4ca5f9fc?alt=json\n",
      "2025-02-04 23:41:33,881 - src.newsletters.main - INFO -- l.37: Using 1 sender(s): dict_keys(['TLDR AI <dan@tldrnewsletter.com>']).\n",
      "2025-02-04 23:41:33,881 - src.newsletters.main - INFO -- l.39: Found 2 emails from sender TLDR AI <dan@tldrnewsletter.com>\n",
      "2025-02-04 23:41:33,882 - src.newsletters.main - INFO -- l.42: Parsing emails to extract news stories\n",
      "2025-02-04 23:41:33,883 - src.newsletters.parser.tldr - DEBUG -- l.26: Parsing email: Elon Musk vs. OpenAI ‚öîÔ∏è, Perplexity hardware ü§ñ, INTELLECT-1 Release 1Ô∏è‚É£\n",
      "2025-02-04 23:41:33,887 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.theverge.com:443\n",
      "2025-02-04 23:41:33,981 - urllib3.connectionpool - DEBUG -- l.546: https://www.theverge.com:443 \"HEAD /2024/11/30/24309697/elon-musk-openai-lawsuit-for-profit-transition-preliminary-injunction?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:33,986 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): techcrunch.com:443\n",
      "2025-02-04 23:41:34,131 - urllib3.connectionpool - DEBUG -- l.546: https://techcrunch.com:443 \"HEAD /2024/11/26/perplexity-mulls-getting-into-hardware/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:34,136 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): techcrunch.com:443\n",
      "2025-02-04 23:41:34,252 - urllib3.connectionpool - DEBUG -- l.546: https://techcrunch.com:443 \"HEAD /2024/11/26/inflection-ceo-says-its-done-competing-to-make-next-generation-ai-models/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:34,258 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.primeintellect.ai:443\n",
      "2025-02-04 23:41:34,626 - urllib3.connectionpool - DEBUG -- l.546: https://www.primeintellect.ai:443 \"HEAD /blog/intellect-1-release?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:34,630 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-02-04 23:41:34,710 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2411.18207v1?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:34,717 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-02-04 23:41:34,940 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2411.18296v1?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:34,944 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): research.google:443\n",
      "2025-02-04 23:41:35,312 - urllib3.connectionpool - DEBUG -- l.546: https://research.google:443 \"HEAD /blog/mapping-the-ionosphere-with-the-power-of-android/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:35,316 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-02-04 23:41:35,387 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2409.16045v1?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:35,389 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): gair-nlp.github.io:443\n",
      "2025-02-04 23:41:35,465 - urllib3.connectionpool - DEBUG -- l.546: https://gair-nlp.github.io:443 \"HEAD /ProX/homepage.html?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:35,468 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): huggingface.co:443\n",
      "2025-02-04 23:41:35,802 - urllib3.connectionpool - DEBUG -- l.546: https://huggingface.co:443 \"HEAD /wangyueqian/MMDuet?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:35,805 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): calpaterson.com:443\n",
      "2025-02-04 23:41:35,908 - urllib3.connectionpool - DEBUG -- l.546: https://calpaterson.com:443 \"HEAD /porter.html?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:35,912 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.notboring.co:443\n",
      "2025-02-04 23:41:36,071 - urllib3.connectionpool - DEBUG -- l.546: https://www.notboring.co:443 \"HEAD /p/rox?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:36,076 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): blog.play.ai:443\n",
      "2025-02-04 23:41:36,190 - urllib3.connectionpool - DEBUG -- l.546: https://blog.play.ai:443 \"HEAD /blog/21m-funding?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:36,193 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.theverge.com:443\n",
      "2025-02-04 23:41:36,255 - urllib3.connectionpool - DEBUG -- l.546: https://www.theverge.com:443 \"HEAD /2024/11/26/24306575/anthropic-claude-ai-custom-style-presets?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:36,258 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): github.com:443\n",
      "2025-02-04 23:41:36,576 - urllib3.connectionpool - DEBUG -- l.546: https://github.com:443 \"HEAD /rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:36,579 - src.newsletters.parser.tldr - DEBUG -- l.26: Parsing email: Alibaba new model üåê, Allen AI Open Instruct üßë‚Äçüè´, xAI app üì±\n",
      "2025-02-04 23:41:36,581 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): oodaloop.com:443\n",
      "2025-02-04 23:41:37,170 - urllib3.connectionpool - DEBUG -- l.546: https://oodaloop.com:443 \"HEAD /briefs/technology/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/?utm_source=tldrai HTTP/11\" 403 0\n",
      "2025-02-04 23:41:37,173 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): techcrunch.com:443\n",
      "2025-02-04 23:41:38,819 - urllib3.connectionpool - DEBUG -- l.546: https://techcrunch.com:443 \"HEAD /2024/11/26/ai2-releases-new-language-models-competitive-with-metas-llama/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:38,824 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.theverge.com:443\n",
      "2025-02-04 23:41:39,103 - urllib3.connectionpool - DEBUG -- l.546: https://www.theverge.com:443 \"HEAD /2024/11/27/24307571/xai-consumer-app-planned-report?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:39,108 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): hazyresearch.stanford.edu:443\n",
      "2025-02-04 23:41:39,349 - urllib3.connectionpool - DEBUG -- l.546: https://hazyresearch.stanford.edu:443 \"HEAD /blog/2024-11-28-tk-mlx?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:39,353 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-02-04 23:41:39,430 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2411.15139?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:39,435 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-02-04 23:41:39,518 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2411.17106v1?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:39,522 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): zhengchen1999.github.io:443\n",
      "2025-02-04 23:41:39,712 - urllib3.connectionpool - DEBUG -- l.546: https://zhengchen1999.github.io:443 \"HEAD /Grounding-IQA-Web/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:39,716 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): spectrum.ieee.org:443\n",
      "2025-02-04 23:41:39,884 - urllib3.connectionpool - DEBUG -- l.546: https://spectrum.ieee.org:443 \"HEAD /jailbreak-llm?utm_source=tldrai HTTP/11\" 403 0\n",
      "2025-02-04 23:41:39,888 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): blogs.nvidia.com:443\n",
      "2025-02-04 23:41:40,556 - urllib3.connectionpool - DEBUG -- l.546: https://blogs.nvidia.com:443 \"HEAD /blog/fugatto-gen-ai-sound-model/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:40,560 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): garymarcus.substack.com:443\n",
      "2025-02-04 23:41:41,073 - urllib3.connectionpool - DEBUG -- l.546: https://garymarcus.substack.com:443 \"HEAD /p/a-new-ai-scaling-law-shell-game?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:41,076 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): francis-rings.github.io:443\n",
      "2025-02-04 23:41:41,285 - urllib3.connectionpool - DEBUG -- l.546: https://francis-rings.github.io:443 \"HEAD /StableAnimator/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-02-04 23:41:41,286 - src.newsletters.main - INFO -- l.49: Newsletters block complete. Found 26 news stories in total.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_date_range = ['2024-11-29', '2024-12-02']\n",
    "news_stories = runner_newsletters(after=report_date_range[0], before=report_date_range[1])\n",
    "len(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa2d05d-080b-41da-ad9b-cd722187f444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:41.294973Z",
     "iopub.status.busy": "2025-02-05T04:41:41.294476Z",
     "iopub.status.idle": "2025-02-05T04:41:41.307374Z",
     "shell.execute_reply": "2025-02-05T04:41:41.306587Z",
     "shell.execute_reply.started": "2025-02-05T04:41:41.294944Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': \"ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN\",\n",
       "  'url': 'https://www.theverge.com/2024/11/30/24309697/elon-musk-openai-lawsuit-for-profit-transition-preliminary-injunction',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'www.theverge.com'},\n",
       " {'title': 'PERPLEXITY MULLS GETTING INTO HARDWARE',\n",
       "  'url': 'https://techcrunch.com/2024/11/26/perplexity-mulls-getting-into-hardware/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'techcrunch.com'},\n",
       " {'title': \"INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS\",\n",
       "  'url': 'https://techcrunch.com/2024/11/26/inflection-ceo-says-its-done-competing-to-make-next-generation-ai-models/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'techcrunch.com'},\n",
       " {'title': 'INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL',\n",
       "  'url': 'https://www.primeintellect.ai/blog/intellect-1-release',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'www.primeintellect.ai'},\n",
       " {'title': 'DETECT AND LEARN UNSEEN OBJECTS',\n",
       "  'url': 'https://arxiv.org/abs/2411.18207v1',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn't seen before.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'arxiv.org'},\n",
       " {'title': 'MAKING UNDERWATER IMAGES CLEAR',\n",
       "  'url': 'https://arxiv.org/abs/2411.18296v1',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'arxiv.org'},\n",
       " {'title': 'MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID',\n",
       "  'url': 'https://research.google/blog/mapping-the-ionosphere-with-the-power-of-android/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'research.google'},\n",
       " {'title': 'INTRODUCING LTNTORCH',\n",
       "  'url': 'https://arxiv.org/abs/2409.16045v1',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'arxiv.org'},\n",
       " {'title': 'REFINING PRETRAINING DATA PROGRAMMATICALLY',\n",
       "  'url': 'https://gair-nlp.github.io/ProX/homepage.html',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'gair-nlp.github.io'},\n",
       " {'title': 'CHATS WITH VIDEOS IN REAL TIME',\n",
       "  'url': 'https://huggingface.co/wangyueqian/MMDuet',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'MMDuet is a novel \"video-text duet\" interaction format for VideoLLMs that allows AI to provide real-time responses as videos play. The approach mimics a dialogue where both users and AI can exchange messages during playback.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'huggingface.co'},\n",
       " {'title': 'BUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS',\n",
       "  'url': 'https://calpaterson.com/porter.html',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'calpaterson.com'},\n",
       " {'title': 'ROX',\n",
       "  'url': 'https://www.notboring.co/p/rox',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI's ability to manage unstructured data and integrate with data warehouses. Rox's strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'www.notboring.co'},\n",
       " {'title': 'PLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL',\n",
       "  'url': 'https://blog.play.ai/blog/21m-funding',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.',\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'blog.play.ai'},\n",
       " {'title': 'ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE',\n",
       "  'url': 'https://www.theverge.com/2024/11/26/24306575/anthropic-claude-ai-custom-style-presets',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'www.theverge.com'},\n",
       " {'title': 'CONVERTING GPT TO LLAMA',\n",
       "  'url': 'https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"This repository contains code for converting a GPT implementation to Meta AI's Llama.\",\n",
       "  'date_source': 'Mon, 2 Dec 2024 14:29:42 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'github.com'},\n",
       " {'title': \"ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL\",\n",
       "  'url': 'https://oodaloop.com/briefs/technology/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\",\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'oodaloop.com'},\n",
       " {'title': \"AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA\",\n",
       "  'url': 'https://techcrunch.com/2024/11/26/ai2-releases-new-language-models-competitive-with-metas-llama/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\",\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'techcrunch.com'},\n",
       " {'title': 'XAI COULD SOON HAVE ITS OWN APP',\n",
       "  'url': 'https://www.theverge.com/2024/11/27/24307571/xai-consumer-app-planned-report',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': \"Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\",\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'www.theverge.com'},\n",
       " {'title': 'THUNDERKITTENS FOR APPLE SILICON',\n",
       "  'url': 'https://hazyresearch.stanford.edu/blog/2024-11-28-tk-mlx',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Hazy Research has been critical in improving hardware utilization for AI workloads. It has extended its amazing ThunderKittens Kernel writing framework to work on Apple Silicon.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'hazyresearch.stanford.edu'},\n",
       " {'title': 'DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR END-TO-END AUTONOMOUS\\r\\nDRIVING',\n",
       "  'url': 'https://arxiv.org/abs/2411.15139',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Diffusion models for End-to-End driving of autonomous vehicles which can operate at 45 FPS on a 4090 chip.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'arxiv.org'},\n",
       " {'title': 'SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION',\n",
       "  'url': 'https://arxiv.org/abs/2411.17106v1',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'PassionSR introduces an approach that makes diffusion-based image super-resolution (SR) models more hardware-friendly.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'arxiv.org'},\n",
       " {'title': 'FINE-GRAINED IMAGE QUALITY ASSESSMENT',\n",
       "  'url': 'https://zhengchen1999.github.io/Grounding-IQA-Web/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'zhengchen1999.github.io'},\n",
       " {'title': \"IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS\",\n",
       "  'url': 'https://spectrum.ieee.org/jailbreak-llm',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'spectrum.ieee.org'},\n",
       " {'title': \"WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS\",\n",
       "  'url': 'https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'blogs.nvidia.com'},\n",
       " {'title': 'THE NEW AI SCALING LAW SHELL GAME',\n",
       "  'url': 'https://garymarcus.substack.com/p/a-new-ai-scaling-law-shell-game',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'Recent shifts in AI scaling laws reveal limitations in predictability and effectiveness, with new models not meeting earlier expectations. Microsoft CEO Satya Nadella highlights \"inference time compute\" as a potential area of focus, but concerns about cost and reliability persist. Innovation beyond scaling is needed. LLMs should be part of a broader AI strategy.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'garymarcus.substack.com'},\n",
       " {'title': 'HUMAN IMAGE ANIMATION',\n",
       "  'url': 'https://francis-rings.github.io/StableAnimator/',\n",
       "  'source_of_the_news': 'TLDR AI <dan@tldrnewsletter.com>',\n",
       "  'news_summary': 'StableAnimator introduces a breakthrough in human image animation by ensuring identity consistency in generated videos.',\n",
       "  'date_source': 'Fri, 29 Nov 2024 14:16:46 +0000',\n",
       "  'date_source_time_zone': 'utc',\n",
       "  'news_provider': 'francis-rings.github.io'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_stories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a218fc7c-a0b8-4f4a-bf4a-66f5ca7ce1f2",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405dc026-e749-4434-970d-878c4a70ba12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:41.310739Z",
     "iopub.status.busy": "2025-02-05T04:41:41.309593Z",
     "iopub.status.idle": "2025-02-05T04:41:56.462417Z",
     "shell.execute_reply": "2025-02-05T04:41:56.461471Z",
     "shell.execute_reply.started": "2025-02-05T04:41:41.310708Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:41:41,313 - src.scoring.main - INFO -- l.24: Converting all news stories to a structured format.\n",
      "2025-02-04 23:41:42,403 - src.scoring.main - INFO -- l.28: Querying the metadata tags from Google Sheets.\n",
      "2025-02-04 23:41:42,407 - googleapiclient.discovery_cache - INFO -- l.49: file_cache is only supported with oauth2client<4.0.0\n",
      "2025-02-04 23:41:42,755 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/competitive_intelligence?alt=json\n",
      "2025-02-04 23:41:42,756 - google_auth_httplib2 - DEBUG -- l.118: Making request: POST https://oauth2.googleapis.com/token\n",
      "2025-02-04 23:41:43,640 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/themes?alt=json\n",
      "2025-02-04 23:41:44,077 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/market_intelligence?alt=json\n",
      "2025-02-04 23:41:44,350 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/personalities?alt=json\n",
      "2025-02-04 23:41:56,454 - src.scoring.structured_news_stories - DEBUG -- l.96: col=competitive_intelligence, score_col=0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "Name: competitive_intelligence, dtype: int64\n",
      "2025-02-04 23:41:56,455 - src.scoring.structured_news_stories - DEBUG -- l.96: col=themes, score_col=0     1\n",
      "1     3\n",
      "2     3\n",
      "3     2\n",
      "4     2\n",
      "5     2\n",
      "6     0\n",
      "7     2\n",
      "8     2\n",
      "9     1\n",
      "10    3\n",
      "11    2\n",
      "12    3\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "16    4\n",
      "17    2\n",
      "18    1\n",
      "19    1\n",
      "20    0\n",
      "21    1\n",
      "22    3\n",
      "23    3\n",
      "24    1\n",
      "25    0\n",
      "Name: themes, dtype: int64\n",
      "2025-02-04 23:41:56,457 - src.scoring.structured_news_stories - DEBUG -- l.96: col=market_intelligence, score_col=0     2\n",
      "1     1\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     1\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    2\n",
      "11    0\n",
      "12    0\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "16    1\n",
      "17    4\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    1\n",
      "24    1\n",
      "25    0\n",
      "Name: market_intelligence, dtype: int64\n",
      "2025-02-04 23:41:56,458 - src.scoring.structured_news_stories - DEBUG -- l.96: col=personalities, score_col=0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "Name: personalities, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_news_stories, target_fields = runner_scoring(news_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ca7e85-41eb-4865-a812-ee85c5933fb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:56.463715Z",
     "iopub.status.busy": "2025-02-05T04:41:56.463474Z",
     "iopub.status.idle": "2025-02-05T04:41:56.509795Z",
     "shell.execute_reply": "2025-02-05T04:41:56.508883Z",
     "shell.execute_reply.started": "2025-02-05T04:41:56.463695Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>news_provider</th>\n",
       "      <th>source_of_the_news</th>\n",
       "      <th>text</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>date_source</th>\n",
       "      <th>date_source_time_zone</th>\n",
       "      <th>version</th>\n",
       "      <th>competitive_intelligence</th>\n",
       "      <th>themes</th>\n",
       "      <th>market_intelligence</th>\n",
       "      <th>personalities</th>\n",
       "      <th>score_category_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...</td>\n",
       "      <td>https://www.theverge.com/2024/11/30/24309697/e...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's legal team has filed a motion to p...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Legal]</td>\n",
       "      <td>[OpenAI, Twitter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERPLEXITY MULLS GETTING INTO HARDWARE</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/perplexity-m...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Perplexity's CEO plans to develop a \"simple, u...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal, Funding]</td>\n",
       "      <td>[Perplexity]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/inflection-c...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Inflection AI shifted its focus from developin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...</td>\n",
       "      <td>https://www.primeintellect.ai/blog/intellect-1...</td>\n",
       "      <td>www.primeintellect.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>INTELLECT-1 is a 10B parameter model trained o...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model Training, Evaluation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DETECT AND LEARN UNSEEN OBJECTS</td>\n",
       "      <td>https://arxiv.org/abs/2411.18207v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This new framework pushes object detection int...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAKING UNDERWATER IMAGES CLEAR</td>\n",
       "      <td>https://arxiv.org/abs/2411.18296v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>HUPE is an AI-powered method that improves und...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID</td>\n",
       "      <td>https://research.google/blog/mapping-the-ionos...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Google researchers were able to accurately map...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Google]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTRODUCING LTNTORCH</td>\n",
       "      <td>https://arxiv.org/abs/2409.16045v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Logic Tensor Networks (LTN) merge deep learnin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, ML&amp;DL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REFINING PRETRAINING DATA PROGRAMMATICALLY</td>\n",
       "      <td>https://gair-nlp.github.io/ProX/homepage.html</td>\n",
       "      <td>gair-nlp.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>ProX is a framework that treats data refinemen...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Model Training]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHATS WITH VIDEOS IN REAL TIME</td>\n",
       "      <td>https://huggingface.co/wangyueqian/MMDuet</td>\n",
       "      <td>huggingface.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>MMDuet is a novel \"video-text duet\" interactio...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...</td>\n",
       "      <td>https://calpaterson.com/porter.html</td>\n",
       "      <td>calpaterson.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>LLM makers like OpenAI face significant challe...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Funding]</td>\n",
       "      <td>[OpenAI, NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROX</td>\n",
       "      <td>https://www.notboring.co/p/rox</td>\n",
       "      <td>www.notboring.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>A new AI-native CRM, Rox, aims to disrupt Sale...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...</td>\n",
       "      <td>https://blog.play.ai/blog/21m-funding</td>\n",
       "      <td>blog.play.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PlayAI raised $21 Million to advance voice-fir...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...</td>\n",
       "      <td>https://www.theverge.com/2024/11/26/24306575/a...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Anthropic's Claude AI now offers customizable ...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Anthropic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CONVERTING GPT TO LLAMA</td>\n",
       "      <td>https://github.com/rasbt/LLMs-from-scratch/tre...</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This repository contains code for converting a...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL</td>\n",
       "      <td>https://oodaloop.com/briefs/technology/alibaba...</td>\n",
       "      <td>oodaloop.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Alibaba has released QwQ-32B-Preview, an ‚Äòopen...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/ai2-releases...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Ai2 has released OLMo 2, an open-source langua...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training, Funding]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XAI COULD SOON HAVE ITS OWN APP</td>\n",
       "      <td>https://www.theverge.com/2024/11/27/24307571/x...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's xAI plans to launch a standalone a...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Conversational AI, RAI]</td>\n",
       "      <td>[OpenAI, Anthropic, Google, Twitter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>THUNDERKITTENS FOR APPLE SILICON</td>\n",
       "      <td>https://hazyresearch.stanford.edu/blog/2024-11...</td>\n",
       "      <td>hazyresearch.stanford.edu</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Hazy Research has been critical in improving h...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...</td>\n",
       "      <td>https://arxiv.org/abs/2411.15139</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Diffusion models for End-to-End driving of aut...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Self-Driving Cars]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION</td>\n",
       "      <td>https://arxiv.org/abs/2411.17106v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PassionSR introduces an approach that makes di...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FINE-GRAINED IMAGE QUALITY ASSESSMENT</td>\n",
       "      <td>https://zhengchen1999.github.io/Grounding-IQA-...</td>\n",
       "      <td>zhengchen1999.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Grounding-IQA is a new approach to image quali...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...</td>\n",
       "      <td>https://spectrum.ieee.org/jailbreak-llm</td>\n",
       "      <td>spectrum.ieee.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>RoboPAIR is an algorithm that successfully jai...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Evaluation, Robotics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS</td>\n",
       "      <td>https://blogs.nvidia.com/blog/fugatto-gen-ai-s...</td>\n",
       "      <td>blogs.nvidia.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Fugatto, a new generative AI model, allows use...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training]</td>\n",
       "      <td>[NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE NEW AI SCALING LAW SHELL GAME</td>\n",
       "      <td>https://garymarcus.substack.com/p/a-new-ai-sca...</td>\n",
       "      <td>garymarcus.substack.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Recent shifts in AI scaling laws reveal limita...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Microsoft]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HUMAN IMAGE ANIMATION</td>\n",
       "      <td>https://francis-rings.github.io/StableAnimator/</td>\n",
       "      <td>francis-rings.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>StableAnimator introduces a breakthrough in hu...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...   \n",
       "1              PERPLEXITY MULLS GETTING INTO HARDWARE   \n",
       "2   INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...   \n",
       "3   INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...   \n",
       "4                     DETECT AND LEARN UNSEEN OBJECTS   \n",
       "5                      MAKING UNDERWATER IMAGES CLEAR   \n",
       "6    MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID   \n",
       "7                                INTRODUCING LTNTORCH   \n",
       "8          REFINING PRETRAINING DATA PROGRAMMATICALLY   \n",
       "9                      CHATS WITH VIDEOS IN REAL TIME   \n",
       "10  BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...   \n",
       "11                                                ROX   \n",
       "12  PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...   \n",
       "13  ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...   \n",
       "14                            CONVERTING GPT TO LLAMA   \n",
       "15   ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL   \n",
       "16  AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...   \n",
       "17                    XAI COULD SOON HAVE ITS OWN APP   \n",
       "18                   THUNDERKITTENS FOR APPLE SILICON   \n",
       "19  DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...   \n",
       "20         SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION   \n",
       "21              FINE-GRAINED IMAGE QUALITY ASSESSMENT   \n",
       "22  IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...   \n",
       "23         WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS   \n",
       "24                  THE NEW AI SCALING LAW SHELL GAME   \n",
       "25                              HUMAN IMAGE ANIMATION   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.theverge.com/2024/11/30/24309697/e...   \n",
       "1   https://techcrunch.com/2024/11/26/perplexity-m...   \n",
       "2   https://techcrunch.com/2024/11/26/inflection-c...   \n",
       "3   https://www.primeintellect.ai/blog/intellect-1...   \n",
       "4                  https://arxiv.org/abs/2411.18207v1   \n",
       "5                  https://arxiv.org/abs/2411.18296v1   \n",
       "6   https://research.google/blog/mapping-the-ionos...   \n",
       "7                  https://arxiv.org/abs/2409.16045v1   \n",
       "8       https://gair-nlp.github.io/ProX/homepage.html   \n",
       "9           https://huggingface.co/wangyueqian/MMDuet   \n",
       "10                https://calpaterson.com/porter.html   \n",
       "11                     https://www.notboring.co/p/rox   \n",
       "12              https://blog.play.ai/blog/21m-funding   \n",
       "13  https://www.theverge.com/2024/11/26/24306575/a...   \n",
       "14  https://github.com/rasbt/LLMs-from-scratch/tre...   \n",
       "15  https://oodaloop.com/briefs/technology/alibaba...   \n",
       "16  https://techcrunch.com/2024/11/26/ai2-releases...   \n",
       "17  https://www.theverge.com/2024/11/27/24307571/x...   \n",
       "18  https://hazyresearch.stanford.edu/blog/2024-11...   \n",
       "19                   https://arxiv.org/abs/2411.15139   \n",
       "20                 https://arxiv.org/abs/2411.17106v1   \n",
       "21  https://zhengchen1999.github.io/Grounding-IQA-...   \n",
       "22            https://spectrum.ieee.org/jailbreak-llm   \n",
       "23  https://blogs.nvidia.com/blog/fugatto-gen-ai-s...   \n",
       "24  https://garymarcus.substack.com/p/a-new-ai-sca...   \n",
       "25    https://francis-rings.github.io/StableAnimator/   \n",
       "\n",
       "                news_provider                source_of_the_news text  \\\n",
       "0            www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "1              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "2              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "3       www.primeintellect.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "4                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "5                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "6             research.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "7                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "8          gair-nlp.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "9              huggingface.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "10            calpaterson.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "11           www.notboring.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "12               blog.play.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "13           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "14                 github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "15               oodaloop.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "16             techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "17           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "18  hazyresearch.stanford.edu  TLDR AI <dan@tldrnewsletter.com>        \n",
       "19                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "20                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "21    zhengchen1999.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "22          spectrum.ieee.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "23           blogs.nvidia.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "24    garymarcus.substack.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "25    francis-rings.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "\n",
       "                                         news_summary  \\\n",
       "0   Elon Musk's legal team has filed a motion to p...   \n",
       "1   Perplexity's CEO plans to develop a \"simple, u...   \n",
       "2   Inflection AI shifted its focus from developin...   \n",
       "3   INTELLECT-1 is a 10B parameter model trained o...   \n",
       "4   This new framework pushes object detection int...   \n",
       "5   HUPE is an AI-powered method that improves und...   \n",
       "6   Google researchers were able to accurately map...   \n",
       "7   Logic Tensor Networks (LTN) merge deep learnin...   \n",
       "8   ProX is a framework that treats data refinemen...   \n",
       "9   MMDuet is a novel \"video-text duet\" interactio...   \n",
       "10  LLM makers like OpenAI face significant challe...   \n",
       "11  A new AI-native CRM, Rox, aims to disrupt Sale...   \n",
       "12  PlayAI raised $21 Million to advance voice-fir...   \n",
       "13  Anthropic's Claude AI now offers customizable ...   \n",
       "14  This repository contains code for converting a...   \n",
       "15  Alibaba has released QwQ-32B-Preview, an ‚Äòopen...   \n",
       "16  Ai2 has released OLMo 2, an open-source langua...   \n",
       "17  Elon Musk's xAI plans to launch a standalone a...   \n",
       "18  Hazy Research has been critical in improving h...   \n",
       "19  Diffusion models for End-to-End driving of aut...   \n",
       "20  PassionSR introduces an approach that makes di...   \n",
       "21  Grounding-IQA is a new approach to image quali...   \n",
       "22  RoboPAIR is an algorithm that successfully jai...   \n",
       "23  Fugatto, a new generative AI model, allows use...   \n",
       "24  Recent shifts in AI scaling laws reveal limita...   \n",
       "25  StableAnimator introduces a breakthrough in hu...   \n",
       "\n",
       "                 date_source date_source_time_zone version  \\\n",
       "0  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "1  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "2  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "3  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "4  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "5  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "6  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "7  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "8  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "9  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "10 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "11 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "12 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "13 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "14 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "15 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "16 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "17 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "18 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "19 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "20 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "21 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "22 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "23 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "24 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "25 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "\n",
       "   competitive_intelligence                                      themes  \\\n",
       "0                        []                                     [Legal]   \n",
       "1                        []             [AI&GenAI, Multimodal, Funding]   \n",
       "2                        []                  [AI&GenAI, Model, Funding]   \n",
       "3                        []                [Model Training, Evaluation]   \n",
       "4                        []                      [AI&GenAI, Multimodal]   \n",
       "5                        []                      [AI&GenAI, Multimodal]   \n",
       "6                        []                                          []   \n",
       "7                        []                              [Model, ML&DL]   \n",
       "8                        []                     [Model, Model Training]   \n",
       "9                        []                                  [AI&GenAI]   \n",
       "10                       []                  [AI&GenAI, Model, Funding]   \n",
       "11                       []                         [AI&GenAI, Funding]   \n",
       "12                       []             [AI&GenAI, Multimodal, Funding]   \n",
       "13                       []                                  [AI&GenAI]   \n",
       "14                       []                                  [AI&GenAI]   \n",
       "15                       []                                     [Model]   \n",
       "16                       []  [AI&GenAI, Model, Model Training, Funding]   \n",
       "17                       []                    [Conversational AI, RAI]   \n",
       "18                       []                                  [AI&GenAI]   \n",
       "19                       []                         [Self-Driving Cars]   \n",
       "20                       []                                          []   \n",
       "21                       []                                [Multimodal]   \n",
       "22                       []               [Model, Evaluation, Robotics]   \n",
       "23                       []           [AI&GenAI, Model, Model Training]   \n",
       "24                       []                                  [AI&GenAI]   \n",
       "25                       []                                          []   \n",
       "\n",
       "                     market_intelligence personalities  score_category_count  \n",
       "0                      [OpenAI, Twitter]            []                     3  \n",
       "1                           [Perplexity]            []                     4  \n",
       "2                                     []            []                     3  \n",
       "3                                     []            []                     2  \n",
       "4                                     []            []                     2  \n",
       "5                                     []            []                     2  \n",
       "6                               [Google]            []                     0  \n",
       "7                                     []            []                     2  \n",
       "8                                     []            []                     2  \n",
       "9                                     []            []                     1  \n",
       "10                      [OpenAI, NVIDIA]            []                     5  \n",
       "11                                    []            []                     2  \n",
       "12                                    []            []                     3  \n",
       "13                           [Anthropic]            []                     2  \n",
       "14                                [Meta]            []                     2  \n",
       "15                              [OpenAI]            []                     2  \n",
       "16                                [Meta]            []                     5  \n",
       "17  [OpenAI, Anthropic, Google, Twitter]            []                     6  \n",
       "18                                    []            []                     1  \n",
       "19                                    []            []                     1  \n",
       "20                                    []            []                     0  \n",
       "21                                    []            []                     1  \n",
       "22                                    []            []                     3  \n",
       "23                              [NVIDIA]            []                     4  \n",
       "24                           [Microsoft]            []                     2  \n",
       "25                                    []            []                     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_news_stories))\n",
    "df_news_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fae023-1f7b-44bd-b576-982478ff4ef0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:41:56.511381Z",
     "iopub.status.busy": "2025-02-05T04:41:56.510699Z",
     "iopub.status.idle": "2025-02-05T04:41:56.523793Z",
     "shell.execute_reply": "2025-02-05T04:41:56.522551Z",
     "shell.execute_reply.started": "2025-02-05T04:41:56.511356Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'competitive_intelligence': {'MS': ['Morgan Stanley'],\n",
       "  'JPM': ['J.P. Morgan', 'JP Morgan', 'Chase', 'JPMorgan', 'J P Morgan'],\n",
       "  'GS': ['Goldman Sachs'],\n",
       "  'BoA': ['Bank of America'],\n",
       "  'Citi': ['Citi', 'Citigroup'],\n",
       "  'UBS': ['UBS'],\n",
       "  'Deutsche': ['Deutsche Bank'],\n",
       "  'HSBC': ['HSBC'],\n",
       "  'Barclays': ['Barclays'],\n",
       "  'RBC': ['RBC', 'Royal Bank of Canada', 'Borealis AI', 'RBC Borealis'],\n",
       "  'Wells': ['Wells Fargo'],\n",
       "  'Capital': ['Capital One'],\n",
       "  'BNY': ['BNY', 'Mellon', 'Bank of New York'],\n",
       "  'TD': ['TD', 'Layer 6', 'Layer6']},\n",
       " 'themes': {'AI&GenAI': ['AI',\n",
       "   'Artificial Intelligence',\n",
       "   'Artificial Intelligences',\n",
       "   'AGI',\n",
       "   'Artificial General Intelligence',\n",
       "   'Artificials General Intelligence',\n",
       "   'A.I',\n",
       "   'A.G.I',\n",
       "   'GenAI',\n",
       "   'Gen AI',\n",
       "   'Generative AI',\n",
       "   'GenerativeAI'],\n",
       "  'Model': ['LLM',\n",
       "   'language model',\n",
       "   'language models',\n",
       "   'Foundational Model',\n",
       "   'Foundational Models',\n",
       "   'Foundational Language Model',\n",
       "   'Foundational Language Models',\n",
       "   'Language Model',\n",
       "   'Language Models',\n",
       "   'Transformer',\n",
       "   'Transformers',\n",
       "   'AI model',\n",
       "   'AI models',\n",
       "   'State-Space Model',\n",
       "   'State-Space Models',\n",
       "   'VLM',\n",
       "   'SLM',\n",
       "   'small language model',\n",
       "   'small language models',\n",
       "   'latent space ',\n",
       "   'latent spaces ',\n",
       "   'reasoning ',\n",
       "   'reasonings ',\n",
       "   'reason ',\n",
       "   'reasons '],\n",
       "  'Agents': ['autonomous agent',\n",
       "   'autonomous agents',\n",
       "   'AI agent',\n",
       "   'AI agents',\n",
       "   'RL agent',\n",
       "   'RL agents',\n",
       "   'reinforcement learning agent',\n",
       "   'reinforcement learning agents'],\n",
       "  'Conversational AI': ['conversational AI', 'chatbot', 'chatbots'],\n",
       "  'Self-Driving Cars': ['autonomous vehicle',\n",
       "   'autonomous vehicles',\n",
       "   'self-driving car',\n",
       "   'self-driving cars',\n",
       "   'autonomous driving',\n",
       "   'autonomous drivings'],\n",
       "  'Information Management': ['RAG',\n",
       "   'Retrieval Augmented Generation',\n",
       "   'Retrieval Augmented Generations',\n",
       "   'Knowledge management',\n",
       "   'Knowledge managements',\n",
       "   'RAG Graph',\n",
       "   'RAG Graphs',\n",
       "   'Knowledge Search',\n",
       "   'Knowledge Searches',\n",
       "   'GraphRAG',\n",
       "   'GraphRAGs',\n",
       "   'Graph RAG',\n",
       "   'Graph RAGS',\n",
       "   'AI Search',\n",
       "   'AI Searches',\n",
       "   'semantic search',\n",
       "   'semantic searches',\n",
       "   'vector similarity',\n",
       "   'vector similarities',\n",
       "   'embedding',\n",
       "   'embeddings'],\n",
       "  'Model Training': ['training',\n",
       "   'trainings',\n",
       "   'SSL',\n",
       "   'Self-supervised learning',\n",
       "   'Self-supervised learnings',\n",
       "   'pretraining',\n",
       "   'pretrainings',\n",
       "   'train',\n",
       "   'trains',\n",
       "   'trained',\n",
       "   'traineds',\n",
       "   'fine-tuning',\n",
       "   'fine-tunings',\n",
       "   'Fine-tune',\n",
       "   'Fine-tunes',\n",
       "   'SFT',\n",
       "   'LoRA',\n",
       "   'LoRAs',\n",
       "   'finetune',\n",
       "   'finetunes',\n",
       "   'finetuning',\n",
       "   'finetunings',\n",
       "   'post-training',\n",
       "   'post-trainings',\n",
       "   'RLHF',\n",
       "   'Constitutional AI',\n",
       "   'RL',\n",
       "   'Reinforcement Learning',\n",
       "   'Reinforcement Learnings',\n",
       "   'DPO',\n",
       "   'Alignment',\n",
       "   'Alignments',\n",
       "   'PPO',\n",
       "   'instruction finetuning',\n",
       "   'instruction finetunings',\n",
       "   'distillation',\n",
       "   'distillations',\n",
       "   'training data',\n",
       "   'training datas',\n",
       "   'training dataset',\n",
       "   'training datasets',\n",
       "   'data efficient ',\n",
       "   'data efficients ',\n",
       "   'alternative data',\n",
       "   'alternative datas'],\n",
       "  'Multimodal': ['multi-modal',\n",
       "   'multi-modals',\n",
       "   'multimodality',\n",
       "   'multimodalities',\n",
       "   'multimodal',\n",
       "   'multimodals',\n",
       "   'text-to-speech',\n",
       "   'texts-to-speech',\n",
       "   'speech-to-text',\n",
       "   'speeches-to-text',\n",
       "   'speech-to-speech',\n",
       "   'speeches-to-speech',\n",
       "   'voice model',\n",
       "   'voice models',\n",
       "   'generative voice',\n",
       "   'generative voices',\n",
       "   'tts model',\n",
       "   'tts models',\n",
       "   'voice-to-voice',\n",
       "   'voices-to-voice',\n",
       "   'Computer Vision',\n",
       "   'Computer Visions',\n",
       "   'video generation',\n",
       "   'video generations',\n",
       "   'image generation',\n",
       "   'image generations',\n",
       "   'image classification',\n",
       "   'image classifications',\n",
       "   'object detection',\n",
       "   'object detections',\n",
       "   'video model',\n",
       "   'video models'],\n",
       "  'ML&DL': ['ML',\n",
       "   'Machine Learning',\n",
       "   'Machine Learnings',\n",
       "   'XGBoost',\n",
       "   'XGBoosts',\n",
       "   'kNN',\n",
       "   'kNNs',\n",
       "   'decision tree',\n",
       "   'decision trees',\n",
       "   'classifier',\n",
       "   'classifiers',\n",
       "   'DL',\n",
       "   'Deep Learning',\n",
       "   'Deep Learnings',\n",
       "   'Neural Network',\n",
       "   'Neural Networks',\n",
       "   'ANN',\n",
       "   'MLP',\n",
       "   'perceptron',\n",
       "   'perceptrons',\n",
       "   'NLP',\n",
       "   'natural language',\n",
       "   'natural languages'],\n",
       "  'RAI': ['Responsible AI',\n",
       "   'RAI',\n",
       "   'AI ethic',\n",
       "   'AI ethics',\n",
       "   'Trustworthy',\n",
       "   'Trustworthys',\n",
       "   'explainability',\n",
       "   'explainabilities',\n",
       "   'interpretability',\n",
       "   'interpretabilities',\n",
       "   'bias',\n",
       "   'biases',\n",
       "   'fairness',\n",
       "   'fairnesses',\n",
       "   'XAI'],\n",
       "  'FoW': ['digital workforce',\n",
       "   'digital workforces',\n",
       "   'digital employee',\n",
       "   'digital employees',\n",
       "   'future of work',\n",
       "   'futures of work'],\n",
       "  'Funding': ['series',\n",
       "   'round',\n",
       "   'rounds',\n",
       "   'investor',\n",
       "   'investors',\n",
       "   'valuation',\n",
       "   'valuations',\n",
       "   'IPO',\n",
       "   'VC',\n",
       "   'VCS',\n",
       "   'raise',\n",
       "   'raises',\n",
       "   'raised',\n",
       "   'raiseds',\n",
       "   'Venture Capital',\n",
       "   'Venture Capitals',\n",
       "   'raising',\n",
       "   'raisings',\n",
       "   'fundraising ',\n",
       "   'fundraisings ',\n",
       "   'investment',\n",
       "   'investments',\n",
       "   'invested',\n",
       "   'investeds',\n",
       "   'funding',\n",
       "   'fundings',\n",
       "   'acquire',\n",
       "   'acquires',\n",
       "   'acquired',\n",
       "   'acquireds',\n",
       "   'acquisition',\n",
       "   'acquisitions'],\n",
       "  'Evaluation': ['evaluation',\n",
       "   'evaluations',\n",
       "   'eval',\n",
       "   'evals',\n",
       "   'leaderboard',\n",
       "   'leaderboards',\n",
       "   'benchmark',\n",
       "   'benchmarks',\n",
       "   'metrics',\n",
       "   'metric',\n",
       "   'as-a-Judge',\n",
       "   'as-a-Judges',\n",
       "   'red-teaming',\n",
       "   'red-teamings',\n",
       "   'safety',\n",
       "   'safeties',\n",
       "   'AI firewall',\n",
       "   'AI firewalls',\n",
       "   'LLM firewall',\n",
       "   'LLM firewalls',\n",
       "   'hallucination',\n",
       "   'hallucinations',\n",
       "   'hallucinate',\n",
       "   'hallucinates'],\n",
       "  'Legal': ['lawsuit',\n",
       "   'lawsuits',\n",
       "   'filed a motion',\n",
       "   'fileds a motion',\n",
       "   'IP',\n",
       "   'copyright',\n",
       "   'copyrights',\n",
       "   'sued',\n",
       "   'sueds',\n",
       "   'infringement',\n",
       "   'infringements',\n",
       "   'sue',\n",
       "   'sues',\n",
       "   'legal',\n",
       "   'legals'],\n",
       "  'Robotics': ['embodied AI',\n",
       "   'physical AI',\n",
       "   'robot',\n",
       "   'robots',\n",
       "   'robotic',\n",
       "   'robotics',\n",
       "   'world model',\n",
       "   'world models',\n",
       "   'spatial intelligence ',\n",
       "   'spatial intelligences ',\n",
       "   'augmented reality ',\n",
       "   'augmented realities ',\n",
       "   'humanoid',\n",
       "   'humanoids']},\n",
       " 'market_intelligence': {'OpenAI': ['OpenAI', 'Open AI', 'Sam Altman'],\n",
       "  'Anthropic': ['Anthropic'],\n",
       "  'Cohere': ['Cohere', 'Cohere For AI', 'Aidan Gomez'],\n",
       "  'AI21': ['AI21 Labs', 'AI 21 Labs'],\n",
       "  'Mistral AI': ['Mistral AI', 'Mistral'],\n",
       "  'Scale': ['Scale AI',\n",
       "   'Scale GenAI Platform',\n",
       "   'Scale Data Engine',\n",
       "   'Scale Donovan',\n",
       "   'Scale Evaluation',\n",
       "   'Alexandr Wang'],\n",
       "  'Google': ['Google',\n",
       "   'GCP',\n",
       "   'Google Cloud Platform',\n",
       "   'Deepmind',\n",
       "   'Demis Hassabis',\n",
       "   'Sundar Pichai',\n",
       "   'Youtube',\n",
       "   'Waymo'],\n",
       "  'Microsoft': ['Microsoft', 'Azure', 'Satya Nadella'],\n",
       "  'Amazon': ['Amazon', 'AWS', 'Jeff Bezos'],\n",
       "  'NVIDIA': ['NVIDIA', 'NVDA', 'Jensen Huang', 'Jim Fan', 'Nvidia'],\n",
       "  'Meta': ['Meta',\n",
       "   'Facebook',\n",
       "   'Whatsapp',\n",
       "   'Instragram',\n",
       "   'FAIR',\n",
       "   'Facebook AI Research',\n",
       "   'Mark Zuckerberg'],\n",
       "  'HF': ['HuggingFace', 'Hugging Face'],\n",
       "  'Twitter': ['Twitter', 'X', 'X.AI', 'Grok', 'Tesla', 'Elon Musk'],\n",
       "  'Perplexity': ['Perplexity', 'Aravind Srinivas']},\n",
       " 'personalities': {'Ilya Sutskever': ['Ilya Sutskever'],\n",
       "  'Andrej Karpathy': ['Andrej Karpathy'],\n",
       "  'Andrew Ng': ['Andrew Ng'],\n",
       "  'Matei Zaharia': ['Matei Zaharia'],\n",
       "  'Benedict Evans': ['Benedict Evans'],\n",
       "  'Ethan Mollick': ['Ethan Mollick'],\n",
       "  'Jonathan Frankle': ['Jonathan Frankle'],\n",
       "  'Omar Khattab': ['Omar Khattab'],\n",
       "  'Jim Fan': ['Jim Fan'],\n",
       "  'Chelsea Finn': ['Chelsea Finn']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4f2435-916a-4b99-8455-6b32a51ce8a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e40e4e11-c4be-4460-9206-a0aade436255",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:57:27.497814Z",
     "iopub.status.busy": "2025-01-12T04:57:27.497425Z",
     "iopub.status.idle": "2025-01-12T04:57:27.638769Z",
     "shell.execute_reply": "2025-01-12T04:57:27.637571Z",
     "shell.execute_reply.started": "2025-01-12T04:57:27.497789Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 23:57:27,549 - src.saving.database - INFO -- l.23: No column unique_id found in df_new. Adding and populating one now.\n",
      "2025-01-11 23:57:27,552 - src.saving.database - DEBUG -- l.80: Creating unique identifier from value 52.\n",
      "2025-01-11 23:57:27,558 - src.saving.database - INFO -- l.89: All values in the unique_id column are unique.\n",
      "2025-01-11 23:57:27,560 - src.saving.database - INFO -- l.93: Saving updated database to log/test.parquet\n"
     ]
    }
   ],
   "source": [
    "runner_saving(df_news_stories, \"log/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fc7174e-2cee-4452-808b-5387b0dcba42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:57:27.642140Z",
     "iopub.status.busy": "2025-01-12T04:57:27.641577Z",
     "iopub.status.idle": "2025-01-12T04:57:27.697021Z",
     "shell.execute_reply": "2025-01-12T04:57:27.695638Z",
     "shell.execute_reply.started": "2025-01-12T04:57:27.642065Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>news_provider</th>\n",
       "      <th>source_of_the_news</th>\n",
       "      <th>text</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>date_source</th>\n",
       "      <th>date_source_time_zone</th>\n",
       "      <th>version</th>\n",
       "      <th>competitive_intelligence</th>\n",
       "      <th>themes</th>\n",
       "      <th>market_intelligence</th>\n",
       "      <th>personalities</th>\n",
       "      <th>score_category_count</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...</td>\n",
       "      <td>https://www.theverge.com/2024/11/30/24309697/e...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's legal team has filed a motion to p...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Legal]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERPLEXITY MULLS GETTING INTO HARDWARE</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/perplexity-m...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Perplexity's CEO plans to develop a \"simple, u...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/inflection-c...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Inflection AI shifted its focus from developin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...</td>\n",
       "      <td>https://www.primeintellect.ai/blog/intellect-1...</td>\n",
       "      <td>www.primeintellect.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>INTELLECT-1 is a 10B parameter model trained o...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model Training, Evaluation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DETECT AND LEARN UNSEEN OBJECTS</td>\n",
       "      <td>https://arxiv.org/abs/2411.18207v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This new framework pushes object detection int...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAKING UNDERWATER IMAGES CLEAR</td>\n",
       "      <td>https://arxiv.org/abs/2411.18296v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>HUPE is an AI-powered method that improves und...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID</td>\n",
       "      <td>https://research.google/blog/mapping-the-ionos...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Google researchers were able to accurately map...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Google]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTRODUCING LTNTORCH</td>\n",
       "      <td>https://arxiv.org/abs/2409.16045v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Logic Tensor Networks (LTN) merge deep learnin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, ML&amp;DL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REFINING PRETRAINING DATA PROGRAMMATICALLY</td>\n",
       "      <td>https://gair-nlp.github.io/ProX/homepage.html</td>\n",
       "      <td>gair-nlp.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>ProX is a framework that treats data refinemen...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Model Training]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHATS WITH VIDEOS IN REAL TIME</td>\n",
       "      <td>https://huggingface.co/wangyueqian/MMDuet</td>\n",
       "      <td>huggingface.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>MMDuet is a novel \"video-text duet\" interactio...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...</td>\n",
       "      <td>https://calpaterson.com/porter.html</td>\n",
       "      <td>calpaterson.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>LLM makers like OpenAI face significant challe...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Funding]</td>\n",
       "      <td>[OpenAI, NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROX</td>\n",
       "      <td>https://www.notboring.co/p/rox</td>\n",
       "      <td>www.notboring.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>A new AI-native CRM, Rox, aims to disrupt Sale...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...</td>\n",
       "      <td>https://blog.play.ai/blog/21m-funding</td>\n",
       "      <td>blog.play.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PlayAI raised $21 Million to advance voice-fir...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...</td>\n",
       "      <td>https://www.theverge.com/2024/11/26/24306575/a...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Anthropic's Claude AI now offers customizable ...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Anthropic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CONVERTING GPT TO LLAMA</td>\n",
       "      <td>https://github.com/rasbt/LLMs-from-scratch/tre...</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This repository contains code for converting a...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL</td>\n",
       "      <td>https://oodaloop.com/briefs/technology/alibaba...</td>\n",
       "      <td>oodaloop.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Alibaba has released QwQ-32B-Preview, an ‚Äòopen...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/ai2-releases...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Ai2 has released OLMo 2, an open-source langua...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training, Funding]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XAI COULD SOON HAVE ITS OWN APP</td>\n",
       "      <td>https://www.theverge.com/2024/11/27/24307571/x...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's xAI plans to launch a standalone a...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Conversational AI, RAI]</td>\n",
       "      <td>[OpenAI, Anthropic, Google, Twitter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>THUNDERKITTENS FOR APPLE SILICON</td>\n",
       "      <td>https://hazyresearch.stanford.edu/blog/2024-11...</td>\n",
       "      <td>hazyresearch.stanford.edu</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Hazy Research has been critical in improving h...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...</td>\n",
       "      <td>https://arxiv.org/abs/2411.15139</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Diffusion models for End-to-End driving of aut...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Self-Driving Cars]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION</td>\n",
       "      <td>https://arxiv.org/abs/2411.17106v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PassionSR introduces an approach that makes di...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FINE-GRAINED IMAGE QUALITY ASSESSMENT</td>\n",
       "      <td>https://zhengchen1999.github.io/Grounding-IQA-...</td>\n",
       "      <td>zhengchen1999.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Grounding-IQA is a new approach to image quali...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...</td>\n",
       "      <td>https://spectrum.ieee.org/jailbreak-llm</td>\n",
       "      <td>spectrum.ieee.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>RoboPAIR is an algorithm that successfully jai...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Evaluation, Robotics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS</td>\n",
       "      <td>https://blogs.nvidia.com/blog/fugatto-gen-ai-s...</td>\n",
       "      <td>blogs.nvidia.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Fugatto, a new generative AI model, allows use...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training]</td>\n",
       "      <td>[NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE NEW AI SCALING LAW SHELL GAME</td>\n",
       "      <td>https://garymarcus.substack.com/p/a-new-ai-sca...</td>\n",
       "      <td>garymarcus.substack.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Recent shifts in AI scaling laws reveal limita...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Microsoft]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HUMAN IMAGE ANIMATION</td>\n",
       "      <td>https://francis-rings.github.io/StableAnimator/</td>\n",
       "      <td>francis-rings.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>StableAnimator introduces a breakthrough in hu...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...   \n",
       "1              PERPLEXITY MULLS GETTING INTO HARDWARE   \n",
       "2   INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...   \n",
       "3   INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...   \n",
       "4                     DETECT AND LEARN UNSEEN OBJECTS   \n",
       "5                      MAKING UNDERWATER IMAGES CLEAR   \n",
       "6    MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID   \n",
       "7                                INTRODUCING LTNTORCH   \n",
       "8          REFINING PRETRAINING DATA PROGRAMMATICALLY   \n",
       "9                      CHATS WITH VIDEOS IN REAL TIME   \n",
       "10  BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...   \n",
       "11                                                ROX   \n",
       "12  PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...   \n",
       "13  ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...   \n",
       "14                            CONVERTING GPT TO LLAMA   \n",
       "15   ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL   \n",
       "16  AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...   \n",
       "17                    XAI COULD SOON HAVE ITS OWN APP   \n",
       "18                   THUNDERKITTENS FOR APPLE SILICON   \n",
       "19  DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...   \n",
       "20         SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION   \n",
       "21              FINE-GRAINED IMAGE QUALITY ASSESSMENT   \n",
       "22  IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...   \n",
       "23         WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS   \n",
       "24                  THE NEW AI SCALING LAW SHELL GAME   \n",
       "25                              HUMAN IMAGE ANIMATION   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.theverge.com/2024/11/30/24309697/e...   \n",
       "1   https://techcrunch.com/2024/11/26/perplexity-m...   \n",
       "2   https://techcrunch.com/2024/11/26/inflection-c...   \n",
       "3   https://www.primeintellect.ai/blog/intellect-1...   \n",
       "4                  https://arxiv.org/abs/2411.18207v1   \n",
       "5                  https://arxiv.org/abs/2411.18296v1   \n",
       "6   https://research.google/blog/mapping-the-ionos...   \n",
       "7                  https://arxiv.org/abs/2409.16045v1   \n",
       "8       https://gair-nlp.github.io/ProX/homepage.html   \n",
       "9           https://huggingface.co/wangyueqian/MMDuet   \n",
       "10                https://calpaterson.com/porter.html   \n",
       "11                     https://www.notboring.co/p/rox   \n",
       "12              https://blog.play.ai/blog/21m-funding   \n",
       "13  https://www.theverge.com/2024/11/26/24306575/a...   \n",
       "14  https://github.com/rasbt/LLMs-from-scratch/tre...   \n",
       "15  https://oodaloop.com/briefs/technology/alibaba...   \n",
       "16  https://techcrunch.com/2024/11/26/ai2-releases...   \n",
       "17  https://www.theverge.com/2024/11/27/24307571/x...   \n",
       "18  https://hazyresearch.stanford.edu/blog/2024-11...   \n",
       "19                   https://arxiv.org/abs/2411.15139   \n",
       "20                 https://arxiv.org/abs/2411.17106v1   \n",
       "21  https://zhengchen1999.github.io/Grounding-IQA-...   \n",
       "22            https://spectrum.ieee.org/jailbreak-llm   \n",
       "23  https://blogs.nvidia.com/blog/fugatto-gen-ai-s...   \n",
       "24  https://garymarcus.substack.com/p/a-new-ai-sca...   \n",
       "25    https://francis-rings.github.io/StableAnimator/   \n",
       "\n",
       "                news_provider                source_of_the_news text  \\\n",
       "0            www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "1              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "2              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "3       www.primeintellect.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "4                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "5                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "6             research.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "7                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "8          gair-nlp.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "9              huggingface.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "10            calpaterson.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "11           www.notboring.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "12               blog.play.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "13           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "14                 github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "15               oodaloop.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "16             techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "17           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "18  hazyresearch.stanford.edu  TLDR AI <dan@tldrnewsletter.com>        \n",
       "19                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "20                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "21    zhengchen1999.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "22          spectrum.ieee.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "23           blogs.nvidia.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "24    garymarcus.substack.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "25    francis-rings.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "\n",
       "                                         news_summary  \\\n",
       "0   Elon Musk's legal team has filed a motion to p...   \n",
       "1   Perplexity's CEO plans to develop a \"simple, u...   \n",
       "2   Inflection AI shifted its focus from developin...   \n",
       "3   INTELLECT-1 is a 10B parameter model trained o...   \n",
       "4   This new framework pushes object detection int...   \n",
       "5   HUPE is an AI-powered method that improves und...   \n",
       "6   Google researchers were able to accurately map...   \n",
       "7   Logic Tensor Networks (LTN) merge deep learnin...   \n",
       "8   ProX is a framework that treats data refinemen...   \n",
       "9   MMDuet is a novel \"video-text duet\" interactio...   \n",
       "10  LLM makers like OpenAI face significant challe...   \n",
       "11  A new AI-native CRM, Rox, aims to disrupt Sale...   \n",
       "12  PlayAI raised $21 Million to advance voice-fir...   \n",
       "13  Anthropic's Claude AI now offers customizable ...   \n",
       "14  This repository contains code for converting a...   \n",
       "15  Alibaba has released QwQ-32B-Preview, an ‚Äòopen...   \n",
       "16  Ai2 has released OLMo 2, an open-source langua...   \n",
       "17  Elon Musk's xAI plans to launch a standalone a...   \n",
       "18  Hazy Research has been critical in improving h...   \n",
       "19  Diffusion models for End-to-End driving of aut...   \n",
       "20  PassionSR introduces an approach that makes di...   \n",
       "21  Grounding-IQA is a new approach to image quali...   \n",
       "22  RoboPAIR is an algorithm that successfully jai...   \n",
       "23  Fugatto, a new generative AI model, allows use...   \n",
       "24  Recent shifts in AI scaling laws reveal limita...   \n",
       "25  StableAnimator introduces a breakthrough in hu...   \n",
       "\n",
       "                 date_source date_source_time_zone version  \\\n",
       "0  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "1  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "2  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "3  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "4  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "5  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "6  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "7  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "8  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "9  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "10 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "11 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "12 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "13 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "14 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "15 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "16 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "17 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "18 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "19 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "20 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "21 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "22 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "23 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "24 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "25 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "\n",
       "   competitive_intelligence                                      themes  \\\n",
       "0                        []                                     [Legal]   \n",
       "1                        []                      [AI&GenAI, Multimodal]   \n",
       "2                        []                           [AI&GenAI, Model]   \n",
       "3                        []                [Model Training, Evaluation]   \n",
       "4                        []                      [AI&GenAI, Multimodal]   \n",
       "5                        []                      [AI&GenAI, Multimodal]   \n",
       "6                        []                                          []   \n",
       "7                        []                              [Model, ML&DL]   \n",
       "8                        []                     [Model, Model Training]   \n",
       "9                        []                                  [AI&GenAI]   \n",
       "10                       []                  [AI&GenAI, Model, Funding]   \n",
       "11                       []                         [AI&GenAI, Funding]   \n",
       "12                       []             [AI&GenAI, Multimodal, Funding]   \n",
       "13                       []                                  [AI&GenAI]   \n",
       "14                       []                                  [AI&GenAI]   \n",
       "15                       []                                     [Model]   \n",
       "16                       []  [AI&GenAI, Model, Model Training, Funding]   \n",
       "17                       []                    [Conversational AI, RAI]   \n",
       "18                       []                                  [AI&GenAI]   \n",
       "19                       []                         [Self-Driving Cars]   \n",
       "20                       []                                          []   \n",
       "21                       []                                [Multimodal]   \n",
       "22                       []               [Model, Evaluation, Robotics]   \n",
       "23                       []           [AI&GenAI, Model, Model Training]   \n",
       "24                       []                                  [AI&GenAI]   \n",
       "25                       []                                          []   \n",
       "\n",
       "                     market_intelligence personalities  score_category_count  \\\n",
       "0                               [OpenAI]            []                     2   \n",
       "1                                     []            []                     2   \n",
       "2                                     []            []                     2   \n",
       "3                                     []            []                     2   \n",
       "4                                     []            []                     2   \n",
       "5                                     []            []                     2   \n",
       "6                               [Google]            []                     0   \n",
       "7                                     []            []                     2   \n",
       "8                                     []            []                     2   \n",
       "9                                     []            []                     1   \n",
       "10                      [OpenAI, NVIDIA]            []                     5   \n",
       "11                                    []            []                     2   \n",
       "12                                    []            []                     3   \n",
       "13                           [Anthropic]            []                     2   \n",
       "14                                [Meta]            []                     2   \n",
       "15                              [OpenAI]            []                     2   \n",
       "16                                [Meta]            []                     5   \n",
       "17  [OpenAI, Anthropic, Google, Twitter]            []                     6   \n",
       "18                                    []            []                     1   \n",
       "19                                    []            []                     1   \n",
       "20                                    []            []                     0   \n",
       "21                                    []            []                     1   \n",
       "22                                    []            []                     3   \n",
       "23                              [NVIDIA]            []                     4   \n",
       "24                           [Microsoft]            []                     2   \n",
       "25                                    []            []                     0   \n",
       "\n",
       "    unique_id  \n",
       "0          52  \n",
       "1          53  \n",
       "2          54  \n",
       "3          55  \n",
       "4          56  \n",
       "5          57  \n",
       "6          58  \n",
       "7          59  \n",
       "8          60  \n",
       "9          61  \n",
       "10         62  \n",
       "11         63  \n",
       "12         64  \n",
       "13         65  \n",
       "14         66  \n",
       "15         67  \n",
       "16         68  \n",
       "17         69  \n",
       "18         70  \n",
       "19         71  \n",
       "20         72  \n",
       "21         73  \n",
       "22         74  \n",
       "23         75  \n",
       "24         76  \n",
       "25         77  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fd706d-63d8-440b-a0e1-eff4db5a0298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:38:07.134278Z",
     "iopub.status.busy": "2025-01-12T04:38:07.133891Z",
     "iopub.status.idle": "2025-01-12T04:38:07.171724Z",
     "shell.execute_reply": "2025-01-12T04:38:07.169309Z",
     "shell.execute_reply.started": "2025-01-12T04:38:07.134246Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2024-12-02 09:29:42-05:00', '2024-11-29 09:16:46-05:00']\n",
       "Length: 2, dtype: datetime64[ns, US/Eastern]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"log/test.parquet\")\n",
    "df[\"date_source\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071782a3-2db7-422a-a9a5-c7a51a502bd4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Check that new df_news_stories get added to the existing one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2660e6c5-f442-4629-80a9-61a32d8be876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:19:05.270338Z",
     "iopub.status.busy": "2025-01-10T03:19:05.269702Z",
     "iopub.status.idle": "2025-01-10T03:19:26.474096Z",
     "shell.execute_reply": "2025-01-10T03:19:26.472804Z",
     "shell.execute_reply.started": "2025-01-10T03:19:05.270212Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-09 22:19:05,277 - googleapiclient.discovery_cache - INFO -- l.49: file_cache is only supported with oauth2client<4.0.0\n",
      "2025-01-09 22:19:05,283 - src.newsletters.main - INFO -- l.22: Query emails\n",
      "2025-01-09 22:19:05,284 - src.gmail - DEBUG -- l.49: Fetch email for sender TLDR AI <dan@tldrnewsletter.com> from 2024-12-04 until 2024-12-06.\n",
      "2025-01-09 22:19:05,287 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages?q=after%3A2024-12-04+before%3A2024-12-06+from%3ATLDR+AI+%3Cdan%40tldrnewsletter.com%3E&alt=json\n",
      "2025-01-09 22:19:05,288 - google_auth_httplib2 - DEBUG -- l.118: Making request: POST https://oauth2.googleapis.com/token\n",
      "2025-01-09 22:19:05,630 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/193972b2f775c6d2?alt=json\n",
      "2025-01-09 22:19:05,747 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/1939692c998b5f05?alt=json\n",
      "2025-01-09 22:19:05,843 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/1939206ea98a7077?alt=json\n",
      "2025-01-09 22:19:05,942 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://gmail.googleapis.com/gmail/v1/users/me/messages/193916d17f48a177?alt=json\n",
      "2025-01-09 22:19:06,057 - src.newsletters.main - INFO -- l.28: Using 1 sender(s): dict_keys(['TLDR AI <dan@tldrnewsletter.com>']).\n",
      "2025-01-09 22:19:06,058 - src.newsletters.main - DEBUG -- l.30: Found 2 emails from sender TLDR AI <dan@tldrnewsletter.com>\n",
      "2025-01-09 22:19:06,059 - src.newsletters.main - INFO -- l.33: Parsing emails to extract news stories\n",
      "2025-01-09 22:19:06,060 - src.newsletters.parser.tldr - DEBUG -- l.26: Parsing email: OpenAI 12 days of Shipmas üéÑ, Meta‚Äôs Nuclear Energy Plans ü™´, AWS Reinvent üéä\n",
      "2025-01-09 22:19:06,062 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): threadreaderapp.com:443\n",
      "2025-01-09 22:19:06,145 - urllib3.connectionpool - DEBUG -- l.546: https://threadreaderapp.com:443 \"HEAD /thread/1864335461268754712.html?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,149 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): sustainability.atmeta.com:443\n",
      "2025-01-09 22:19:06,242 - urllib3.connectionpool - DEBUG -- l.546: https://sustainability.atmeta.com:443 \"HEAD /blog/2024/12/03/accelerating-the-next-wave-of-nuclear-to-power-ai-innovation/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,246 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): aws.amazon.com:443\n",
      "2025-01-09 22:19:06,367 - urllib3.connectionpool - DEBUG -- l.546: https://aws.amazon.com:443 \"HEAD /blogs/aws/top-announcements-of-aws-reinvent-2024/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,371 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): deepmind.google:443\n",
      "2025-01-09 22:19:06,600 - urllib3.connectionpool - DEBUG -- l.546: https://deepmind.google:443 \"HEAD /discover/blog/genie-2-a-large-scale-foundation-world-model/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,604 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): motion-prompting.github.io:443\n",
      "2025-01-09 22:19:06,692 - urllib3.connectionpool - DEBUG -- l.546: https://motion-prompting.github.io:443 \"HEAD /?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,697 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): unsloth.ai:443\n",
      "2025-01-09 22:19:06,791 - urllib3.connectionpool - DEBUG -- l.546: https://unsloth.ai:443 \"HEAD /blog/dynamic-4bit?utm_source=tldrai HTTP/11\" 403 0\n",
      "2025-01-09 22:19:06,795 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): research.character.ai:443\n",
      "2025-01-09 22:19:06,885 - urllib3.connectionpool - DEBUG -- l.546: https://research.character.ai:443 \"HEAD /optimizing-ai-inference-at-character-ai-part-deux/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:06,890 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arstechnica.com:443\n",
      "2025-01-09 22:19:07,214 - urllib3.connectionpool - DEBUG -- l.546: https://arstechnica.com:443 \"HEAD /information-technology/2024/12/certain-names-make-chatgpt-grind-to-a-halt-and-we-know-why/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:07,218 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): cameronrwolfe.substack.com:443\n",
      "2025-01-09 22:19:07,315 - urllib3.connectionpool - DEBUG -- l.546: https://cameronrwolfe.substack.com:443 \"HEAD /p/finetuned-judge?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:07,321 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): github.com:443\n",
      "2025-01-09 22:19:07,804 - urllib3.connectionpool - DEBUG -- l.546: https://github.com:443 \"HEAD /lmnr-ai/flow?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:07,811 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): stratechery.com:443\n",
      "2025-01-09 22:19:08,147 - urllib3.connectionpool - DEBUG -- l.546: https://stratechery.com:443 \"HEAD /2024/the-gen-ai-bridge-to-the-future/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:08,151 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): techcrunch.com:443\n",
      "2025-01-09 22:19:08,607 - urllib3.connectionpool - DEBUG -- l.546: https://techcrunch.com:443 \"HEAD /2024/12/02/world-labs-ai-can-generate-interactive-3d-scenes-from-a-single-photo/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:08,609 - src.newsletters.parser.tldr - DEBUG -- l.26: Parsing email: Eleven Labs Conversational AI ü§ñ, Amazon Nova üåê, Claude on AWS üíª\n",
      "2025-01-09 22:19:08,611 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): elevenlabs.io:443\n",
      "2025-01-09 22:19:09,620 - urllib3.connectionpool - DEBUG -- l.546: https://elevenlabs.io:443 \"HEAD /conversational-ai?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:09,623 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.anthropic.com:443\n",
      "2025-01-09 22:19:10,135 - urllib3.connectionpool - DEBUG -- l.546: https://www.anthropic.com:443 \"HEAD /news/trainium2-and-distillation?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:10,139 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): aws.amazon.com:443\n",
      "2025-01-09 22:19:10,486 - urllib3.connectionpool - DEBUG -- l.546: https://aws.amazon.com:443 \"HEAD /blogs/aws/introducing-amazon-nova-frontier-intelligence-and-industry-leading-price-performance/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:10,491 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): diffusionflow.github.io:443\n",
      "2025-01-09 22:19:10,690 - urllib3.connectionpool - DEBUG -- l.546: https://diffusionflow.github.io:443 \"HEAD /?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:10,694 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-01-09 22:19:11,029 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2410.06424?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:11,034 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): arxiv.org:443\n",
      "2025-01-09 22:19:11,368 - urllib3.connectionpool - DEBUG -- l.546: https://arxiv.org:443 \"HEAD /abs/2412.00381v1?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:11,371 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): foundationcapital.com:443\n",
      "2025-01-09 22:19:12,061 - urllib3.connectionpool - DEBUG -- l.546: https://foundationcapital.com:443 \"HEAD /system-of-agents/?utm_source=tldrai HTTP/11\" 403 0\n",
      "2025-01-09 22:19:12,068 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): www.rollingstone.com:443\n",
      "2025-01-09 22:19:12,322 - urllib3.connectionpool - DEBUG -- l.546: https://www.rollingstone.com:443 \"HEAD /music/music-features/ai-music-generator-new-model-suno-1235172581/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:12,326 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): techcrunch.com:443\n",
      "2025-01-09 22:19:12,443 - urllib3.connectionpool - DEBUG -- l.546: https://techcrunch.com:443 \"HEAD /2024/11/27/blueskys-open-api-means-anyone-can-scrape-your-data-for-ai-training/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:12,448 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): github.com:443\n",
      "2025-01-09 22:19:12,824 - urllib3.connectionpool - DEBUG -- l.546: https://github.com:443 \"HEAD /andrewyng/aisuite?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:12,828 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): originality.ai:443\n",
      "2025-01-09 22:19:13,007 - urllib3.connectionpool - DEBUG -- l.546: https://originality.ai:443 \"HEAD /blog/ai-content-published-linkedin?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:13,011 - urllib3.connectionpool - DEBUG -- l.1051: Starting new HTTPS connection (1): blog.google:443\n",
      "2025-01-09 22:19:13,154 - urllib3.connectionpool - DEBUG -- l.546: https://blog.google:443 \"HEAD /around-the-globe/google-europe/united-kingdom/google-launches-ai-campus-london/?utm_source=tldrai HTTP/11\" 200 0\n",
      "2025-01-09 22:19:13,157 - src.newsletters.main - INFO -- l.40: Newsletters block complete. Found 24 news stories.\n",
      "2025-01-09 22:19:13,158 - src.scoring.main - INFO -- l.18: Converting all news stories to a structured format.\n",
      "2025-01-09 22:19:13,694 - src.scoring.main - INFO -- l.22: Querying the metadata tags from Google Sheets.\n",
      "2025-01-09 22:19:13,697 - googleapiclient.discovery_cache - INFO -- l.49: file_cache is only supported with oauth2client<4.0.0\n",
      "2025-01-09 22:19:13,918 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/competitive_intelligence?alt=json\n",
      "2025-01-09 22:19:13,919 - google_auth_httplib2 - DEBUG -- l.118: Making request: POST https://oauth2.googleapis.com/token\n",
      "2025-01-09 22:19:14,402 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/themes?alt=json\n",
      "2025-01-09 22:19:14,683 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/market_intelligence?alt=json\n",
      "2025-01-09 22:19:14,847 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: GET https://sheets.googleapis.com/v4/spreadsheets/1AZhmfDyjbbX5tWJYRsziL4hlHVUhp8G3aYv0-o5VyDA/values/personalities?alt=json\n",
      "2025-01-09 22:19:26,410 - src.scoring.structured_news_stories - DEBUG -- l.96: col=competitive_intelligence, score_col=0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "Name: competitive_intelligence, dtype: int64\n",
      "2025-01-09 22:19:26,412 - src.scoring.structured_news_stories - DEBUG -- l.96: col=themes, score_col=0     0\n",
      "1     1\n",
      "2     1\n",
      "3     2\n",
      "4     2\n",
      "5     1\n",
      "6     2\n",
      "7     2\n",
      "8     3\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    2\n",
      "13    2\n",
      "14    1\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    2\n",
      "19    2\n",
      "20    3\n",
      "21    1\n",
      "22    1\n",
      "23    1\n",
      "Name: themes, dtype: int64\n",
      "2025-01-09 22:19:26,413 - src.scoring.structured_news_stories - DEBUG -- l.96: col=market_intelligence, score_col=0     1\n",
      "1     1\n",
      "2     1\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    1\n",
      "14    1\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    1\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "Name: market_intelligence, dtype: int64\n",
      "2025-01-09 22:19:26,415 - src.scoring.structured_news_stories - DEBUG -- l.96: col=personalities, score_col=0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "Name: personalities, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "news_stories_2 = runner_newsletters(after='2024-12-04', before='2024-12-06')\n",
    "df_news_stories_2, _ = runner_scoring(news_stories_2)\n",
    "runner_saving(df_news_stories_2, \"log/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2dacfd8-f39f-4521-9c56-dc90ad9d8c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:19:26.475091Z",
     "iopub.status.busy": "2025-01-10T03:19:26.474722Z",
     "iopub.status.idle": "2025-01-10T03:19:26.516470Z",
     "shell.execute_reply": "2025-01-10T03:19:26.515355Z",
     "shell.execute_reply.started": "2025-01-10T03:19:26.475069Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>news_provider</th>\n",
       "      <th>source_of_the_news</th>\n",
       "      <th>text</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>date_source</th>\n",
       "      <th>date_source_time_zone</th>\n",
       "      <th>competitive_intelligence</th>\n",
       "      <th>themes</th>\n",
       "      <th>market_intelligence</th>\n",
       "      <th>personalities</th>\n",
       "      <th>score</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPENAI 12 DAYS OF SHIPMAS</td>\n",
       "      <td>https://threadreaderapp.com/thread/18643354612...</td>\n",
       "      <td>threadreaderapp.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>OpenAI will be having 12 live streams over the...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>META'S NUCLEAR ENERGY PLANS</td>\n",
       "      <td>https://sustainability.atmeta.com/blog/2024/12...</td>\n",
       "      <td>sustainability.atmeta.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Meta announced plans to collaborate with nucle...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AWS REINVENT TOP ANNOUNCEMENTS</td>\n",
       "      <td>https://aws.amazon.com/blogs/aws/top-announcem...</td>\n",
       "      <td>aws.amazon.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>AWS announced various additions and tools incl...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[Amazon]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GENIE 2: A LARGE-SCALE FOUNDATION WORLD MODEL</td>\n",
       "      <td>https://deepmind.google/discover/blog/genie-2-...</td>\n",
       "      <td>deepmind.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Genie 2 is a large scale latent diffusion mode...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ML&amp;DL, Robotics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MOTION PROMPTING</td>\n",
       "      <td>https://motion-prompting.github.io/</td>\n",
       "      <td>motion-prompting.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Motion Prompting is a method that trains a vid...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model Training, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DYNAMIC 4-BIT QUANTIZATION</td>\n",
       "      <td>https://unsloth.ai/blog/dynamic-4bit</td>\n",
       "      <td>unsloth.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>The Unsloth team aims to shrink a 20GB languag...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPTIMIZING AI INFERENCE AT CHARACTER AI</td>\n",
       "      <td>https://research.character.ai/optimizing-ai-in...</td>\n",
       "      <td>research.character.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Character AI has a strong inference pipeline. ...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CERTAIN NAMES MAKE CHATGPT GRIND TO A HALT, AN...</td>\n",
       "      <td>https://arstechnica.com/information-technology...</td>\n",
       "      <td>arstechnica.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>OpenAI's ChatGPT employs hard-coded filters to...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Legal]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FINETUNING LLM JUDGES FOR EVALUATION</td>\n",
       "      <td>https://cameronrwolfe.substack.com/p/finetuned...</td>\n",
       "      <td>cameronrwolfe.substack.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Evaluating LLMs has become challenging due to ...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Model Training, Evaluation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FLOW</td>\n",
       "      <td>https://github.com/lmnr-ai/flow</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Flow is a lightweight engine for creating flex...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>THE GEN AI BRIDGE TO THE FUTURE</td>\n",
       "      <td>https://stratechery.com/2024/the-gen-ai-bridge...</td>\n",
       "      <td>stratechery.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Generative AI is set to revolutionize wearable...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>WORLD LABS' AI CAN GENERATE INTERACTIVE 3D SCE...</td>\n",
       "      <td>https://techcrunch.com/2024/12/02/world-labs-a...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>World Labs, founded by AI expert Fei-Fei Li, h...</td>\n",
       "      <td>2024-12-05 09:13:29-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ELEVEN LABS CONVERSATIONAL AI</td>\n",
       "      <td>https://elevenlabs.io/conversational-ai</td>\n",
       "      <td>elevenlabs.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Eleven Labs has launched a new conversational ...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Conversational AI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CLAUDE MODELS NOW FASTER AND SMARTER ON AWS TR...</td>\n",
       "      <td>https://www.anthropic.com/news/trainium2-and-d...</td>\n",
       "      <td>www.anthropic.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Claude models are being optimized for AWS' adv...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model Training]</td>\n",
       "      <td>[Amazon]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AMAZON LAUNCHES NOVA</td>\n",
       "      <td>https://aws.amazon.com/blogs/aws/introducing-a...</td>\n",
       "      <td>aws.amazon.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Amazon Nova introduces a suite of multimodal m...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multimodal]</td>\n",
       "      <td>[Amazon]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DIFFUSION MEETS FLOW MATCHING: TWO SIDES OF TH...</td>\n",
       "      <td>https://diffusionflow.github.io/</td>\n",
       "      <td>diffusionflow.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This post talks through some of the literature...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RESTRUCTURING VECTOR QUANTIZATION WITH THE ROT...</td>\n",
       "      <td>https://arxiv.org/abs/2410.06424</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Vector Quantization relies on gradient estimat...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LAYOUT GENERATION WITH DIFFUSION GANS</td>\n",
       "      <td>https://arxiv.org/abs/2412.00381v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>DogLayout is a hybrid model that combines GANs...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A SYSTEM OF AGENTS BRINGS SERVICE-AS-SOFTWARE ...</td>\n",
       "      <td>https://foundationcapital.com/system-of-agents/</td>\n",
       "      <td>foundationcapital.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>AI is transitioning software from a tool to au...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Agents]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI MUSIC IS MORE REALISTIC THAN EVER: MEET SUN...</td>\n",
       "      <td>https://www.rollingstone.com/music/music-featu...</td>\n",
       "      <td>www.rollingstone.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Suno has become the fifth most-used generative...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Legal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BLUESKY'S OPEN API MEANS ANYONE CAN SCRAPE YOU...</td>\n",
       "      <td>https://techcrunch.com/2024/11/27/blueskys-ope...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Bluesky isn't using user content to train AI, ...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model Training, ML&amp;DL]</td>\n",
       "      <td>[HF]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AISUITE</td>\n",
       "      <td>https://github.com/andrewyng/aisuite</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>aisuite provides a unified interface for seaml...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OVER ¬Ω OF LONG POSTS ON LINKEDIN ARE LIKELY AI...</td>\n",
       "      <td>https://originality.ai/blog/ai-content-publish...</td>\n",
       "      <td>originality.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Since ChatGPT's launch, LinkedIn has seen an 1...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GOOGLE LAUNCHES THE LONDON AI CAMPUS</td>\n",
       "      <td>https://blog.google/around-the-globe/google-eu...</td>\n",
       "      <td>blog.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>The AI Campus is an educational pilot to suppo...</td>\n",
       "      <td>2024-12-04 09:15:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                           OPENAI 12 DAYS OF SHIPMAS   \n",
       "1                         META'S NUCLEAR ENERGY PLANS   \n",
       "2                      AWS REINVENT TOP ANNOUNCEMENTS   \n",
       "3       GENIE 2: A LARGE-SCALE FOUNDATION WORLD MODEL   \n",
       "4                                    MOTION PROMPTING   \n",
       "5                          DYNAMIC 4-BIT QUANTIZATION   \n",
       "6             OPTIMIZING AI INFERENCE AT CHARACTER AI   \n",
       "7   CERTAIN NAMES MAKE CHATGPT GRIND TO A HALT, AN...   \n",
       "8                FINETUNING LLM JUDGES FOR EVALUATION   \n",
       "9                                                FLOW   \n",
       "10                    THE GEN AI BRIDGE TO THE FUTURE   \n",
       "11  WORLD LABS' AI CAN GENERATE INTERACTIVE 3D SCE...   \n",
       "12                      ELEVEN LABS CONVERSATIONAL AI   \n",
       "13  CLAUDE MODELS NOW FASTER AND SMARTER ON AWS TR...   \n",
       "14                               AMAZON LAUNCHES NOVA   \n",
       "15  DIFFUSION MEETS FLOW MATCHING: TWO SIDES OF TH...   \n",
       "16  RESTRUCTURING VECTOR QUANTIZATION WITH THE ROT...   \n",
       "17              LAYOUT GENERATION WITH DIFFUSION GANS   \n",
       "18  A SYSTEM OF AGENTS BRINGS SERVICE-AS-SOFTWARE ...   \n",
       "19  AI MUSIC IS MORE REALISTIC THAN EVER: MEET SUN...   \n",
       "20  BLUESKY'S OPEN API MEANS ANYONE CAN SCRAPE YOU...   \n",
       "21                                            AISUITE   \n",
       "22  OVER ¬Ω OF LONG POSTS ON LINKEDIN ARE LIKELY AI...   \n",
       "23               GOOGLE LAUNCHES THE LONDON AI CAMPUS   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://threadreaderapp.com/thread/18643354612...   \n",
       "1   https://sustainability.atmeta.com/blog/2024/12...   \n",
       "2   https://aws.amazon.com/blogs/aws/top-announcem...   \n",
       "3   https://deepmind.google/discover/blog/genie-2-...   \n",
       "4                 https://motion-prompting.github.io/   \n",
       "5                https://unsloth.ai/blog/dynamic-4bit   \n",
       "6   https://research.character.ai/optimizing-ai-in...   \n",
       "7   https://arstechnica.com/information-technology...   \n",
       "8   https://cameronrwolfe.substack.com/p/finetuned...   \n",
       "9                     https://github.com/lmnr-ai/flow   \n",
       "10  https://stratechery.com/2024/the-gen-ai-bridge...   \n",
       "11  https://techcrunch.com/2024/12/02/world-labs-a...   \n",
       "12            https://elevenlabs.io/conversational-ai   \n",
       "13  https://www.anthropic.com/news/trainium2-and-d...   \n",
       "14  https://aws.amazon.com/blogs/aws/introducing-a...   \n",
       "15                   https://diffusionflow.github.io/   \n",
       "16                   https://arxiv.org/abs/2410.06424   \n",
       "17                 https://arxiv.org/abs/2412.00381v1   \n",
       "18    https://foundationcapital.com/system-of-agents/   \n",
       "19  https://www.rollingstone.com/music/music-featu...   \n",
       "20  https://techcrunch.com/2024/11/27/blueskys-ope...   \n",
       "21               https://github.com/andrewyng/aisuite   \n",
       "22  https://originality.ai/blog/ai-content-publish...   \n",
       "23  https://blog.google/around-the-globe/google-eu...   \n",
       "\n",
       "                 news_provider                source_of_the_news text  \\\n",
       "0          threadreaderapp.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "1    sustainability.atmeta.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "2               aws.amazon.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "3              deepmind.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "4   motion-prompting.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "5                   unsloth.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "6        research.character.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "7              arstechnica.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "8   cameronrwolfe.substack.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "9                   github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "10             stratechery.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "11              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "12               elevenlabs.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "13           www.anthropic.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "14              aws.amazon.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "15     diffusionflow.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "16                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "17                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "18       foundationcapital.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "19        www.rollingstone.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "20              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "21                  github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "22              originality.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "23                 blog.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "\n",
       "                                         news_summary  \\\n",
       "0   OpenAI will be having 12 live streams over the...   \n",
       "1   Meta announced plans to collaborate with nucle...   \n",
       "2   AWS announced various additions and tools incl...   \n",
       "3   Genie 2 is a large scale latent diffusion mode...   \n",
       "4   Motion Prompting is a method that trains a vid...   \n",
       "5   The Unsloth team aims to shrink a 20GB languag...   \n",
       "6   Character AI has a strong inference pipeline. ...   \n",
       "7   OpenAI's ChatGPT employs hard-coded filters to...   \n",
       "8   Evaluating LLMs has become challenging due to ...   \n",
       "9   Flow is a lightweight engine for creating flex...   \n",
       "10  Generative AI is set to revolutionize wearable...   \n",
       "11  World Labs, founded by AI expert Fei-Fei Li, h...   \n",
       "12  Eleven Labs has launched a new conversational ...   \n",
       "13  Claude models are being optimized for AWS' adv...   \n",
       "14  Amazon Nova introduces a suite of multimodal m...   \n",
       "15  This post talks through some of the literature...   \n",
       "16  Vector Quantization relies on gradient estimat...   \n",
       "17  DogLayout is a hybrid model that combines GANs...   \n",
       "18  AI is transitioning software from a tool to au...   \n",
       "19  Suno has become the fifth most-used generative...   \n",
       "20  Bluesky isn't using user content to train AI, ...   \n",
       "21  aisuite provides a unified interface for seaml...   \n",
       "22  Since ChatGPT's launch, LinkedIn has seen an 1...   \n",
       "23  The AI Campus is an educational pilot to suppo...   \n",
       "\n",
       "                 date_source date_source_time_zone competitive_intelligence  \\\n",
       "0  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "1  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "2  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "3  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "4  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "5  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "6  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "7  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "8  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "9  2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "10 2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "11 2024-12-05 09:13:29-05:00            US/Eastern                       []   \n",
       "12 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "13 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "14 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "15 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "16 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "17 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "18 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "19 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "20 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "21 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "22 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "23 2024-12-04 09:15:46-05:00            US/Eastern                       []   \n",
       "\n",
       "                                 themes market_intelligence personalities  \\\n",
       "0                                    []            [OpenAI]            []   \n",
       "1                            [AI&GenAI]              [Meta]            []   \n",
       "2                               [Model]            [Amazon]            []   \n",
       "3                     [ML&DL, Robotics]                  []            []   \n",
       "4          [Model Training, Multimodal]                  []            []   \n",
       "5                               [Model]                  []            []   \n",
       "6                     [AI&GenAI, Model]                  []            []   \n",
       "7                     [AI&GenAI, Legal]            [OpenAI]            []   \n",
       "8   [Model, Model Training, Evaluation]                  []            []   \n",
       "9                            [AI&GenAI]                  []            []   \n",
       "10                           [AI&GenAI]                  []            []   \n",
       "11                           [AI&GenAI]                  []            []   \n",
       "12        [AI&GenAI, Conversational AI]                  []            []   \n",
       "13           [AI&GenAI, Model Training]            [Amazon]            []   \n",
       "14                         [Multimodal]            [Amazon]            []   \n",
       "15                                   []                  []            []   \n",
       "16                                   []                  []            []   \n",
       "17                                   []                  []            []   \n",
       "18                   [AI&GenAI, Agents]                  []            []   \n",
       "19                    [AI&GenAI, Legal]                  []            []   \n",
       "20    [AI&GenAI, Model Training, ML&DL]                [HF]            []   \n",
       "21                              [Model]                  []            []   \n",
       "22                           [AI&GenAI]                  []            []   \n",
       "23                           [AI&GenAI]                  []            []   \n",
       "\n",
       "    score  unique_id  \n",
       "0       0         54  \n",
       "1       2         55  \n",
       "2       2         56  \n",
       "3       2         57  \n",
       "4       2         58  \n",
       "5       1         59  \n",
       "6       2         60  \n",
       "7       3         61  \n",
       "8       3         62  \n",
       "9       1         63  \n",
       "10      1         64  \n",
       "11      1         65  \n",
       "12      2         66  \n",
       "13      3         67  \n",
       "14      2         68  \n",
       "15      0         69  \n",
       "16      0         70  \n",
       "17      0         71  \n",
       "18      2         72  \n",
       "19      2         73  \n",
       "20      4         74  \n",
       "21      1         75  \n",
       "22      1         76  \n",
       "23      1         77  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_stories_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f976cf7b-5279-45d0-9ee9-7d99a0acd5e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:19:26.517701Z",
     "iopub.status.busy": "2025-01-10T03:19:26.517352Z",
     "iopub.status.idle": "2025-01-10T03:19:26.538200Z",
     "shell.execute_reply": "2025-01-10T03:19:26.537065Z",
     "shell.execute_reply.started": "2025-01-10T03:19:26.517658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2024-12-02 09:29:42-05:00', '2024-12-05 09:13:29-05:00',\n",
       " '2024-12-04 09:15:46-05:00']\n",
       "Length: 3, dtype: datetime64[ns, US/Eastern]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"log/test.parquet\")\n",
    "df[\"date_source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44a752e-e3cf-4c57-9912-8bb56308a718",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:19:26.539959Z",
     "iopub.status.busy": "2025-01-10T03:19:26.539189Z",
     "iopub.status.idle": "2025-01-10T03:19:26.552951Z",
     "shell.execute_reply": "2025-01-10T03:19:26.551084Z",
     "shell.execute_reply.started": "2025-01-10T03:19:26.539815Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      2\n",
       "3      3\n",
       "4      4\n",
       "      ..\n",
       "73    73\n",
       "74    74\n",
       "75    75\n",
       "76    76\n",
       "77    77\n",
       "Name: unique_id, Length: 78, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "df[\"unique_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c5e256-d28c-4064-a8cf-bc71fe785e50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18bce677-e9d4-4cb6-aedd-32756f242a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:20:36.738689Z",
     "iopub.status.busy": "2025-01-10T03:20:36.738291Z",
     "iopub.status.idle": "2025-01-10T03:20:36.757886Z",
     "shell.execute_reply": "2025-01-10T03:20:36.755834Z",
     "shell.execute_reply.started": "2025-01-10T03:20:36.738661Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2024-12-02 09:29:42-05:00', '2024-12-05 09:13:29-05:00',\n",
       " '2024-12-04 09:15:46-05:00']\n",
       "Length: 3, dtype: datetime64[ns, US/Eastern]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.saving.database import Database\n",
    "db = Database(\"log/test.parquet\")\n",
    "db.db[\"date_source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e47a853-7a58-49da-8425-5011c618f9b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T03:20:23.582282Z",
     "iopub.status.busy": "2025-01-10T03:20:23.581923Z",
     "iopub.status.idle": "2025-01-10T03:20:23.593127Z",
     "shell.execute_reply": "2025-01-10T03:20:23.592026Z",
     "shell.execute_reply.started": "2025-01-10T03:20:23.582257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatetimeArray>\n",
       "['2024-12-04 09:15:46-05:00']\n",
       "Length: 1, dtype: datetime64[ns, US/Eastern]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp = db.get_data_from_range_dates(\"2024-12-03\", \"2024-12-04\")\n",
    "df_tmp[\"date_source\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362df4c4-40d6-4404-9e9f-90c694c98f31",
   "metadata": {},
   "source": [
    "# Reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272c9ca7-24f6-4811-b066-9b3bf18aaf4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:42:03.001788Z",
     "iopub.status.busy": "2025-02-05T04:42:03.001435Z",
     "iopub.status.idle": "2025-02-05T04:42:03.074357Z",
     "shell.execute_reply": "2025-02-05T04:42:03.072328Z",
     "shell.execute_reply.started": "2025-02-05T04:42:03.001759Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>news_provider</th>\n",
       "      <th>source_of_the_news</th>\n",
       "      <th>text</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>date_source</th>\n",
       "      <th>date_source_time_zone</th>\n",
       "      <th>version</th>\n",
       "      <th>competitive_intelligence</th>\n",
       "      <th>themes</th>\n",
       "      <th>market_intelligence</th>\n",
       "      <th>personalities</th>\n",
       "      <th>score_category_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...</td>\n",
       "      <td>https://www.theverge.com/2024/11/30/24309697/e...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's legal team has filed a motion to p...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Legal]</td>\n",
       "      <td>[OpenAI, Twitter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERPLEXITY MULLS GETTING INTO HARDWARE</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/perplexity-m...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Perplexity's CEO plans to develop a \"simple, u...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal, Funding]</td>\n",
       "      <td>[Perplexity]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/inflection-c...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Inflection AI shifted its focus from developin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...</td>\n",
       "      <td>https://www.primeintellect.ai/blog/intellect-1...</td>\n",
       "      <td>www.primeintellect.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>INTELLECT-1 is a 10B parameter model trained o...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model Training, Evaluation]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DETECT AND LEARN UNSEEN OBJECTS</td>\n",
       "      <td>https://arxiv.org/abs/2411.18207v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This new framework pushes object detection int...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAKING UNDERWATER IMAGES CLEAR</td>\n",
       "      <td>https://arxiv.org/abs/2411.18296v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>HUPE is an AI-powered method that improves und...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID</td>\n",
       "      <td>https://research.google/blog/mapping-the-ionos...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Google researchers were able to accurately map...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Google]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTRODUCING LTNTORCH</td>\n",
       "      <td>https://arxiv.org/abs/2409.16045v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Logic Tensor Networks (LTN) merge deep learnin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, ML&amp;DL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REFINING PRETRAINING DATA PROGRAMMATICALLY</td>\n",
       "      <td>https://gair-nlp.github.io/ProX/homepage.html</td>\n",
       "      <td>gair-nlp.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>ProX is a framework that treats data refinemen...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Model Training]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHATS WITH VIDEOS IN REAL TIME</td>\n",
       "      <td>https://huggingface.co/wangyueqian/MMDuet</td>\n",
       "      <td>huggingface.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>MMDuet is a novel \"video-text duet\" interactio...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...</td>\n",
       "      <td>https://calpaterson.com/porter.html</td>\n",
       "      <td>calpaterson.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>LLM makers like OpenAI face significant challe...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Funding]</td>\n",
       "      <td>[OpenAI, NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROX</td>\n",
       "      <td>https://www.notboring.co/p/rox</td>\n",
       "      <td>www.notboring.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>A new AI-native CRM, Rox, aims to disrupt Sale...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...</td>\n",
       "      <td>https://blog.play.ai/blog/21m-funding</td>\n",
       "      <td>blog.play.ai</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PlayAI raised $21 Million to advance voice-fir...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal, Funding]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...</td>\n",
       "      <td>https://www.theverge.com/2024/11/26/24306575/a...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Anthropic's Claude AI now offers customizable ...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Anthropic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CONVERTING GPT TO LLAMA</td>\n",
       "      <td>https://github.com/rasbt/LLMs-from-scratch/tre...</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This repository contains code for converting a...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL</td>\n",
       "      <td>https://oodaloop.com/briefs/technology/alibaba...</td>\n",
       "      <td>oodaloop.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Alibaba has released QwQ-32B-Preview, an ‚Äòopen...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/ai2-releases...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Ai2 has released OLMo 2, an open-source langua...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training, Funding]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>XAI COULD SOON HAVE ITS OWN APP</td>\n",
       "      <td>https://www.theverge.com/2024/11/27/24307571/x...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's xAI plans to launch a standalone a...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Conversational AI, RAI]</td>\n",
       "      <td>[OpenAI, Anthropic, Google, Twitter]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>THUNDERKITTENS FOR APPLE SILICON</td>\n",
       "      <td>https://hazyresearch.stanford.edu/blog/2024-11...</td>\n",
       "      <td>hazyresearch.stanford.edu</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Hazy Research has been critical in improving h...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...</td>\n",
       "      <td>https://arxiv.org/abs/2411.15139</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Diffusion models for End-to-End driving of aut...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Self-Driving Cars]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION</td>\n",
       "      <td>https://arxiv.org/abs/2411.17106v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PassionSR introduces an approach that makes di...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FINE-GRAINED IMAGE QUALITY ASSESSMENT</td>\n",
       "      <td>https://zhengchen1999.github.io/Grounding-IQA-...</td>\n",
       "      <td>zhengchen1999.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Grounding-IQA is a new approach to image quali...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...</td>\n",
       "      <td>https://spectrum.ieee.org/jailbreak-llm</td>\n",
       "      <td>spectrum.ieee.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>RoboPAIR is an algorithm that successfully jai...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Evaluation, Robotics]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS</td>\n",
       "      <td>https://blogs.nvidia.com/blog/fugatto-gen-ai-s...</td>\n",
       "      <td>blogs.nvidia.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Fugatto, a new generative AI model, allows use...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model, Model Training]</td>\n",
       "      <td>[NVIDIA]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE NEW AI SCALING LAW SHELL GAME</td>\n",
       "      <td>https://garymarcus.substack.com/p/a-new-ai-sca...</td>\n",
       "      <td>garymarcus.substack.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Recent shifts in AI scaling laws reveal limita...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Microsoft]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HUMAN IMAGE ANIMATION</td>\n",
       "      <td>https://francis-rings.github.io/StableAnimator/</td>\n",
       "      <td>francis-rings.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>StableAnimator introduces a breakthrough in hu...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...   \n",
       "1              PERPLEXITY MULLS GETTING INTO HARDWARE   \n",
       "2   INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...   \n",
       "3   INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINE...   \n",
       "4                     DETECT AND LEARN UNSEEN OBJECTS   \n",
       "5                      MAKING UNDERWATER IMAGES CLEAR   \n",
       "6    MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID   \n",
       "7                                INTRODUCING LTNTORCH   \n",
       "8          REFINING PRETRAINING DATA PROGRAMMATICALLY   \n",
       "9                      CHATS WITH VIDEOS IN REAL TIME   \n",
       "10  BUILDING LLMS IS PROBABLY NOT GOING BE A BRILL...   \n",
       "11                                                ROX   \n",
       "12  PLAYAI RAISES $21M FUNDING AND RELEASES A NEW ...   \n",
       "13  ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...   \n",
       "14                            CONVERTING GPT TO LLAMA   \n",
       "15   ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL   \n",
       "16  AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE W...   \n",
       "17                    XAI COULD SOON HAVE ITS OWN APP   \n",
       "18                   THUNDERKITTENS FOR APPLE SILICON   \n",
       "19  DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...   \n",
       "20         SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION   \n",
       "21              FINE-GRAINED IMAGE QUALITY ASSESSMENT   \n",
       "22  IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN...   \n",
       "23         WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS   \n",
       "24                  THE NEW AI SCALING LAW SHELL GAME   \n",
       "25                              HUMAN IMAGE ANIMATION   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.theverge.com/2024/11/30/24309697/e...   \n",
       "1   https://techcrunch.com/2024/11/26/perplexity-m...   \n",
       "2   https://techcrunch.com/2024/11/26/inflection-c...   \n",
       "3   https://www.primeintellect.ai/blog/intellect-1...   \n",
       "4                  https://arxiv.org/abs/2411.18207v1   \n",
       "5                  https://arxiv.org/abs/2411.18296v1   \n",
       "6   https://research.google/blog/mapping-the-ionos...   \n",
       "7                  https://arxiv.org/abs/2409.16045v1   \n",
       "8       https://gair-nlp.github.io/ProX/homepage.html   \n",
       "9           https://huggingface.co/wangyueqian/MMDuet   \n",
       "10                https://calpaterson.com/porter.html   \n",
       "11                     https://www.notboring.co/p/rox   \n",
       "12              https://blog.play.ai/blog/21m-funding   \n",
       "13  https://www.theverge.com/2024/11/26/24306575/a...   \n",
       "14  https://github.com/rasbt/LLMs-from-scratch/tre...   \n",
       "15  https://oodaloop.com/briefs/technology/alibaba...   \n",
       "16  https://techcrunch.com/2024/11/26/ai2-releases...   \n",
       "17  https://www.theverge.com/2024/11/27/24307571/x...   \n",
       "18  https://hazyresearch.stanford.edu/blog/2024-11...   \n",
       "19                   https://arxiv.org/abs/2411.15139   \n",
       "20                 https://arxiv.org/abs/2411.17106v1   \n",
       "21  https://zhengchen1999.github.io/Grounding-IQA-...   \n",
       "22            https://spectrum.ieee.org/jailbreak-llm   \n",
       "23  https://blogs.nvidia.com/blog/fugatto-gen-ai-s...   \n",
       "24  https://garymarcus.substack.com/p/a-new-ai-sca...   \n",
       "25    https://francis-rings.github.io/StableAnimator/   \n",
       "\n",
       "                news_provider                source_of_the_news text  \\\n",
       "0            www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "1              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "2              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "3       www.primeintellect.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "4                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "5                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "6             research.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "7                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "8          gair-nlp.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "9              huggingface.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "10            calpaterson.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "11           www.notboring.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "12               blog.play.ai  TLDR AI <dan@tldrnewsletter.com>        \n",
       "13           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "14                 github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "15               oodaloop.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "16             techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "17           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "18  hazyresearch.stanford.edu  TLDR AI <dan@tldrnewsletter.com>        \n",
       "19                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "20                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "21    zhengchen1999.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "22          spectrum.ieee.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "23           blogs.nvidia.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "24    garymarcus.substack.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "25    francis-rings.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "\n",
       "                                         news_summary  \\\n",
       "0   Elon Musk's legal team has filed a motion to p...   \n",
       "1   Perplexity's CEO plans to develop a \"simple, u...   \n",
       "2   Inflection AI shifted its focus from developin...   \n",
       "3   INTELLECT-1 is a 10B parameter model trained o...   \n",
       "4   This new framework pushes object detection int...   \n",
       "5   HUPE is an AI-powered method that improves und...   \n",
       "6   Google researchers were able to accurately map...   \n",
       "7   Logic Tensor Networks (LTN) merge deep learnin...   \n",
       "8   ProX is a framework that treats data refinemen...   \n",
       "9   MMDuet is a novel \"video-text duet\" interactio...   \n",
       "10  LLM makers like OpenAI face significant challe...   \n",
       "11  A new AI-native CRM, Rox, aims to disrupt Sale...   \n",
       "12  PlayAI raised $21 Million to advance voice-fir...   \n",
       "13  Anthropic's Claude AI now offers customizable ...   \n",
       "14  This repository contains code for converting a...   \n",
       "15  Alibaba has released QwQ-32B-Preview, an ‚Äòopen...   \n",
       "16  Ai2 has released OLMo 2, an open-source langua...   \n",
       "17  Elon Musk's xAI plans to launch a standalone a...   \n",
       "18  Hazy Research has been critical in improving h...   \n",
       "19  Diffusion models for End-to-End driving of aut...   \n",
       "20  PassionSR introduces an approach that makes di...   \n",
       "21  Grounding-IQA is a new approach to image quali...   \n",
       "22  RoboPAIR is an algorithm that successfully jai...   \n",
       "23  Fugatto, a new generative AI model, allows use...   \n",
       "24  Recent shifts in AI scaling laws reveal limita...   \n",
       "25  StableAnimator introduces a breakthrough in hu...   \n",
       "\n",
       "                 date_source date_source_time_zone version  \\\n",
       "0  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "1  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "2  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "3  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "4  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "5  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "6  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "7  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "8  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "9  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "10 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "11 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "12 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "13 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "14 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "15 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "16 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "17 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "18 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "19 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "20 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "21 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "22 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "23 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "24 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "25 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "\n",
       "   competitive_intelligence                                      themes  \\\n",
       "0                        []                                     [Legal]   \n",
       "1                        []             [AI&GenAI, Multimodal, Funding]   \n",
       "2                        []                  [AI&GenAI, Model, Funding]   \n",
       "3                        []                [Model Training, Evaluation]   \n",
       "4                        []                      [AI&GenAI, Multimodal]   \n",
       "5                        []                      [AI&GenAI, Multimodal]   \n",
       "6                        []                                          []   \n",
       "7                        []                              [Model, ML&DL]   \n",
       "8                        []                     [Model, Model Training]   \n",
       "9                        []                                  [AI&GenAI]   \n",
       "10                       []                  [AI&GenAI, Model, Funding]   \n",
       "11                       []                         [AI&GenAI, Funding]   \n",
       "12                       []             [AI&GenAI, Multimodal, Funding]   \n",
       "13                       []                                  [AI&GenAI]   \n",
       "14                       []                                  [AI&GenAI]   \n",
       "15                       []                                     [Model]   \n",
       "16                       []  [AI&GenAI, Model, Model Training, Funding]   \n",
       "17                       []                    [Conversational AI, RAI]   \n",
       "18                       []                                  [AI&GenAI]   \n",
       "19                       []                         [Self-Driving Cars]   \n",
       "20                       []                                          []   \n",
       "21                       []                                [Multimodal]   \n",
       "22                       []               [Model, Evaluation, Robotics]   \n",
       "23                       []           [AI&GenAI, Model, Model Training]   \n",
       "24                       []                                  [AI&GenAI]   \n",
       "25                       []                                          []   \n",
       "\n",
       "                     market_intelligence personalities  score_category_count  \n",
       "0                      [OpenAI, Twitter]            []                     3  \n",
       "1                           [Perplexity]            []                     4  \n",
       "2                                     []            []                     3  \n",
       "3                                     []            []                     2  \n",
       "4                                     []            []                     2  \n",
       "5                                     []            []                     2  \n",
       "6                               [Google]            []                     0  \n",
       "7                                     []            []                     2  \n",
       "8                                     []            []                     2  \n",
       "9                                     []            []                     1  \n",
       "10                      [OpenAI, NVIDIA]            []                     5  \n",
       "11                                    []            []                     2  \n",
       "12                                    []            []                     3  \n",
       "13                           [Anthropic]            []                     2  \n",
       "14                                [Meta]            []                     2  \n",
       "15                              [OpenAI]            []                     2  \n",
       "16                                [Meta]            []                     5  \n",
       "17  [OpenAI, Anthropic, Google, Twitter]            []                     6  \n",
       "18                                    []            []                     1  \n",
       "19                                    []            []                     1  \n",
       "20                                    []            []                     0  \n",
       "21                                    []            []                     1  \n",
       "22                                    []            []                     3  \n",
       "23                              [NVIDIA]            []                     4  \n",
       "24                           [Microsoft]            []                     2  \n",
       "25                                    []            []                     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d54c3d2-bb26-4e3b-84b5-0e3409aeddf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T04:42:10.993199Z",
     "iopub.status.busy": "2025-02-05T04:42:10.992776Z",
     "iopub.status.idle": "2025-02-05T04:43:07.704562Z",
     "shell.execute_reply": "2025-02-05T04:43:07.702957Z",
     "shell.execute_reply.started": "2025-02-05T04:42:10.993168Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:42:10,994 - src.reporting.report - INFO -- l.59: Will generate report for range 2024-11-29 to 2024-12-02\n",
      "2025-02-04 23:42:10,997 - src.reporting.report - INFO -- l.214: Target fields were successfully verified.\n",
      "2025-02-04 23:42:10,998 - src.reporting.report - INFO -- l.178: We'll use the news stories provided by the dataframe.\n",
      "2025-02-04 23:42:10,999 - src.reporting.report - DEBUG -- l.180: Column score_category_count found in df_scored_news_stories.\n",
      "2025-02-04 23:42:11,000 - src.reporting.report - INFO -- l.73: Found 26 candidate news stories for this report.\n",
      "2025-02-04 23:42:11,005 - src.genai_model.genai_model - INFO -- l.92: Found 13 models for model_type large\n",
      "2025-02-04 23:42:11,007 - src.genai_model.genai_model - INFO -- l.95: List of models included: ['gemini/gemini-exp-1206', 'openrouter/google/gemini-exp-1206:free', 'gemini/gemini-exp-1121', 'openrouter/google/gemini-exp-1121:free', 'gemini/gemini-exp-1114', 'openrouter/google/gemini-exp-1114:free', 'gemini/gemini-1.5-pro-002', 'gemini/gemini-1.5-pro-exp-0827', 'openrouter/meta-llama/llama-3.1-405b-instruct:free', 'gemini/gemini-1.5-pro-001', 'mistral/mistral-large-2411', 'mistral/mistral-large-2407', 'mistral/mistral-large-2402']\n",
      "2025-02-04 23:42:11,009 - src.genai_model.genai_model - INFO -- l.92: Found 13 models for model_type large\n",
      "2025-02-04 23:42:11,010 - src.genai_model.genai_model - INFO -- l.95: List of models included: ['gemini/gemini-exp-1206', 'openrouter/google/gemini-exp-1206:free', 'gemini/gemini-exp-1121', 'openrouter/google/gemini-exp-1121:free', 'gemini/gemini-exp-1114', 'openrouter/google/gemini-exp-1114:free', 'gemini/gemini-1.5-pro-002', 'gemini/gemini-1.5-pro-exp-0827', 'openrouter/meta-llama/llama-3.1-405b-instruct:free', 'gemini/gemini-1.5-pro-001', 'mistral/mistral-large-2411', 'mistral/mistral-large-2407', 'mistral/mistral-large-2402']\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:11,015 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:11,018 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:11,020 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:11,023 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:11,025 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:11,027 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:11 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:11,036 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:11,038 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:11,040 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:11,042 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:11,045 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:11,063 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:11 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:11,067 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:11,084 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:11,138 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011a8d0390>\n",
      "2025-02-04 23:42:11,143 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe7b0> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:11,181 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011b380c90>\n",
      "2025-02-04 23:42:11,185 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:11,191 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:11,192 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:11,194 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:11,196 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:15,048 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:15 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3833'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:15,050 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:15,050 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:15,054 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:15,055 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:15,056 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is developing a standalone app for its Grok chatbot, set to launch by December, directly competing with OpenAI's ChatGPT and other established chatbot apps. Currently, Grok is only available to X subscribers. Concurrently, Musk's legal team is attempting to block OpenAI's transition to a for-profit model, citing antitrust violations and financial risks. This legal action is part of a broader trend where LLM developers, including OpenAI, face challenges such as NVIDIA's pricing power and high buyer price sensitivity, leading to difficulties in achieving profitability despite substantial capital raised. Meanwhile, Alibaba has introduced QwQ-32B-Preview, an open challenger to OpenAI's o1 reasoning model, further intensifying competition in the AI landscape.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 587,\n",
      "    \"candidatesTokenCount\": 155,\n",
      "    \"totalTokenCount\": 742\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:15,058 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is developing a standalone app for its Grok chatbot, set to launch by December, directly competing with OpenAI's ChatGPT and other established chatbot apps. Currently, Grok is only available to X subscribers. Concurrently, Musk's legal team is attempting to block OpenAI's transition to a for-profit model, citing antitrust violations and financial risks. This legal action is part of a broader trend where LLM developers, including OpenAI, face challenges such as NVIDIA's pricing power and high buyer price sensitivity, leading to difficulties in achieving profitability despite substantial capital raised. Meanwhile, Alibaba has introduced QwQ-32B-Preview, an open challenger to OpenAI's o1 reasoning model, further intensifying competition in the AI landscape.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 587,\n",
      "    \"candidatesTokenCount\": 155,\n",
      "    \"totalTokenCount\": 742\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:15,060 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:15,061 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:15 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:15,063 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:15,065 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:15,066 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:15,069 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:15,072 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:15,077 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:15,081 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:15,083 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:15,085 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:15,090 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:15,092 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:15,095 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:15,099 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:15 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:15,107 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:15,110 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:15,115 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:15,119 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:15,123 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:15,143 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:15 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:15,147 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN : Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:15,163 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:15,193 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011e772e90>\n",
      "2025-02-04 23:42:15,194 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe720> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:15,229 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d50c90>\n",
      "2025-02-04 23:42:15,230 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:15,232 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:15,233 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:15,235 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:15,236 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:18,031 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:18 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2775'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:18,032 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:18,033 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:18,036 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:18,037 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:18,038 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is developing a standalone app for its Grok chatbot, set to launch by December, positioning it as a direct competitor to established apps like OpenAI's ChatGPT. Currently, Grok is only available to X subscribers. Simultaneously, Musk's legal team has filed a motion to block OpenAI's transition to a for-profit model, citing antitrust violations and financial risks. The motion argues that CEO Sam Altman's actions could hinder OpenAI's ability to pay damages if Musk prevails in his lawsuit.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 447,\n",
      "    \"candidatesTokenCount\": 106,\n",
      "    \"totalTokenCount\": 553\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:18,040 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is developing a standalone app for its Grok chatbot, set to launch by December, positioning it as a direct competitor to established apps like OpenAI's ChatGPT. Currently, Grok is only available to X subscribers. Simultaneously, Musk's legal team has filed a motion to block OpenAI's transition to a for-profit model, citing antitrust violations and financial risks. The motion argues that CEO Sam Altman's actions could hinder OpenAI's ability to pay damages if Musk prevails in his lawsuit.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 447,\n",
      "    \"candidatesTokenCount\": 106,\n",
      "    \"totalTokenCount\": 553\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:18,043 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:18,044 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:18 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:18,047 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:18,051 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:18,051 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "2025-02-04 23:42:18,055 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:18,057 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:18,061 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:18,069 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:18,073 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:18,077 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:18,080 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:18,082 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:18,084 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:18,087 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:18 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:18,090 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:18,092 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:18,096 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:18,098 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:18,101 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:18,115 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:18 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:18,116 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nMAPPING THE IONOSPHERE WITH THE POWER OF ANDROID : Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:18,129 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:18,156 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d50390>\n",
      "2025-02-04 23:42:18,158 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbdfd0> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:18,195 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119e5d610>\n",
      "2025-02-04 23:42:18,197 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:18,199 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:18,200 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:18,202 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:18,203 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:20,456 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:20 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2230'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:20,458 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:20,460 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:20,466 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:20,467 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:20,468 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is set to launch a standalone app for its Grok chatbot by December, directly competing with established chatbot apps from OpenAI, Google, and Anthropic, as Grok is currently only accessible through X for subscribers. Separately, Google researchers have successfully mapped the Ionosphere using GPS fluctuations and algorithmic work, a task typically expensive and time-consuming, which could aid in various climate solutions.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 425,\n",
      "    \"candidatesTokenCount\": 83,\n",
      "    \"totalTokenCount\": 508\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:20,470 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Elon Musk's xAI is set to launch a standalone app for its Grok chatbot by December, directly competing with established chatbot apps from OpenAI, Google, and Anthropic, as Grok is currently only accessible through X for subscribers. Separately, Google researchers have successfully mapped the Ionosphere using GPS fluctuations and algorithmic work, a task typically expensive and time-consuming, which could aid in various climate solutions.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 425,\n",
      "    \"candidatesTokenCount\": 83,\n",
      "    \"totalTokenCount\": 508\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:20,477 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:20,482 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:20 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:20,487 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:20,494 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:20,498 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:20,502 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:20,508 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:20,510 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:20,520 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "2025-02-04 23:42:20,525 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:20,528 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:20,533 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:20,536 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:20,541 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:20,544 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:20 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:20,548 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:20,551 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:20,555 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:20,559 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:20,562 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:20,580 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:20 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:20,584 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:20,603 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:20,649 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119e31690>\n",
      "2025-02-04 23:42:20,650 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe3c0> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:20,688 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119e31710>\n",
      "2025-02-04 23:42:20,689 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:20,690 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:20,691 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:20,692 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:20,693 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:23,690 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:23 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2926'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:23,693 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:23,694 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:23,696 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:23,697 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:23,698 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"NVIDIA's generative AI model, Fugatto, enables users to create and transform audio using text prompts, supporting music generation, voice modification, and unique sound creation with 2.5 billion parameters trained on a vast dataset for multilingual audio tasks and unsupervised learning. Despite the potential of such advanced AI models, the profitability of building large language models (LLMs) like those from OpenAI remains uncertain due to significant challenges such as NVIDIA's pricing power as a key chip supplier, high buyer price sensitivity, and intense competition, leading many AI companies to struggle financially despite substantial capital raised.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 484,\n",
      "    \"candidatesTokenCount\": 117,\n",
      "    \"totalTokenCount\": 601\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:23,699 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"NVIDIA's generative AI model, Fugatto, enables users to create and transform audio using text prompts, supporting music generation, voice modification, and unique sound creation with 2.5 billion parameters trained on a vast dataset for multilingual audio tasks and unsupervised learning. Despite the potential of such advanced AI models, the profitability of building large language models (LLMs) like those from OpenAI remains uncertain due to significant challenges such as NVIDIA's pricing power as a key chip supplier, high buyer price sensitivity, and intense competition, leading many AI companies to struggle financially despite substantial capital raised.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 484,\n",
      "    \"candidatesTokenCount\": 117,\n",
      "    \"totalTokenCount\": 601\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:23,702 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:23,703 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:23 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:23,704 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:23,706 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:23,707 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:23,709 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "2025-02-04 23:42:23,713 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:23,715 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:23,721 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:23,723 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:23,725 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:23,728 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:23,729 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:23,731 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:23,732 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:23 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:23,734 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:23,737 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:23,739 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:23,742 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:23,743 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:23,759 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:23 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:23,761 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE : Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\\nXAI COULD SOON HAVE ITS OWN APP : Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:23,773 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:23,875 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cc0890>\n",
      "2025-02-04 23:42:23,876 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe960> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:24,041 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011b54be90>\n",
      "2025-02-04 23:42:24,042 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:24,044 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:24,046 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:24,048 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:24,048 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:26,315 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:26 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2187'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:26,317 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:26,318 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:26,322 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:26,324 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:26,325 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"xAI, led by Elon Musk, is set to launch a standalone app for its Grok chatbot by December, directly competing with established chatbot apps from OpenAI, Google, and Anthropic; Grok is currently available only to X subscribers. Meanwhile, Anthropic's Claude AI has introduced customizable response styles, enabling users to tailor the AI's tone and length for various writing tasks.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 412,\n",
      "    \"candidatesTokenCount\": 78,\n",
      "    \"totalTokenCount\": 490\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:26,327 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"xAI, led by Elon Musk, is set to launch a standalone app for its Grok chatbot by December, directly competing with established chatbot apps from OpenAI, Google, and Anthropic; Grok is currently available only to X subscribers. Meanwhile, Anthropic's Claude AI has introduced customizable response styles, enabling users to tailor the AI's tone and length for various writing tasks.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 412,\n",
      "    \"candidatesTokenCount\": 78,\n",
      "    \"totalTokenCount\": 490\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:26,329 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:26,331 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:26 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:26,334 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:26,337 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:26,338 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "2025-02-04 23:42:26,340 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:26,343 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:26,345 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:26,351 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:26,357 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:26,359 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:26,363 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:26,365 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:26,368 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:26,370 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:26 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:26,373 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:26,375 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:26,377 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:26,378 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:26,380 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:26,393 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:26 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:26,395 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles related to a single technology company, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nCONVERTING GPT TO LLAMA : This repository contains code for converting a GPT implementation to Meta AI's Llama.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in market intelligence in the field of Artificial Intelligence.\\nYour speciality is to read multiple articles related to a specific technology company and summarize them into a professional news digest.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:26,406 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:26,538 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011b4d3bd0>\n",
      "2025-02-04 23:42:26,539 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbeb10> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:26,706 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119e50250>\n",
      "2025-02-04 23:42:26,707 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:26,711 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:26,712 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:26,715 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:26,716 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:29,525 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:29 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=2742'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:29,527 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:29,528 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:29,530 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:29,531 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:29,532 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The Allen Institute for AI (AI2) has released OLMo 2, a new series of open-source language models with 7 and 13 billion parameters, designed to compete with models like Meta's Llama 3.1. Developed using publicly available training data and code, OLMo 2 aims to enhance open-source AI innovation and is available under the Apache 2.0 license for commercial use. Additionally, a separate project provides code for converting GPT implementations to Meta AI's Llama architecture.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 429,\n",
      "    \"candidatesTokenCount\": 107,\n",
      "    \"totalTokenCount\": 536\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:29,534 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The Allen Institute for AI (AI2) has released OLMo 2, a new series of open-source language models with 7 and 13 billion parameters, designed to compete with models like Meta's Llama 3.1. Developed using publicly available training data and code, OLMo 2 aims to enhance open-source AI innovation and is available under the Apache 2.0 license for commercial use. Additionally, a separate project provides code for converting GPT implementations to Meta AI's Llama architecture.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 429,\n",
      "    \"candidatesTokenCount\": 107,\n",
      "    \"totalTokenCount\": 536\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:29,536 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:29,539 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:29 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:29,541 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:29,545 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:29,549 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:29,553 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:29,555 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:29,557 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:29,562 - src.genai_model.genai_model - INFO -- l.92: Found 13 models for model_type large\n",
      "2025-02-04 23:42:29,564 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:29,566 - src.genai_model.genai_model - INFO -- l.95: List of models included: ['gemini/gemini-exp-1206', 'openrouter/google/gemini-exp-1206:free', 'gemini/gemini-exp-1121', 'openrouter/google/gemini-exp-1121:free', 'gemini/gemini-exp-1114', 'openrouter/google/gemini-exp-1114:free', 'gemini/gemini-1.5-pro-002', 'gemini/gemini-1.5-pro-exp-0827', 'openrouter/meta-llama/llama-3.1-405b-instruct:free', 'gemini/gemini-1.5-pro-001', 'mistral/mistral-large-2411', 'mistral/mistral-large-2407', 'mistral/mistral-large-2402']\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:29,573 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:29,575 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:29,576 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:29,578 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:29,581 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:29,582 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:29 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:29,584 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}\n",
      "2025-02-04 23:42:29,585 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:29,587 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:29,589 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:29,591 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:29,601 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:29 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:29,602 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nDETECT AND LEARN UNSEEN OBJECTS : This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn\\'t seen before.\\nMAKING UNDERWATER IMAGES CLEAR : HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nFINE-GRAINED IMAGE QUALITY ASSESSMENT : Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:29,630 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:29,665 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d42d10>\n",
      "2025-02-04 23:42:29,666 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbed50> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:29,700 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d29f90>\n",
      "2025-02-04 23:42:29,701 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:29,703 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:29,704 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:29,706 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:29,708 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:33,530 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:33 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=3803'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:33,532 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:33,533 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:33,534 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:33,535 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:33,537 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Perplexity's CEO is considering the development of a \\\"simple, under $50\\\" AI device for voice-to-voice interactions, reflecting a trend among AI startups to explore hardware for new interaction methods, despite historical challenges in this area. In parallel, PlayAI has secured $21 million in funding to advance voice-first AI interfaces and models, and has released Play Dialog, a new multi-turn speech model. On the research front, advancements include the development of a framework for open-world object detection that enables AI to learn from unseen objects, HUPE for enhancing underwater image clarity while preserving critical details, and Grounding-IQA, a novel approach to image quality assessment that incorporates precise location-based grounding and multimodal descriptions.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 531,\n",
      "    \"candidatesTokenCount\": 151,\n",
      "    \"totalTokenCount\": 682\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:33,538 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Perplexity's CEO is considering the development of a \\\"simple, under $50\\\" AI device for voice-to-voice interactions, reflecting a trend among AI startups to explore hardware for new interaction methods, despite historical challenges in this area. In parallel, PlayAI has secured $21 million in funding to advance voice-first AI interfaces and models, and has released Play Dialog, a new multi-turn speech model. On the research front, advancements include the development of a framework for open-world object detection that enables AI to learn from unseen objects, HUPE for enhancing underwater image clarity while preserving critical details, and Grounding-IQA, a novel approach to image quality assessment that incorporates precise location-based grounding and multimodal descriptions.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 531,\n",
      "    \"candidatesTokenCount\": 151,\n",
      "    \"totalTokenCount\": 682\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:33,540 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:33,543 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:33 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:33,544 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:33,546 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:33,548 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:33,552 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "2025-02-04 23:42:33,553 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:33,555 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:33,564 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:33,566 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:33,568 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:33,571 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:33,573 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:33,575 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:33,577 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:33 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:33,579 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}\n",
      "2025-02-04 23:42:33,581 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:33,583 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:33,585 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:33,587 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:33,596 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:33 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:33,598 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nPERPLEXITY MULLS GETTING INTO HARDWARE : Perplexity\\'s CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane\\'s Ai Pin.\\nINFLECTION AI CEO SAYS IT\\'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA\\'s pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nROX : A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI\\'s ability to manage unstructured data and integrate with data warehouses. Rox\\'s strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\\nPLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL : PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META\\'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta\\'s Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\n\\n        '}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:33,607 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:33,634 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d283d0>\n",
      "2025-02-04 23:42:33,635 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbea80> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:33,668 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cc1390>\n",
      "2025-02-04 23:42:33,669 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:33,669 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:33,670 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:33,671 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:33,672 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:37,808 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:37 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4053'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:37,809 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:37,810 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:37,812 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:37,814 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:37,815 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The AI landscape is witnessing a shift from developing cutting-edge models to leveraging existing ones for practical applications. Inflection AI has pivoted to providing AI tools for enterprise customers, emphasizing on-premise solutions for data security, while the broader industry faces challenges in profitability despite substantial capital. AI2 has released OLMo 2, an open-source language model series designed to compete with models like Meta's Llama 3.1, aiming to boost open-source AI innovation with models available under the Apache 2.0 license. In terms of new developments, Perplexity is exploring a sub-$50 AI device for voice interactions, PlayAI has raised $21 million and introduced a new multi-turn speech model, and Rox is launching an AI-native CRM to challenge Salesforce by leveraging AI's ability to manage unstructured data.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 798,\n",
      "    \"candidatesTokenCount\": 170,\n",
      "    \"totalTokenCount\": 968\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:37,821 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"The AI landscape is witnessing a shift from developing cutting-edge models to leveraging existing ones for practical applications. Inflection AI has pivoted to providing AI tools for enterprise customers, emphasizing on-premise solutions for data security, while the broader industry faces challenges in profitability despite substantial capital. AI2 has released OLMo 2, an open-source language model series designed to compete with models like Meta's Llama 3.1, aiming to boost open-source AI innovation with models available under the Apache 2.0 license. In terms of new developments, Perplexity is exploring a sub-$50 AI device for voice interactions, PlayAI has raised $21 million and introduced a new multi-turn speech model, and Rox is launching an AI-native CRM to challenge Salesforce by leveraging AI's ability to manage unstructured data.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 798,\n",
      "    \"candidatesTokenCount\": 170,\n",
      "    \"totalTokenCount\": 968\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:37,822 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:37,824 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:37 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:37,826 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:37,828 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:37,829 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:37,831 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:37,834 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:37,837 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:37,849 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:37,853 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:42:37,855 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:37,860 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:37,862 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:37,864 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:37,869 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:37 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:37,871 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:37,872 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:37,875 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:37,880 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:37,881 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:37,893 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:37 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:37,896 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\\r\\nMODELS : Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\\nINTRODUCING LTNTORCH : Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nBUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS : LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\\nALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL : Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:37,906 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:37,932 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d2bcd0>\n",
      "2025-02-04 23:42:37,934 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbec30> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:37,970 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011b380810>\n",
      "2025-02-04 23:42:37,971 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:37,974 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:37,975 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:37,976 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:37,978 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:42,435 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:42 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4443'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:42,436 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:42,437 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:42,440 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:42,441 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:42,443 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Inflection AI has pivoted from developing next-generation AI models to offering AI tools for enterprise customers, emphasizing practical applications and data security. The trend of building new large language models (LLMs) faces challenges, including high costs and competition, leading some companies to leverage existing models instead. Alibaba has introduced QwQ-32B-Preview as an open challenger to OpenAI's o1, while AI2 has released OLMo 2, an open-source model series outperforming Meta's Llama 3.1. New research highlights advancements and challenges in AI: LTNtorch merges deep learning with logical reasoning, ProX refines pretraining data programmatically, and RoboPAIR demonstrates the ease of jailbreaking LLM-driven robots, revealing significant security vulnerabilities. Additionally, NVIDIA's Fugatto model allows for advanced audio creation and transformation using text prompts, showcasing the flexibility of generative AI in multimedia applications.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 897,\n",
      "    \"candidatesTokenCount\": 186,\n",
      "    \"totalTokenCount\": 1083\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:42,446 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Inflection AI has pivoted from developing next-generation AI models to offering AI tools for enterprise customers, emphasizing practical applications and data security. The trend of building new large language models (LLMs) faces challenges, including high costs and competition, leading some companies to leverage existing models instead. Alibaba has introduced QwQ-32B-Preview as an open challenger to OpenAI's o1, while AI2 has released OLMo 2, an open-source model series outperforming Meta's Llama 3.1. New research highlights advancements and challenges in AI: LTNtorch merges deep learning with logical reasoning, ProX refines pretraining data programmatically, and RoboPAIR demonstrates the ease of jailbreaking LLM-driven robots, revealing significant security vulnerabilities. Additionally, NVIDIA's Fugatto model allows for advanced audio creation and transformation using text prompts, showcasing the flexibility of generative AI in multimedia applications.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 897,\n",
      "    \"candidatesTokenCount\": 186,\n",
      "    \"totalTokenCount\": 1083\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:42,452 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:42,455 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:42 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:42,457 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:42,461 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:42,463 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:42,469 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "2025-02-04 23:42:42,472 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:42,473 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:42,482 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:42,484 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:42,486 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:42,492 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:42,498 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:42,502 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:42,504 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:42 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:42,507 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:42,510 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:42,515 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:42,521 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:42,523 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:42,546 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:42 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:42,549 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nREFINING PRETRAINING DATA PROGRAMMATICALLY : ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\\nAI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA : Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\\nWORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS : Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:42,567 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:42,605 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119e3ad90>\n",
      "2025-02-04 23:42:42,606 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe8d0> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:42,648 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011a8a8a90>\n",
      "2025-02-04 23:42:42,650 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:42,652 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:42,653 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:42,657 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:42,659 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:46,778 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:46 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=4107'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:46,780 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:46,782 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:46,786 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:46,789 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:46,792 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"AI2 has introduced OLMo 2, an open-source language model series with 7 and 13 billion parameter models that reportedly outperform similar open models like Meta's Llama 3.1, available under the Apache 2.0 license for commercial use. INTELLECT-1, a globally trained 10B parameter model, demonstrates significant advancements in decentralized large model training with an impressive MFU of 30%+. ProX offers a framework for refining pretraining data programmatically, enhancing the quality of pre-training corpora by using small language models to generate programs. NVIDIA researchers have developed Fugatto, a 2.5 billion parameter generative AI model that allows users to control audio creation and transformation via text prompts, capable of generating music, modifying voices, and creating unique sounds for applications like music production and video game development.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 619,\n",
      "    \"candidatesTokenCount\": 173,\n",
      "    \"totalTokenCount\": 792\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:46,793 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"AI2 has introduced OLMo 2, an open-source language model series with 7 and 13 billion parameter models that reportedly outperform similar open models like Meta's Llama 3.1, available under the Apache 2.0 license for commercial use. INTELLECT-1, a globally trained 10B parameter model, demonstrates significant advancements in decentralized large model training with an impressive MFU of 30%+. ProX offers a framework for refining pretraining data programmatically, enhancing the quality of pre-training corpora by using small language models to generate programs. NVIDIA researchers have developed Fugatto, a 2.5 billion parameter generative AI model that allows users to control audio creation and transformation via text prompts, capable of generating music, modifying voices, and creating unique sounds for applications like music production and video game development.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"index\": 0\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 619,\n",
      "    \"candidatesTokenCount\": 173,\n",
      "    \"totalTokenCount\": 792\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-exp-1206\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:42:46,797 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:46,798 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:42:46 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:42:46,800 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:42:46,804 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:46,805 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:42:46,807 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:46,809 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:42:46,813 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-exp-1206 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:46,820 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:42:46,823 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:46,825 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:46,832 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1206', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:46,835 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:46,839 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:46,841 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:46 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-04 23:42:46,844 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:46,847 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1206', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:46,849 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:46,853 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:46,855 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:46,868 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:46 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:46,870 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:46,882 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:46,912 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cc3f50>\n",
      "2025-02-04 23:42:46,914 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119dbe0f0> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:46,948 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d55c50>\n",
      "2025-02-04 23:42:46,949 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:46,951 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:46,953 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:46,955 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:46,956 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,025 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 429, b'Too Many Requests', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=56'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:47,026 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 429 Too Many Requests\"\n",
      "2025-02-04 23:42:47,028 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,030 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:47,030 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:47,031 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1206\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:47,037 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1206\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:47,039 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:47,056 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,058 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,060 - src.genai_model.genai_model - WARNING -- l.39: Model gemini/gemini-exp-1206 raised an Exception.\n",
      "2025-02-04 23:42:47,061 - src.genai_model.genai_model - DEBUG -- l.40: litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 429,\n",
      "    \"message\": \"Resource has been exhausted (e.g. check quota).\",\n",
      "    \"status\": \"RESOURCE_EXHAUSTED\"\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,063 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:47,065 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1206:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:47,067 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1206:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,070 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:47,074 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:47,077 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:47 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= google/gemini-exp-1206:free; provider = openrouter\n",
      "2025-02-04 23:42:47,080 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= google/gemini-exp-1206:free; provider = openrouter\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1206:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:47,082 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1206:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:47,085 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:47,086 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:47,088 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1206:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "2025-02-04 23:42:47,098 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1206:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1206:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,100 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1206:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,111 - openai._base_client - DEBUG -- l.453: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM', 'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'model': 'google/gemini-exp-1206:free', 'temperature': 0.2, 'top_p': 0.5}, 'extra_json': {'transforms': []}}\n",
      "2025-02-04 23:42:47,114 - openai._base_client - DEBUG -- l.993: Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "2025-02-04 23:42:47,115 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='openrouter.ai' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:47,162 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cc0110>\n",
      "2025-02-04 23:42:47,164 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119a88950> server_hostname='openrouter.ai' timeout=600.0\n",
      "2025-02-04 23:42:47,185 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cbe050>\n",
      "2025-02-04 23:42:47,186 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,187 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:47,189 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,191 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:47,192 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:42:47,316 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 04:42:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d03c5d5ca2715a-YUL'), (b'Content-Encoding', b'gzip')])\n",
      "2025-02-04 23:42:47,317 - httpx - INFO -- l.1027: HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:47,318 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,611 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:47,612 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:47,613 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "2025-02-04 23:42:47,615 - openai._base_client - DEBUG -- l.1032: HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 05 Feb 2025 04:42:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '90d03c5d5ca2715a-YUL', 'content-encoding': 'gzip'})\n",
      "2025-02-04 23:42:47,615 - openai._base_client - DEBUG -- l.1040: request_id: None\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 429, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 429,\\n    \\\"message\\\": \\\"Resource has been exhausted (e.g. check quota).\\\",\\n    \\\"status\\\": \\\"RESOURCE_EXHAUSTED\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "2025-02-04 23:42:47,626 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 429, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 429,\\n    \\\"message\\\": \\\"Resource has been exhausted (e.g. check quota).\\\",\\n    \\\"status\\\": \\\"RESOURCE_EXHAUSTED\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: main.py:5291 - openai.py: Received openai error - \n",
      "2025-02-04 23:42:47,627 - LiteLLM - DEBUG -- l.5291: openai.py: Received openai error - \n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1206:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:47,629 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1206:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:47,631 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:47,642 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,643 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,645 - src.genai_model.genai_model - WARNING -- l.39: Model openrouter/google/gemini-exp-1206:free raised an Exception.\n",
      "2025-02-04 23:42:47,646 - src.genai_model.genai_model - DEBUG -- l.40: litellm.RateLimitError: RateLimitError: OpenrouterException - \n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,646 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:47,648 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1121', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:47,649 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1121', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,650 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:47,652 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:47,653 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:47 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1121; provider = gemini\n",
      "2025-02-04 23:42:47,655 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1121; provider = gemini\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1121', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:47,656 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1121', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:47,658 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:47,659 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:47,660 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:47 - LiteLLM:WARNING\u001b[0m: common_utils.py:33 - Unable to identify if system message supported. Defaulting to 'False'. Received error message - Model not supports system messages. You passed model=gemini-exp-1121, custom_llm_provider=gemini.\n",
      "Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "2025-02-04 23:42:47,672 - LiteLLM - WARNING -- l.33: Unable to identify if system message supported. Defaulting to 'False'. Received error message - Model not supports system messages. You passed model=gemini-exp-1121, custom_llm_provider=gemini.\n",
      "Add it here - https://github.com/BerriAI/litellm/blob/main/model_prices_and_context_window.json\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1121:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:47,673 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1121:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1121:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,676 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1121:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,685 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:47,709 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119cbc850>\n",
      "2025-02-04 23:42:47,710 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119af9d90> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:47,748 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d549d0>\n",
      "2025-02-04 23:42:47,749 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,751 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:47,752 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,753 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:47,754 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,801 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:47 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=34'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:47,802 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1121:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 404 Not Found\"\n",
      "2025-02-04 23:42:47,803 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,805 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:47,805 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:47,806 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1121\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:47,808 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1121\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:47,812 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:47,824 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,825 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:47,827 - src.genai_model.genai_model - WARNING -- l.39: Model gemini/gemini-exp-1121 raised an Exception.\n",
      "2025-02-04 23:42:47,829 - src.genai_model.genai_model - DEBUG -- l.40: litellm.NotFoundError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"models/gemini-exp-1121 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n",
      "    \"status\": \"NOT_FOUND\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,830 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:47,832 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1121:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:47,833 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1121:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:47,835 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:47,837 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:47,842 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:47 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= google/gemini-exp-1121:free; provider = openrouter\n",
      "2025-02-04 23:42:47,846 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= google/gemini-exp-1121:free; provider = openrouter\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1121:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:47,850 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1121:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:47,852 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:47,855 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:47,856 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1121:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "2025-02-04 23:42:47,859 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1121:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "\u001b[92m23:42:47 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1121:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,861 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1121:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:47,866 - openai._base_client - DEBUG -- l.453: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM', 'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'model': 'google/gemini-exp-1121:free', 'temperature': 0.2, 'top_p': 0.5}, 'extra_json': {'transforms': []}}\n",
      "2025-02-04 23:42:47,868 - openai._base_client - DEBUG -- l.993: Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "2025-02-04 23:42:47,868 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,870 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:47,871 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,874 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:47,875 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:47,971 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 04:42:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d03c61aefa715a-YUL'), (b'Content-Encoding', b'gzip')])\n",
      "2025-02-04 23:42:47,972 - httpx - INFO -- l.1027: HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:47,974 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,261 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:48,262 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:48,263 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "2025-02-04 23:42:48,264 - openai._base_client - DEBUG -- l.1032: HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 05 Feb 2025 04:42:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '90d03c61aefa715a-YUL', 'content-encoding': 'gzip'})\n",
      "2025-02-04 23:42:48,266 - openai._base_client - DEBUG -- l.1040: request_id: None\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 404, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 404,\\n    \\\"message\\\": \\\"models/gemini-exp-1121 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\\\",\\n    \\\"status\\\": \\\"NOT_FOUND\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "2025-02-04 23:42:48,267 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 404, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 404,\\n    \\\"message\\\": \\\"models/gemini-exp-1121 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\\\",\\n    \\\"status\\\": \\\"NOT_FOUND\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: main.py:5291 - openai.py: Received openai error - \n",
      "2025-02-04 23:42:48,270 - LiteLLM - DEBUG -- l.5291: openai.py: Received openai error - \n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1121:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:48,273 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1121:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:48,277 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:48,291 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,294 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,296 - src.genai_model.genai_model - WARNING -- l.39: Model openrouter/google/gemini-exp-1121:free raised an Exception.\n",
      "2025-02-04 23:42:48,296 - src.genai_model.genai_model - DEBUG -- l.40: litellm.NotFoundError: NotFoundError: OpenrouterException - \n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,298 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:48,300 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-exp-1114', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:48,301 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-exp-1114', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,304 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:48,306 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:48,308 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:48 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-exp-1114; provider = gemini\n",
      "2025-02-04 23:42:48,311 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-exp-1114; provider = gemini\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1114', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:48,312 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-exp-1114', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,313 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,316 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,318 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1114:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:48,329 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1114:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1114:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,330 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1114:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,340 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:48,365 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f011b22b750>\n",
      "2025-02-04 23:42:48,367 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119afa570> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:48,401 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d2b910>\n",
      "2025-02-04 23:42:48,402 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,403 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:48,404 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,406 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:48,407 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,448 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 404, b'Not Found', [(b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Type', b'application/json; charset=UTF-8'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:42:48 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=25'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:42:48,449 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1114:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 404 Not Found\"\n",
      "2025-02-04 23:42:48,451 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,452 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:48,453 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:48,453 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1114\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:48,456 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=gemini-exp-1114\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:48,460 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:48,472 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,475 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,476 - src.genai_model.genai_model - WARNING -- l.39: Model gemini/gemini-exp-1114 raised an Exception.\n",
      "2025-02-04 23:42:48,477 - src.genai_model.genai_model - DEBUG -- l.40: litellm.NotFoundError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 404,\n",
      "    \"message\": \"models/gemini-exp-1114 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\",\n",
      "    \"status\": \"NOT_FOUND\"\n",
      "  }\n",
      "}\n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,482 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:48,491 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1114:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:48,498 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='openrouter/google/gemini-exp-1114:free', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,607 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:48,609 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:48,611 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:48 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= google/gemini-exp-1114:free; provider = openrouter\n",
      "2025-02-04 23:42:48,620 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= google/gemini-exp-1114:free; provider = openrouter\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1114:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:48,627 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'google/gemini-exp-1114:free', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openrouter', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,644 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:48,648 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "2025-02-04 23:42:48,650 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5, 'extra_body': {}}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1114:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "2025-02-04 23:42:48,654 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}, 'api_base': ParseResult(scheme='https', userinfo='', host='openrouter.ai', port=None, path='/api/v1/', query=None, fragment=None), 'acompletion': False, 'complete_input_dict': {'model': 'google/gemini-exp-1114:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1114:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,657 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://openrouter.ai/api/v1/ \\\n",
      "-H 'HTTP-Referer: *****' -H 'X-Title: *****' \\\n",
      "-d '{'model': 'google/gemini-exp-1114:free', 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'temperature': 0.2, 'top_p': 0.5, 'extra_body': {'transforms': []}, 'extra_headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM'}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,664 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:42:48,667 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "2025-02-04 23:42:48,674 - openai._base_client - DEBUG -- l.453: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'HTTP-Referer': 'https://litellm.ai', 'X-Title': 'liteLLM', 'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], 'model': 'google/gemini-exp-1114:free', 'temperature': 0.2, 'top_p': 0.5}, 'extra_json': {'transforms': []}}\n",
      "2025-02-04 23:42:48,677 - openai._base_client - DEBUG -- l.993: Sending HTTP Request: POST https://openrouter.ai/api/v1/chat/completions\n",
      "2025-02-04 23:42:48,678 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,681 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:48,682 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,685 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:48,685 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,778 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 05 Feb 2025 04:42:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Access-Control-Allow-Origin', b'*'), (b'x-clerk-auth-message', b'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)'), (b'x-clerk-auth-reason', b'token-invalid'), (b'x-clerk-auth-status', b'signed-out'), (b'Vary', b'Accept-Encoding'), (b'Server', b'cloudflare'), (b'CF-RAY', b'90d03c66b9c4715a-YUL'), (b'Content-Encoding', b'gzip')])\n",
      "2025-02-04 23:42:48,779 - httpx - INFO -- l.1027: HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:42:48,780 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:48,932 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:42:48,933 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:42:48,934 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "2025-02-04 23:42:48,934 - openai._base_client - DEBUG -- l.1032: HTTP Response: POST https://openrouter.ai/api/v1/chat/completions \"200 OK\" Headers({'date': 'Wed, 05 Feb 2025 04:42:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'x-clerk-auth-message': 'Invalid JWT form. A JWT consists of three parts separated by dots. (reason=token-invalid, token-carrier=header)', 'x-clerk-auth-reason': 'token-invalid', 'x-clerk-auth-status': 'signed-out', 'vary': 'Accept-Encoding', 'server': 'cloudflare', 'cf-ray': '90d03c66b9c4715a-YUL', 'content-encoding': 'gzip'})\n",
      "2025-02-04 23:42:48,935 - openai._base_client - DEBUG -- l.1040: request_id: None\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 404, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 404,\\n    \\\"message\\\": \\\"models/gemini-exp-1114 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\\\",\\n    \\\"status\\\": \\\"NOT_FOUND\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "2025-02-04 23:42:48,936 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\"id\": null, \"choices\": null, \"created\": null, \"model\": null, \"object\": null, \"service_tier\": null, \"system_fingerprint\": null, \"usage\": null, \"error\": {\"message\": \"Provider returned error\", \"code\": 404, \"metadata\": {\"raw\": \"{\\n  \\\"error\\\": {\\n    \\\"code\\\": 404,\\n    \\\"message\\\": \\\"models/gemini-exp-1114 is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\\\",\\n    \\\"status\\\": \\\"NOT_FOUND\\\"\\n  }\\n}\\n\", \"provider_name\": \"Google AI Studio\"}}, \"user_id\": \"user_2sHi5De2jH8imIMypXBgpZ1H8FG\"}\n",
      "\n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: main.py:5291 - openai.py: Received openai error - \n",
      "2025-02-04 23:42:48,937 - LiteLLM - DEBUG -- l.5291: openai.py: Received openai error - \n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:4051 - Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1114:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "2025-02-04 23:42:48,939 - LiteLLM - DEBUG -- l.4051: Error occurred in getting api base - litellm.BadRequestError: LLM Provider NOT provided. Pass in the LLM provider you are trying to call. You passed model=google/gemini-exp-1114:free\n",
      " Pass model as E.g. For 'Huggingface' inference endpoints pass in `completion(model='huggingface/starcoder',..)` Learn more: https://docs.litellm.ai/docs/providers\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: exception_mapping_utils.py:2166 - Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "2025-02-04 23:42:48,941 - LiteLLM - DEBUG -- l.2166: Logging Details: logger_fn - None | callable(logger_fn) - False\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:1723 - Logging Details LiteLLM-Failure Call: []\n",
      "2025-02-04 23:42:48,953 - LiteLLM - DEBUG -- l.1723: Logging Details LiteLLM-Failure Call: []\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:2599 - Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,954 - LiteLLM - DEBUG -- l.2599: Model= is not mapped in model cost map. Defaulting to None model_cost_information for standard_logging_payload\n",
      "2025-02-04 23:42:48,956 - src.genai_model.genai_model - WARNING -- l.39: Model openrouter/google/gemini-exp-1114:free raised an Exception.\n",
      "2025-02-04 23:42:48,956 - src.genai_model.genai_model - DEBUG -- l.40: litellm.NotFoundError: NotFoundError: OpenrouterException - \n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,958 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mRequest to litellm:\u001b[0m\n",
      "2025-02-04 23:42:48,959 - LiteLLM - DEBUG -- l.257: \u001b[92mRequest to litellm:\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92mlitellm.completion(model='gemini/gemini-1.5-pro-002', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "2025-02-04 23:42:48,960 - LiteLLM - DEBUG -- l.257: \u001b[92mlitellm.completion(model='gemini/gemini-1.5-pro-002', messages=[{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}], temperature=0.2, top_p=0.5)\u001b[0m\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \n",
      "\n",
      "2025-02-04 23:42:48,962 - LiteLLM - DEBUG -- l.257: \n",
      "\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {}\n",
      "2025-02-04 23:42:48,963 - LiteLLM - DEBUG -- l.390: self.optional_params: {}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "2025-02-04 23:42:48,965 - LiteLLM - DEBUG -- l.257: SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "\u001b[92m23:42:48 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "2025-02-04 23:42:48,967 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2755 - \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro-002', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "2025-02-04 23:42:48,968 - LiteLLM - DEBUG -- l.2755: \n",
      "LiteLLM: Params passed to completion() {'model': 'gemini-1.5-pro-002', 'functions': None, 'function_call': None, 'temperature': 0.2, 'top_p': 0.5, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'gemini', 'response_format': None, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'additional_drop_params': None, 'messages': [{'role': 'system', 'content': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}, {'role': 'user', 'content': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:2758 - \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,970 - LiteLLM - DEBUG -- l.2758: \n",
      "LiteLLM: Non-Default params passed to completion() {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,976 - LiteLLM - DEBUG -- l.257: Final returned optional params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:390 - self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "2025-02-04 23:42:48,977 - LiteLLM - DEBUG -- l.390: self.optional_params: {'temperature': 0.2, 'top_p': 0.5}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:476 - PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "2025-02-04 23:42:48,987 - LiteLLM - DEBUG -- l.476: PRE-API-CALL ADDITIONAL ARGS: {'complete_input_dict': {'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}, 'api_base': 'https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY', 'headers': {'Content-Type': 'application/json'}}\n",
      "\u001b[92m23:42:48 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,989 - LiteLLM - DEBUG -- l.257: \u001b[92m\n",
      "\n",
      "POST Request Sent from LiteLLM:\n",
      "curl -X POST \\\n",
      "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \\\n",
      "-H 'Content-Type: *****' \\\n",
      "-d '{'contents': [{'role': 'user', 'parts': [{'text': \"\\nI will provide you with a list of news articles, and I want you to summarize all those articles into a single paragraph. Here are a few additional requirements:\\n- The summary should be as short as possible.\\n- The core content of all the news stories should be contained in the summary. \\n- If several news stories contain similar or identical material, this should not be repeated in the summary.\\n\\nTo produce the summaries, I want you to follow these steps:\\n1. Organize the news articles into a small number of categories.\\n2. For each category, summarize all news articles of that category into a concise paragraph.\\n3. Combine the summaries of all categories together.\\n\\nYou must only return the output from step 3, not the intermediate steps (steps 1 and 2).\\n\\nEach news article follows the same format:\\n<TITLE> : <MAIN TEXT>\\nHere is the list of news articles that I want you to use to create your newsletter:\\nINTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL : INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\\nIT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS : RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\\n\\n        \"}]}], 'system_instruction': {'parts': [{'text': '\\nYou are an expert technical writer, specialized in the field of Artificial Intelligence.\\nYour speciality is to summarize multiple news articles into professional news digests.\\nYou audience consists of senior business leaders who are interested in \\n1. understanding the technological trends in AI, \\n2. monitoring the fundraising activities in the ecosystem, and \\n3. tracking the main AI companies.\\n        '}]}, 'generationConfig': {'temperature': 0.2, 'top_p': 0.5}}'\n",
      "\u001b[0m\n",
      "\n",
      "2025-02-04 23:42:48,999 - httpcore.connection - DEBUG -- l.47: connect_tcp.started host='generativelanguage.googleapis.com' port=443 local_address=None timeout=600.0 socket_options=None\n",
      "2025-02-04 23:42:49,022 - httpcore.connection - DEBUG -- l.47: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119d28b90>\n",
      "2025-02-04 23:42:49,023 - httpcore.connection - DEBUG -- l.47: start_tls.started ssl_context=<ssl.SSLContext object at 0x7f0119afa840> server_hostname='generativelanguage.googleapis.com' timeout=600.0\n",
      "2025-02-04 23:42:49,061 - httpcore.connection - DEBUG -- l.47: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x7f0119b31090>\n",
      "2025-02-04 23:42:49,062 - httpcore.http11 - DEBUG -- l.47: send_request_headers.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:49,065 - httpcore.http11 - DEBUG -- l.47: send_request_headers.complete\n",
      "2025-02-04 23:42:49,066 - httpcore.http11 - DEBUG -- l.47: send_request_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:42:49,068 - httpcore.http11 - DEBUG -- l.47: send_request_body.complete\n",
      "2025-02-04 23:42:49,069 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.started request=<Request [b'POST']>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm.set_verbose=True'.\n",
      "\n",
      "\n",
      "\u001b[1;31mProvider List: https://docs.litellm.ai/docs/providers\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 23:43:06,409 - httpcore.http11 - DEBUG -- l.47: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Wed, 05 Feb 2025 04:43:06 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=17302'), (b'Alt-Svc', b'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])\n",
      "2025-02-04 23:43:06,410 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "2025-02-04 23:43:06,412 - httpcore.http11 - DEBUG -- l.47: receive_response_body.started request=<Request [b'POST']>\n",
      "2025-02-04 23:43:06,414 - httpcore.http11 - DEBUG -- l.47: receive_response_body.complete\n",
      "2025-02-04 23:43:06,415 - httpcore.http11 - DEBUG -- l.47: response_closed.started\n",
      "2025-02-04 23:43:06,416 - httpcore.http11 - DEBUG -- l.47: response_closed.complete\n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Researchers achieved a breakthrough in decentralized large model training with INTELLECT-1, a 10-billion parameter model trained on a trillion tokens using globally distributed hardware, demonstrating a remarkable 30%+ MFU.  However,  LLM-powered robots are vulnerable to jailbreaking, as demonstrated by the RoboPAIR algorithm, which bypassed safety protocols in systems like Go2 and robot dogs with a 100% success rate, highlighting a critical need for enhanced security measures.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.093754057981530012\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 458,\n",
      "    \"candidatesTokenCount\": 98,\n",
      "    \"totalTokenCount\": 556,\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 458\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 98\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-1.5-pro-002\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:43:06,417 - LiteLLM - DEBUG -- l.257: RAW RESPONSE:\n",
      "{\n",
      "  \"candidates\": [\n",
      "    {\n",
      "      \"content\": {\n",
      "        \"parts\": [\n",
      "          {\n",
      "            \"text\": \"Researchers achieved a breakthrough in decentralized large model training with INTELLECT-1, a 10-billion parameter model trained on a trillion tokens using globally distributed hardware, demonstrating a remarkable 30%+ MFU.  However,  LLM-powered robots are vulnerable to jailbreaking, as demonstrated by the RoboPAIR algorithm, which bypassed safety protocols in systems like Go2 and robot dogs with a 100% success rate, highlighting a critical need for enhanced security measures.\\n\"\n",
      "          }\n",
      "        ],\n",
      "        \"role\": \"model\"\n",
      "      },\n",
      "      \"finishReason\": \"STOP\",\n",
      "      \"avgLogprobs\": -0.093754057981530012\n",
      "    }\n",
      "  ],\n",
      "  \"usageMetadata\": {\n",
      "    \"promptTokenCount\": 458,\n",
      "    \"candidatesTokenCount\": 98,\n",
      "    \"totalTokenCount\": 556,\n",
      "    \"promptTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 458\n",
      "      }\n",
      "    ],\n",
      "    \"candidatesTokensDetails\": [\n",
      "      {\n",
      "        \"modality\": \"TEXT\",\n",
      "        \"tokenCount\": 98\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersion\": \"gemini-1.5-pro-002\"\n",
      "}\n",
      "\n",
      "\n",
      "\n",
      "2025-02-04 23:43:06,421 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:43:06,422 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "\u001b[92m23:43:06 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-04 23:43:06,424 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "2025-02-04 23:43:06,426 - LiteLLM - DEBUG -- l.257: Logging Details LiteLLM-Success Call: Cache_hit=None\n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:43:06,427 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: cost_calculator.py:620 - completion_response response ms: None \n",
      "2025-02-04 23:43:06,431 - LiteLLM - DEBUG -- l.620: completion_response response ms: None \n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-1.5-pro-002 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:43:06,434 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-1.5-pro-002 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: utils.py:257 - Looking up model=gemini/gemini-1.5-pro-002 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "2025-02-04 23:43:06,438 - LiteLLM - DEBUG -- l.257: Looking up model=gemini/gemini-1.5-pro-002 in model_cost_map, custom_llm_provider=gemini, call_type=completion\n",
      "\u001b[92m23:43:06 - LiteLLM:DEBUG\u001b[0m: litellm_logging.py:891 - success callbacks: ['cache']\n",
      "2025-02-04 23:43:06,454 - LiteLLM - DEBUG -- l.891: success callbacks: ['cache']\n",
      "2025-02-04 23:43:06,463 - googleapiclient.discovery_cache - INFO -- l.49: file_cache is only supported with oauth2client<4.0.0\n",
      "2025-02-04 23:43:06,467 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:43:06,471 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "2025-02-04 23:43:06,472 - httpcore.connection - DEBUG -- l.47: close.started\n",
      "2025-02-04 23:43:06,474 - httpcore.connection - DEBUG -- l.47: close.complete\n",
      "2025-02-04 23:43:06,493 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: POST https://gmail.googleapis.com/gmail/v1/users/me/messages/send?alt=json\n",
      "2025-02-04 23:43:06,494 - google_auth_httplib2 - DEBUG -- l.118: Making request: POST https://oauth2.googleapis.com/token\n",
      "2025-02-04 23:43:07,109 - src.gmail - INFO -- l.87: Message Report automatic_newsletter: 2024-11-29 -- 2024-12-02 sent; message ID: 194d46b43ae13421\n",
      "2025-02-04 23:43:07,115 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: POST https://gmail.googleapis.com/gmail/v1/users/me/messages/send?alt=json\n",
      "2025-02-04 23:43:07,402 - src.gmail - INFO -- l.87: Message Report automatic_newsletter: 2024-11-29 -- 2024-12-02 sent; message ID: 194d46b45d569cca\n",
      "2025-02-04 23:43:07,409 - googleapiclient.discovery - DEBUG -- l.1258: URL being requested: POST https://gmail.googleapis.com/gmail/v1/users/me/messages/send?alt=json\n",
      "2025-02-04 23:43:07,697 - src.gmail - INFO -- l.87: Message Report automatic_newsletter: 2024-11-29 -- 2024-12-02 sent; message ID: 194d46b457680dd1\n"
     ]
    }
   ],
   "source": [
    "runner_reporting(\n",
    "    df_scored_news_stories=df_news_stories, \n",
    "    target_fields=target_fields, \n",
    "    report_date_range=report_date_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239d71d7-56d3-4e19-a57c-7a86ec86ea22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:59:02.534004Z",
     "iopub.status.busy": "2025-01-12T04:59:02.533516Z",
     "iopub.status.idle": "2025-01-12T04:59:02.543835Z",
     "shell.execute_reply": "2025-01-12T04:59:02.542072Z",
     "shell.execute_reply.started": "2025-01-12T04:59:02.533971Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.io.text import load_from_text\n",
    "txt = load_from_text(\"log/2024-11-29_2024-12-02_report_20250111235739_v1.0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "500e067a-7fee-4c86-b663-1cc4c8d9f1a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T04:59:15.654331Z",
     "iopub.status.busy": "2025-01-12T04:59:15.653906Z",
     "iopub.status.idle": "2025-01-12T04:59:15.661514Z",
     "shell.execute_reply": "2025-01-12T04:59:15.658921Z",
     "shell.execute_reply.started": "2025-01-12T04:59:15.654300Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# COMPETTIVE_INTELLIGENCE\n",
      "Nothing to see here!\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# FUNDING\n",
      "‚Ä¢ BUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS (https://calpaterson.com/porter.html):\n",
      "\tScore: 5 (tags: ['AI&GenAI', 'Model', 'Funding', 'OpenAI', 'NVIDIA'])\n",
      "\tSummary: LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\n",
      "‚Ä¢ ROX (https://www.notboring.co/p/rox):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Funding'])\n",
      "\tSummary: A new AI-native CRM, Rox, aims to disrupt Salesforce by leveraging AI's ability to manage unstructured data and integrate with data warehouses. Rox's strategy focuses on enhancing top sales performers through AI-powered agents while securing customer data for future AI developments. Investors have shown confidence with $50M in funding, betting on Rox as AI capabilities continue to improve.\n",
      "‚Ä¢ PLAYAI RAISES $21M FUNDING AND RELEASES A NEW VOICE MODEL (https://blog.play.ai/blog/21m-funding):\n",
      "\tScore: 3 (tags: ['AI&GenAI', 'Multimodal', 'Funding'])\n",
      "\tSummary: PlayAI raised $21 Million to advance voice-first AI interfaces and models and introduced Play Dialog, a state-of-the-art multi-turn speech model.\n",
      "‚Ä¢ AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA (https://techcrunch.com/2024/11/26/ai2-releases-new-language-models-competitive-with-metas-llama/):\n",
      "\tScore: 5 (tags: ['AI&GenAI', 'Model', 'Model Training', 'Funding', 'Meta'])\n",
      "\tSummary: Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# EVALUATION\n",
      "‚Ä¢ INTELLECT-1 RELEASE: THE FIRST GLOBALLY TRAINED 10B PARAMETER MODEL (https://www.primeintellect.ai/blog/intellect-1-release):\n",
      "\tScore: 2 (tags: ['Model Training', 'Evaluation'])\n",
      "\tSummary: INTELLECT-1 is a 10B parameter model trained on 1T tokens with hardware distributed around the globe. The benchmarks are reasonable, and the MFU of 30%+ is amazing given the distributed nature of training. If the results hold, this is a substantial improvement for decentralized large model training.\n",
      "‚Ä¢ IT'S SURPRISINGLY EASY TO JAILBREAK LLM-DRIVEN ROBOTS (https://spectrum.ieee.org/jailbreak-llm):\n",
      "\tScore: 3 (tags: ['Model', 'Evaluation', 'Robotics'])\n",
      "\tSummary: RoboPAIR is an algorithm that successfully jailbreaks robots powered by LLMs, bypassing all safety guardrails. Experiments showed a 100% success rate in hacking systems like Go2, a self-driving simulator, and robot dogs. These findings reveal significant security vulnerabilities, stressing the need for better defenses against LLM-based robot hacking.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# THEMES-Model Training\n",
      "‚Ä¢ AI2 RELEASES NEW LANGUAGE MODELS COMPETITIVE WITH META'S LLAMA (https://techcrunch.com/2024/11/26/ai2-releases-new-language-models-competitive-with-metas-llama/):\n",
      "\tScore: 5 (tags: ['AI&GenAI', 'Model', 'Model Training', 'Funding', 'Meta'])\n",
      "\tSummary: Ai2 has released OLMo 2, an open-source language model series with models containing 7 and 13 billion parameters. OLMo 2 is developed with publicly accessible training data and code. Aiming to boost open-source AI innovation, Ai2 claims these models outperform similar open models like Meta's Llama 3.1. The models are available under the Apache 2.0 license for commercial use.\n",
      "‚Ä¢ WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS (https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/):\n",
      "\tScore: 4 (tags: ['AI&GenAI', 'Model', 'Model Training', 'NVIDIA'])\n",
      "\tSummary: Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# THEMES-NVIDIA\n",
      "‚Ä¢ BUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS (https://calpaterson.com/porter.html):\n",
      "\tScore: 5 (tags: ['AI&GenAI', 'Model', 'Funding', 'OpenAI', 'NVIDIA'])\n",
      "\tSummary: LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\n",
      "‚Ä¢ WORLD'S MOST FLEXIBLE SOUND MACHINE DEBUTS (https://blogs.nvidia.com/blog/fugatto-gen-ai-sound-model/):\n",
      "\tScore: 4 (tags: ['AI&GenAI', 'Model', 'Model Training', 'NVIDIA'])\n",
      "\tSummary: Fugatto, a new generative AI model, allows users to control audio creation and transformation using text prompts. It can generate music, modify voices, and create unique sounds, showcasing capabilities through tasks like music production and video game development. Developed by NVIDIA researchers, Fugatto uses 2.5 billion parameters and was trained on a vast dataset to handle multilingual audio tasks and unsupervised learning.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# THEMES-OpenAI\n",
      "‚Ä¢ XAI COULD SOON HAVE ITS OWN APP (https://www.theverge.com/2024/11/27/24307571/xai-consumer-app-planned-report):\n",
      "\tScore: 6 (tags: ['Conversational AI', 'RAI', 'OpenAI', 'Anthropic', 'Google', 'Twitter'])\n",
      "\tSummary: Elon Musk's xAI plans to launch a standalone app for its Grok chatbot by December, competing directly with OpenAI's ChatGPT. Grok is currently accessible through X for subscribers only. This move positions xAI to more directly challenge established chatbot apps from OpenAI, Google, and Anthropic.\n",
      "‚Ä¢ BUILDING LLMS IS PROBABLY NOT GOING BE A BRILLIANT BUSINESS (https://calpaterson.com/porter.html):\n",
      "\tScore: 5 (tags: ['AI&GenAI', 'Model', 'Funding', 'OpenAI', 'NVIDIA'])\n",
      "\tSummary: LLM makers like OpenAI face significant challenges due to industry structure, notably NVIDIA's pricing power as the key chip supplier and high buyer price sensitivity and competition. Many AI companies raise substantial capital but struggle with profitability, similar to historical tech firms like Netscape. Despite this, the technology itself may still advance. AI businesses might succeed by leveraging existing models rather than developing new ones.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# THEMES-Other\n",
      "Nothing to see here!\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "# Non-Selected News Stories\n",
      "‚Ä¢ ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT CONVERSION AGAIN (https://www.theverge.com/2024/11/30/24309697/elon-musk-openai-lawsuit-for-profit-transition-preliminary-injunction):\n",
      "\tScore: 2 (tags: ['Legal', 'OpenAI'])\n",
      "\tSummary: Elon Musk's legal team has filed a motion to prevent OpenAI from transitioning to a for-profit model citing alleged antitrust violations and financial risks. The motion claims CEO Sam Altman's actions could leave the company unable to pay damages if Musk wins his lawsuit.\n",
      "‚Ä¢ PERPLEXITY MULLS GETTING INTO HARDWARE (https://techcrunch.com/2024/11/26/perplexity-mulls-getting-into-hardware/):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Multimodal'])\n",
      "\tSummary: Perplexity's CEO plans to develop a \"simple, under $50\" AI device for voice-to-voice interactions. This aligns with a broader trend of AI startups exploring hardware to enable new interactions, although historical challenges in AI hardware highlight risks. Perplexity, with substantial funding, aims to avoid pitfalls faced by others like Humane's Ai Pin.\n",
      "‚Ä¢ INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAKE NEXT-GENERATION AI\n",
      "MODELS (https://techcrunch.com/2024/11/26/inflection-ceo-says-its-done-competing-to-make-next-generation-ai-models/):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Model'])\n",
      "\tSummary: Inflection AI shifted its focus from developing cutting-edge AI models to providing AI tools for enterprise customers, leveraging current AI models. It has acquired three AI startups to strengthen offerings and is open to licensing models from former competitors. CEO Sean White says the company is focused on practical applications over frontier model development, highlighting on-premise AI solutions for enterprise data security.\n",
      "‚Ä¢ DETECT AND LEARN UNSEEN OBJECTS (https://arxiv.org/abs/2411.18207v1):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Multimodal'])\n",
      "\tSummary: This new framework pushes object detection into open-world scenarios by teaching AI to identify and learn from objects it hasn't seen before.\n",
      "‚Ä¢ MAKING UNDERWATER IMAGES CLEAR (https://arxiv.org/abs/2411.18296v1):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Multimodal'])\n",
      "\tSummary: HUPE is an AI-powered method that improves underwater image clarity while preserving details critical for other tasks like object detection.\n",
      "‚Ä¢ MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID (https://research.google/blog/mapping-the-ionosphere-with-the-power-of-android/):\n",
      "\tScore: 0 (tags: ['Google'])\n",
      "\tSummary: Google researchers were able to accurately map the Ionosphere by using GPS fluctuations and some clever algorithmic work. The task is usually expensive and time consuming. This effort can assist with various climate solutions.\n",
      "‚Ä¢ INTRODUCING LTNTORCH (https://arxiv.org/abs/2409.16045v1):\n",
      "\tScore: 2 (tags: ['Model', 'ML&DL'])\n",
      "\tSummary: Logic Tensor Networks (LTN) merge deep learning with logical reasoning, allowing neural models to learn by optimizing a knowledge base of logical formulas.\n",
      "‚Ä¢ REFINING PRETRAINING DATA PROGRAMMATICALLY (https://gair-nlp.github.io/ProX/homepage.html):\n",
      "\tScore: 2 (tags: ['Model', 'Model Training'])\n",
      "\tSummary: ProX is a framework that treats data refinement as a programming task, allowing models to apply fine-grained operations to individual examples at scale. It improves the quality of pre-training corpora by using small language models to generate programs.\n",
      "‚Ä¢ CHATS WITH VIDEOS IN REAL TIME (https://huggingface.co/wangyueqian/MMDuet):\n",
      "\tScore: 1 (tags: ['AI&GenAI'])\n",
      "\tSummary: MMDuet is a novel \"video-text duet\" interaction format for VideoLLMs that allows AI to provide real-time responses as videos play. The approach mimics a dialogue where both users and AI can exchange messages during playback.\n",
      "‚Ä¢ ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE WRITING STYLE (https://www.theverge.com/2024/11/26/24306575/anthropic-claude-ai-custom-style-presets):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Anthropic'])\n",
      "\tSummary: Anthropic's Claude AI now offers customizable response styles, allowing users to adjust tone and length for different writing tasks.\n",
      "‚Ä¢ CONVERTING GPT TO LLAMA (https://github.com/rasbt/LLMs-from-scratch/tree/main/ch05/07_gpt_to_llama):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Meta'])\n",
      "\tSummary: This repository contains code for converting a GPT implementation to Meta AI's Llama.\n",
      "‚Ä¢ ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL (https://oodaloop.com/briefs/technology/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/):\n",
      "\tScore: 2 (tags: ['Model', 'OpenAI'])\n",
      "\tSummary: Alibaba has released QwQ-32B-Preview, an ‚Äòopen' challenger to OpenAI's o1 reasoning model.\n",
      "‚Ä¢ THUNDERKITTENS FOR APPLE SILICON (https://hazyresearch.stanford.edu/blog/2024-11-28-tk-mlx):\n",
      "\tScore: 1 (tags: ['AI&GenAI'])\n",
      "\tSummary: Hazy Research has been critical in improving hardware utilization for AI workloads. It has extended its amazing ThunderKittens Kernel writing framework to work on Apple Silicon.\n",
      "‚Ä¢ DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR END-TO-END AUTONOMOUS\n",
      "DRIVING (https://arxiv.org/abs/2411.15139):\n",
      "\tScore: 1 (tags: ['Self-Driving Cars'])\n",
      "\tSummary: Diffusion models for End-to-End driving of autonomous vehicles which can operate at 45 FPS on a 4090 chip.\n",
      "‚Ä¢ SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION (https://arxiv.org/abs/2411.17106v1):\n",
      "\tScore: 0 (tags: [])\n",
      "\tSummary: PassionSR introduces an approach that makes diffusion-based image super-resolution (SR) models more hardware-friendly.\n",
      "‚Ä¢ FINE-GRAINED IMAGE QUALITY ASSESSMENT (https://zhengchen1999.github.io/Grounding-IQA-Web/):\n",
      "\tScore: 1 (tags: ['Multimodal'])\n",
      "\tSummary: Grounding-IQA is a new approach to image quality assessment (IQA) that integrates precise location-based grounding and multimodal descriptions.\n",
      "‚Ä¢ THE NEW AI SCALING LAW SHELL GAME (https://garymarcus.substack.com/p/a-new-ai-scaling-law-shell-game):\n",
      "\tScore: 2 (tags: ['AI&GenAI', 'Microsoft'])\n",
      "\tSummary: Recent shifts in AI scaling laws reveal limitations in predictability and effectiveness, with new models not meeting earlier expectations. Microsoft CEO Satya Nadella highlights \"inference time compute\" as a potential area of focus, but concerns about cost and reliability persist. Innovation beyond scaling is needed. LLMs should be part of a broader AI strategy.\n",
      "‚Ä¢ HUMAN IMAGE ANIMATION (https://francis-rings.github.io/StableAnimator/):\n",
      "\tScore: 0 (tags: [])\n",
      "\tSummary: StableAnimator introduces a breakthrough in human image animation by ensuring identity consistency in generated videos.\n",
      "\n",
      "\n",
      "============================================================\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7de0b0ee-de66-4a2d-98cf-7c5591982156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T05:04:35.190434Z",
     "iopub.status.busy": "2025-01-12T05:04:35.190027Z",
     "iopub.status.idle": "2025-01-12T05:04:35.208565Z",
     "shell.execute_reply": "2025-01-12T05:04:35.207226Z",
     "shell.execute_reply.started": "2025-01-12T05:04:35.190385Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"log/2024-11-29_2024-12-02_df_news_stories_20250111235739_v1.0.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b8a5cc-c657-4a9d-a247-6b869978c0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-12T05:04:36.280825Z",
     "iopub.status.busy": "2025-01-12T05:04:36.280349Z",
     "iopub.status.idle": "2025-01-12T05:04:36.329460Z",
     "shell.execute_reply": "2025-01-12T05:04:36.327830Z",
     "shell.execute_reply.started": "2025-01-12T05:04:36.280749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>news_provider</th>\n",
       "      <th>source_of_the_news</th>\n",
       "      <th>text</th>\n",
       "      <th>news_summary</th>\n",
       "      <th>date_source</th>\n",
       "      <th>date_source_time_zone</th>\n",
       "      <th>version</th>\n",
       "      <th>competitive_intelligence</th>\n",
       "      <th>themes</th>\n",
       "      <th>market_intelligence</th>\n",
       "      <th>personalities</th>\n",
       "      <th>score_category_count</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>included_in_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...</td>\n",
       "      <td>https://www.theverge.com/2024/11/30/24309697/e...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Elon Musk's legal team has filed a motion to p...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Legal]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PERPLEXITY MULLS GETTING INTO HARDWARE</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/perplexity-m...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Perplexity's CEO plans to develop a \"simple, u...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...</td>\n",
       "      <td>https://techcrunch.com/2024/11/26/inflection-c...</td>\n",
       "      <td>techcrunch.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Inflection AI shifted its focus from developin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Model]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DETECT AND LEARN UNSEEN OBJECTS</td>\n",
       "      <td>https://arxiv.org/abs/2411.18207v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This new framework pushes object detection int...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAKING UNDERWATER IMAGES CLEAR</td>\n",
       "      <td>https://arxiv.org/abs/2411.18296v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>HUPE is an AI-powered method that improves und...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI, Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID</td>\n",
       "      <td>https://research.google/blog/mapping-the-ionos...</td>\n",
       "      <td>research.google</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Google researchers were able to accurately map...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Google]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>INTRODUCING LTNTORCH</td>\n",
       "      <td>https://arxiv.org/abs/2409.16045v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Logic Tensor Networks (LTN) merge deep learnin...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, ML&amp;DL]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>59</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REFINING PRETRAINING DATA PROGRAMMATICALLY</td>\n",
       "      <td>https://gair-nlp.github.io/ProX/homepage.html</td>\n",
       "      <td>gair-nlp.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>ProX is a framework that treats data refinemen...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model, Model Training]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CHATS WITH VIDEOS IN REAL TIME</td>\n",
       "      <td>https://huggingface.co/wangyueqian/MMDuet</td>\n",
       "      <td>huggingface.co</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>MMDuet is a novel \"video-text duet\" interactio...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...</td>\n",
       "      <td>https://www.theverge.com/2024/11/26/24306575/a...</td>\n",
       "      <td>www.theverge.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Anthropic's Claude AI now offers customizable ...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Anthropic]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CONVERTING GPT TO LLAMA</td>\n",
       "      <td>https://github.com/rasbt/LLMs-from-scratch/tre...</td>\n",
       "      <td>github.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>This repository contains code for converting a...</td>\n",
       "      <td>2024-12-02 09:29:42-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Meta]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL</td>\n",
       "      <td>https://oodaloop.com/briefs/technology/alibaba...</td>\n",
       "      <td>oodaloop.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Alibaba has released QwQ-32B-Preview, an ‚Äòopen...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Model]</td>\n",
       "      <td>[OpenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>THUNDERKITTENS FOR APPLE SILICON</td>\n",
       "      <td>https://hazyresearch.stanford.edu/blog/2024-11...</td>\n",
       "      <td>hazyresearch.stanford.edu</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Hazy Research has been critical in improving h...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...</td>\n",
       "      <td>https://arxiv.org/abs/2411.15139</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Diffusion models for End-to-End driving of aut...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Self-Driving Cars]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION</td>\n",
       "      <td>https://arxiv.org/abs/2411.17106v1</td>\n",
       "      <td>arxiv.org</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>PassionSR introduces an approach that makes di...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FINE-GRAINED IMAGE QUALITY ASSESSMENT</td>\n",
       "      <td>https://zhengchen1999.github.io/Grounding-IQA-...</td>\n",
       "      <td>zhengchen1999.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Grounding-IQA is a new approach to image quali...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Multimodal]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>THE NEW AI SCALING LAW SHELL GAME</td>\n",
       "      <td>https://garymarcus.substack.com/p/a-new-ai-sca...</td>\n",
       "      <td>garymarcus.substack.com</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>Recent shifts in AI scaling laws reveal limita...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[AI&amp;GenAI]</td>\n",
       "      <td>[Microsoft]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HUMAN IMAGE ANIMATION</td>\n",
       "      <td>https://francis-rings.github.io/StableAnimator/</td>\n",
       "      <td>francis-rings.github.io</td>\n",
       "      <td>TLDR AI &lt;dan@tldrnewsletter.com&gt;</td>\n",
       "      <td></td>\n",
       "      <td>StableAnimator introduces a breakthrough in hu...</td>\n",
       "      <td>2024-11-29 09:16:46-05:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   ELON MUSK SEEKS TO BLOCK OPENAI'S FOR-PROFIT C...   \n",
       "1              PERPLEXITY MULLS GETTING INTO HARDWARE   \n",
       "2   INFLECTION AI CEO SAYS IT'S DONE TRYING TO MAK...   \n",
       "4                     DETECT AND LEARN UNSEEN OBJECTS   \n",
       "5                      MAKING UNDERWATER IMAGES CLEAR   \n",
       "6    MAPPING THE IONOSPHERE WITH THE POWER OF ANDROID   \n",
       "7                                INTRODUCING LTNTORCH   \n",
       "8          REFINING PRETRAINING DATA PROGRAMMATICALLY   \n",
       "9                      CHATS WITH VIDEOS IN REAL TIME   \n",
       "13  ANTHROPIC SAYS CLAUDE AI CAN MATCH YOUR UNIQUE...   \n",
       "14                            CONVERTING GPT TO LLAMA   \n",
       "15   ALIBABA CHALLENGING OPENAI'S O1 WITH A NEW MODEL   \n",
       "18                   THUNDERKITTENS FOR APPLE SILICON   \n",
       "19  DIFFUSIONDRIVE: TRUNCATED DIFFUSION MODEL FOR ...   \n",
       "20         SUPER-RESOLUTION WITH LOW-BIT QUANTIZATION   \n",
       "21              FINE-GRAINED IMAGE QUALITY ASSESSMENT   \n",
       "24                  THE NEW AI SCALING LAW SHELL GAME   \n",
       "25                              HUMAN IMAGE ANIMATION   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://www.theverge.com/2024/11/30/24309697/e...   \n",
       "1   https://techcrunch.com/2024/11/26/perplexity-m...   \n",
       "2   https://techcrunch.com/2024/11/26/inflection-c...   \n",
       "4                  https://arxiv.org/abs/2411.18207v1   \n",
       "5                  https://arxiv.org/abs/2411.18296v1   \n",
       "6   https://research.google/blog/mapping-the-ionos...   \n",
       "7                  https://arxiv.org/abs/2409.16045v1   \n",
       "8       https://gair-nlp.github.io/ProX/homepage.html   \n",
       "9           https://huggingface.co/wangyueqian/MMDuet   \n",
       "13  https://www.theverge.com/2024/11/26/24306575/a...   \n",
       "14  https://github.com/rasbt/LLMs-from-scratch/tre...   \n",
       "15  https://oodaloop.com/briefs/technology/alibaba...   \n",
       "18  https://hazyresearch.stanford.edu/blog/2024-11...   \n",
       "19                   https://arxiv.org/abs/2411.15139   \n",
       "20                 https://arxiv.org/abs/2411.17106v1   \n",
       "21  https://zhengchen1999.github.io/Grounding-IQA-...   \n",
       "24  https://garymarcus.substack.com/p/a-new-ai-sca...   \n",
       "25    https://francis-rings.github.io/StableAnimator/   \n",
       "\n",
       "                news_provider                source_of_the_news text  \\\n",
       "0            www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "1              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "2              techcrunch.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "4                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "5                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "6             research.google  TLDR AI <dan@tldrnewsletter.com>        \n",
       "7                   arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "8          gair-nlp.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "9              huggingface.co  TLDR AI <dan@tldrnewsletter.com>        \n",
       "13           www.theverge.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "14                 github.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "15               oodaloop.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "18  hazyresearch.stanford.edu  TLDR AI <dan@tldrnewsletter.com>        \n",
       "19                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "20                  arxiv.org  TLDR AI <dan@tldrnewsletter.com>        \n",
       "21    zhengchen1999.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "24    garymarcus.substack.com  TLDR AI <dan@tldrnewsletter.com>        \n",
       "25    francis-rings.github.io  TLDR AI <dan@tldrnewsletter.com>        \n",
       "\n",
       "                                         news_summary  \\\n",
       "0   Elon Musk's legal team has filed a motion to p...   \n",
       "1   Perplexity's CEO plans to develop a \"simple, u...   \n",
       "2   Inflection AI shifted its focus from developin...   \n",
       "4   This new framework pushes object detection int...   \n",
       "5   HUPE is an AI-powered method that improves und...   \n",
       "6   Google researchers were able to accurately map...   \n",
       "7   Logic Tensor Networks (LTN) merge deep learnin...   \n",
       "8   ProX is a framework that treats data refinemen...   \n",
       "9   MMDuet is a novel \"video-text duet\" interactio...   \n",
       "13  Anthropic's Claude AI now offers customizable ...   \n",
       "14  This repository contains code for converting a...   \n",
       "15  Alibaba has released QwQ-32B-Preview, an ‚Äòopen...   \n",
       "18  Hazy Research has been critical in improving h...   \n",
       "19  Diffusion models for End-to-End driving of aut...   \n",
       "20  PassionSR introduces an approach that makes di...   \n",
       "21  Grounding-IQA is a new approach to image quali...   \n",
       "24  Recent shifts in AI scaling laws reveal limita...   \n",
       "25  StableAnimator introduces a breakthrough in hu...   \n",
       "\n",
       "                 date_source date_source_time_zone version  \\\n",
       "0  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "1  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "2  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "4  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "5  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "6  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "7  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "8  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "9  2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "13 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "14 2024-12-02 09:29:42-05:00            US/Eastern     1.0   \n",
       "15 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "18 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "19 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "20 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "21 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "24 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "25 2024-11-29 09:16:46-05:00            US/Eastern     1.0   \n",
       "\n",
       "   competitive_intelligence                   themes market_intelligence  \\\n",
       "0                        []                  [Legal]            [OpenAI]   \n",
       "1                        []   [AI&GenAI, Multimodal]                  []   \n",
       "2                        []        [AI&GenAI, Model]                  []   \n",
       "4                        []   [AI&GenAI, Multimodal]                  []   \n",
       "5                        []   [AI&GenAI, Multimodal]                  []   \n",
       "6                        []                       []            [Google]   \n",
       "7                        []           [Model, ML&DL]                  []   \n",
       "8                        []  [Model, Model Training]                  []   \n",
       "9                        []               [AI&GenAI]                  []   \n",
       "13                       []               [AI&GenAI]         [Anthropic]   \n",
       "14                       []               [AI&GenAI]              [Meta]   \n",
       "15                       []                  [Model]            [OpenAI]   \n",
       "18                       []               [AI&GenAI]                  []   \n",
       "19                       []      [Self-Driving Cars]                  []   \n",
       "20                       []                       []                  []   \n",
       "21                       []             [Multimodal]                  []   \n",
       "24                       []               [AI&GenAI]         [Microsoft]   \n",
       "25                       []                       []                  []   \n",
       "\n",
       "   personalities  score_category_count  unique_id  included_in_report  \n",
       "0             []                     2         52               False  \n",
       "1             []                     2         53               False  \n",
       "2             []                     2         54               False  \n",
       "4             []                     2         56               False  \n",
       "5             []                     2         57               False  \n",
       "6             []                     0         58               False  \n",
       "7             []                     2         59               False  \n",
       "8             []                     2         60               False  \n",
       "9             []                     1         61               False  \n",
       "13            []                     2         65               False  \n",
       "14            []                     2         66               False  \n",
       "15            []                     2         67               False  \n",
       "18            []                     1         70               False  \n",
       "19            []                     1         71               False  \n",
       "20            []                     0         72               False  \n",
       "21            []                     1         73               False  \n",
       "24            []                     2         76               False  \n",
       "25            []                     0         77               False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[~df[\"included_in_report\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c7ba6-6679-4de1-bcbc-d4ed1291b1ba",
   "metadata": {},
   "source": [
    "# Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b9ec205-2dec-4bb6-9f8b-b63ea6cf67ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T04:12:22.349180Z",
     "iopub.status.busy": "2025-01-15T04:12:22.348805Z",
     "iopub.status.idle": "2025-01-15T04:12:22.428096Z",
     "shell.execute_reply": "2025-01-15T04:12:22.384018Z",
     "shell.execute_reply.started": "2025-01-15T04:12:22.349117Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.io.text import load_from_text, save_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e992befe-98b8-4fe9-907f-b61bcda7994d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T04:12:22.581548Z",
     "iopub.status.busy": "2025-01-15T04:12:22.581115Z",
     "iopub.status.idle": "2025-01-15T04:12:22.588353Z",
     "shell.execute_reply": "2025-01-15T04:12:22.587210Z",
     "shell.execute_reply.started": "2025-01-15T04:12:22.581525Z"
    }
   },
   "outputs": [],
   "source": [
    "txt = load_from_text(\"/home/logs/report_date.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed9b77e-d2dc-492d-90ce-fbdcd7862238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T04:12:23.093295Z",
     "iopub.status.busy": "2025-01-15T04:12:23.092939Z",
     "iopub.status.idle": "2025-01-15T04:12:23.105387Z",
     "shell.execute_reply": "2025-01-15T04:12:23.104182Z",
     "shell.execute_reply.started": "2025-01-15T04:12:23.093267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-12-01\\n2025-01-12'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005480fb-5420-4611-801d-4c4f8d4f8576",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T04:12:33.863929Z",
     "iopub.status.busy": "2025-01-15T04:12:33.863482Z",
     "iopub.status.idle": "2025-01-15T04:12:33.871212Z",
     "shell.execute_reply": "2025-01-15T04:12:33.868291Z",
     "shell.execute_reply.started": "2025-01-15T04:12:33.863897Z"
    }
   },
   "outputs": [],
   "source": [
    "from src.utils.date import add_days_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d59a87a-ae6f-4d86-aec9-8416272f175c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T04:12:50.940106Z",
     "iopub.status.busy": "2025-01-15T04:12:50.939735Z",
     "iopub.status.idle": "2025-01-15T04:12:50.949367Z",
     "shell.execute_reply": "2025-01-15T04:12:50.948211Z",
     "shell.execute_reply.started": "2025-01-15T04:12:50.940081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-02-16'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_days_str(\"2024-02-28\", -12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63540bab-7665-4953-a8f1-3a344c5941fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
