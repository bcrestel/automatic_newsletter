{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e4e67ef-738a-44f6-8f69-5df41ec65b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:09:04.934496Z",
     "iopub.status.busy": "2025-01-30T22:09:04.933678Z",
     "iopub.status.idle": "2025-01-30T22:09:04.949136Z",
     "shell.execute_reply": "2025-01-30T22:09:04.946625Z",
     "shell.execute_reply.started": "2025-01-30T22:09:04.934451Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s -- l.%(lineno)d: %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0c913b6-9110-4fb0-a6b8-2f67bcfb92e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:09:04.950855Z",
     "iopub.status.busy": "2025-01-30T22:09:04.950569Z",
     "iopub.status.idle": "2025-01-30T22:09:04.958773Z",
     "shell.execute_reply": "2025-01-30T22:09:04.957238Z",
     "shell.execute_reply.started": "2025-01-30T22:09:04.950831Z"
    }
   },
   "outputs": [],
   "source": [
    "#system_prompt = \"You are a university-level physics professor teaching a graduate course in Physics.\"\n",
    "system_prompt = \"You are kindergarden teacher who introduces elementary physics concetps to a group of 5 year old in a language that they can understand.\"\n",
    "prompt = \"Explain nuclear fusion in 5 sentences or less.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225dea5-4737-4132-b26b-1ab60dd7141c",
   "metadata": {},
   "source": [
    "# Test GenAIModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac35b947-3a68-44e6-9a6d-a596cbb144c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:09:04.960393Z",
     "iopub.status.busy": "2025-01-30T22:09:04.960110Z",
     "iopub.status.idle": "2025-01-30T22:09:06.719651Z",
     "shell.execute_reply": "2025-01-30T22:09:06.718811Z",
     "shell.execute_reply.started": "2025-01-30T22:09:04.960338Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:09:05,992 - httpx - INFO -- l.1027: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from src.genai_model.genai_model import GenAIModel\n",
    "from src.utils.list import flatten_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfff21ec-a912-433b-8d00-c096ee201ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:10:47.524079Z",
     "iopub.status.busy": "2025-01-30T22:10:47.523701Z",
     "iopub.status.idle": "2025-01-30T22:10:47.537809Z",
     "shell.execute_reply": "2025-01-30T22:10:47.536060Z",
     "shell.execute_reply.started": "2025-01-30T22:10:47.524050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:10:47,525 - src.genai_model.genai_model - INFO -- l.81: Found 4 models for model_type gemini-2.0\n",
      "2025-01-30 17:10:47,526 - src.genai_model.genai_model - INFO -- l.82: List of models included: ['gemini/gemini-2.0-flash-thinking-exp-01-21', 'openrouter/google/gemini-2.0-flash-thinking-exp:free', 'gemini/gemini-2.0-flash-thinking-exp-1219', 'openrouter/google/gemini-2.0-flash-thinking-exp-1219:free']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp:free',\n",
       " 'gemini/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp-1219:free']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = GenAIModel(model_type=\"gemini-2.0\", system_promt=system_prompt)\n",
    "_model.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63103a8f-7179-438e-bc59-5577a619846b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T22:09:22.659412Z",
     "iopub.status.busy": "2025-01-30T22:09:22.658977Z",
     "iopub.status.idle": "2025-01-30T22:09:22.672747Z",
     "shell.execute_reply": "2025-01-30T22:09:22.670951Z",
     "shell.execute_reply.started": "2025-01-30T22:09:22.659381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 17:09:22,660 - src.genai_model.genai_model - INFO -- l.81: Found 7 models for model_type large\n",
      "2025-01-30 17:09:22,662 - src.genai_model.genai_model - INFO -- l.82: List of models included: ['gemini/gemini-1.5-pro-002', 'gemini/gemini-1.5-pro-exp-0827', 'openrouter/meta-llama/llama-3.1-405b-instruct:free', 'gemini/gemini-1.5-pro-001', 'mistral/mistral-large-2411', 'mistral/mistral-large-2407', 'mistral/mistral-large-2402']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-1.5-pro-002',\n",
       " 'gemini/gemini-1.5-pro-exp-0827',\n",
       " 'openrouter/meta-llama/llama-3.1-405b-instruct:free',\n",
       " 'gemini/gemini-1.5-pro-001',\n",
       " 'mistral/mistral-large-2411',\n",
       " 'mistral/mistral-large-2407',\n",
       " 'mistral/mistral-large-2402']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large = GenAIModel(model_type=\"large\", system_promt=system_prompt)\n",
    "model_large.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8cd4e8-7dbc-4c66-bad8-b8614cdf1de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:56:12.235809Z",
     "iopub.status.busy": "2025-01-30T14:56:12.235353Z",
     "iopub.status.idle": "2025-01-30T14:56:14.512886Z",
     "shell.execute_reply": "2025-01-30T14:56:14.508496Z",
     "shell.execute_reply.started": "2025-01-30T14:56:12.235771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m09:56:12 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "2025-01-30 09:56:12,238 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "2025-01-30 09:56:14,485 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:56:14 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-01-30 09:56:14,491 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-e289b6d8-bc0d-4a74-9349-2fec8bdf4326', created=1738248972, model='gemini-1.5-pro-002', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Imagine tiny bouncing balls, way smaller than you can even see!  Sometimes, if they bump *really* hard and fast, they stick together and make a bigger ball.  When they stick, they get a little bit hotter and make a tiny spark of energy.  The sun does this with lots of tiny balls, making it big and bright and warm!  That's called fusion.\\n\", role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=81, prompt_tokens=39, total_tokens=120, completion_tokens_details=None, prompt_tokens_details=None), vertex_ai_grounding_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large.completion(user_prompt=prompt, parameters={\"temperature\": 0.5, \"top_p\": 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710aa8-94c8-4f26-b71c-af2d8f71c755",
   "metadata": {},
   "source": [
    "# Test LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79bda238-758d-4ad8-9c82-12ff0cd5300d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:51:27.290536Z",
     "iopub.status.busy": "2025-01-30T14:51:27.289938Z",
     "iopub.status.idle": "2025-01-30T14:51:29.407012Z",
     "shell.execute_reply": "2025-01-30T14:51:29.406240Z",
     "shell.execute_reply.started": "2025-01-30T14:51:27.290502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 09:51:28,484 - httpx - INFO -- l.1027: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edbb2b57-06d0-4f17-b287-516d232a6a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:51:33.819672Z",
     "iopub.status.busy": "2025-01-30T14:51:33.818149Z",
     "iopub.status.idle": "2025-01-30T14:51:33.824951Z",
     "shell.execute_reply": "2025-01-30T14:51:33.823263Z",
     "shell.execute_reply.started": "2025-01-30T14:51:33.819641Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_models = {\n",
    "    \"Gemini\": \"gemini/gemini-1.5-pro-002\",\n",
    "    \"OpenRouter\": \"openrouter/meta-llama/llama-3.1-405b-instruct:free\",\n",
    "    \"Mistral\": \"mistral/mistral-large-2411\",\n",
    "    \"Groq\": \"groq/llama3-70b-8192\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cd3b494-33f0-4076-b57e-6a0ca957b30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T14:52:51.019601Z",
     "iopub.status.busy": "2025-01-30T14:52:51.019263Z",
     "iopub.status.idle": "2025-01-30T14:52:53.311718Z",
     "shell.execute_reply": "2025-01-30T14:52:53.310098Z",
     "shell.execute_reply.started": "2025-01-30T14:52:51.019575Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m09:52:51 - LiteLLM:INFO\u001b[0m: utils.py:2752 - \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "2025-01-30 09:52:51,023 - LiteLLM - INFO -- l.2752: \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Using model gemini/gemini-1.5-pro-002 from Gemini:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-30 09:52:53,297 - httpx - INFO -- l.1027: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m09:52:53 - LiteLLM:INFO\u001b[0m: utils.py:890 - Wrapper: Completed Call, calling success_handler\n",
      "2025-01-30 09:52:53,303 - LiteLLM - INFO -- l.890: Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine tiny bouncing balls, smaller than you can even see!  Sometimes these balls crash together *really* hard and stick together, making a bigger ball.  When they stick, they get a little bit hotter and give off a tiny spark of energy, like a tiny firefly.  The sun does this with its tiny balls all the time, making sunshine and keeping us warm! That's called nuclear fusion.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"temperature\": 0.5}\n",
    "\n",
    "for provider, model in list_of_models.items():\n",
    "    print(\"=\"*25)\n",
    "    print(f\"Using model {model} from {provider}:\\n\")\n",
    "    try:\n",
    "        response_l = completion(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            **parameters\n",
    "        )\n",
    "        print(response_l['choices'][0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"The model failed, raising the following exception: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bba9c2-dab7-4830-82fd-1fc7658c252b",
   "metadata": {},
   "source": [
    "# Test fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b68ad5f-68c7-446a-bc2e-e9d2da8f78f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T03:56:34.657597Z",
     "iopub.status.busy": "2025-01-30T03:56:34.657306Z",
     "iopub.status.idle": "2025-01-30T03:56:57.994602Z",
     "shell.execute_reply": "2025-01-30T03:56:57.992906Z",
     "shell.execute_reply.started": "2025-01-30T03:56:34.657573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuclear fusion is a process where two or more atomic nuclei combine to form a single, heavier nucleus, releasing a vast amount of energy in the process. This process is the opposite of nuclear fission, where an atomic nucleus splits into lighter nuclei. The most commonly discussed fusion reaction is the deuterium-tritium (D-T) reaction, where a deuterium nucleus (one proton and one neutron) combines with a tritium nucleus (one proton and two neutrons) to form a helium nucleus and a high-energy neutron. The energy released in fusion reactions is several orders of magnitude greater than that released in chemical reactions, making it a promising source of clean and sustainable energy. However, achieving controlled nuclear fusion has proven to be a significant technical challenge due to the extremely high temperatures and pressures required to initiate and sustain the reaction.\n"
     ]
    }
   ],
   "source": [
    "ll_models = list(list_of_models.values())\n",
    "response_l = completion(\n",
    "    model=ll_models[-1],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    fallbacks=ll_models[:-1],\n",
    ")\n",
    "print(response_l['choices'][0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "11cce687-be34-441d-945f-18b593c3b32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-30T03:55:21.542865Z",
     "iopub.status.busy": "2025-01-30T03:55:21.542382Z",
     "iopub.status.idle": "2025-01-30T03:55:21.551706Z",
     "shell.execute_reply": "2025-01-30T03:55:21.550598Z",
     "shell.execute_reply.started": "2025-01-30T03:55:21.542840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-63ac749c-900a-40b1-8c28-d0a1b1be1aac', created=1738209284, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Nuclear fusion is the process where two light atomic nuclei combine to form a heavier nucleus, releasing a tremendous amount of energy.  This energy release stems from the conversion of a small amount of mass into energy, as described by Einstein's famous equation, E=mc².  The process requires overcoming the electrostatic repulsion between the positively charged nuclei, typically through extremely high temperatures and pressures.  Fusion powers the sun and other stars.  Harnessing fusion energy on Earth remains a significant technological challenge, but offers a potentially clean and virtually limitless energy source.\\n\", role='assistant', tool_calls=None, function_call=None))], usage=Usage(completion_tokens=110, prompt_tokens=26, total_tokens=136, completion_tokens_details=None, prompt_tokens_details=None), vertex_ai_grounding_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[{'citationSources': [{'endIndex': 129}]}])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21dba7-d218-4131-a014-49892a9af702",
   "metadata": {},
   "source": [
    "# Compare Gemini and Groq models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95993511-577f-4132-abda-1a21be446986",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e8545f-28c4-4e8c-a009-1476b7e480c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:42:10.718515Z",
     "iopub.status.busy": "2025-01-29T02:42:10.718134Z",
     "iopub.status.idle": "2025-01-29T02:42:13.587027Z",
     "shell.execute_reply": "2025-01-29T02:42:13.586251Z",
     "shell.execute_reply.started": "2025-01-29T02:42:10.718464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b96bfb0-a3f4-447e-a5d9-c7b75ab23f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:57.152219Z",
     "iopub.status.busy": "2025-01-28T20:59:57.151832Z",
     "iopub.status.idle": "2025-01-28T20:59:57.158810Z",
     "shell.execute_reply": "2025-01-28T20:59:57.157196Z",
     "shell.execute_reply.started": "2025-01-28T20:59:57.152191Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gemini-1.5-flash\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2be53e0a-e5b4-414d-beb7-b94bb9ee0078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:57.859923Z",
     "iopub.status.busy": "2025-01-28T20:59:57.859328Z",
     "iopub.status.idle": "2025-01-28T20:59:58.626254Z",
     "shell.execute_reply": "2025-01-28T20:59:58.624962Z",
     "shell.execute_reply.started": "2025-01-28T20:59:57.859897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e492321-bf28-46a9-9297-2db44bded706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:58.630575Z",
     "iopub.status.busy": "2025-01-28T20:59:58.629294Z",
     "iopub.status.idle": "2025-01-28T20:59:59.552332Z",
     "shell.execute_reply": "2025-01-28T20:59:59.551195Z",
     "shell.execute_reply.started": "2025-01-28T20:59:58.630528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/gemini\n",
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ea8bc-dc58-4fcb-af05-0960f696b203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check reproducibility in the case temperature=0.0 and top_p < 1.0\n",
    "In the case top_p = 1.0, I would still get some stochasticity, probably since temperature=0.0 is approximated algorithmically (using eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1d2e76f-6035-4fee-a34d-4d02035f93e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:37.955872Z",
     "iopub.status.busy": "2025-01-28T20:53:37.955465Z",
     "iopub.status.idle": "2025-01-28T20:53:38.837304Z",
     "shell.execute_reply": "2025-01-28T20:53:38.835959Z",
     "shell.execute_reply.started": "2025-01-28T20:53:37.955841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1c79a17-1e4a-45df-a65f-599da71c07b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:39.587496Z",
     "iopub.status.busy": "2025-01-28T20:53:39.587117Z",
     "iopub.status.idle": "2025-01-28T20:53:40.349271Z",
     "shell.execute_reply": "2025-01-28T20:53:40.347870Z",
     "shell.execute_reply.started": "2025-01-28T20:53:39.587468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b7272d8-7d12-47f5-bc70-3bfc698766a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:40.941653Z",
     "iopub.status.busy": "2025-01-28T20:53:40.941148Z",
     "iopub.status.idle": "2025-01-28T20:53:41.791465Z",
     "shell.execute_reply": "2025-01-28T20:53:41.789924Z",
     "shell.execute_reply.started": "2025-01-28T20:53:40.941623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a329a4-ae1f-4b97-8987-2712976bafb6",
   "metadata": {},
   "source": [
    "## Compare Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47305b29-b45e-4181-b9b4-9581b878a088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:27.516968Z",
     "iopub.status.busy": "2025-01-28T21:00:27.516558Z",
     "iopub.status.idle": "2025-01-28T21:00:27.524554Z",
     "shell.execute_reply": "2025-01-28T21:00:27.523009Z",
     "shell.execute_reply.started": "2025-01-28T21:00:27.516939Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a035767f-fe04-4414-8b5e-9933d86287f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:27.875371Z",
     "iopub.status.busy": "2025-01-28T21:00:27.875073Z",
     "iopub.status.idle": "2025-01-28T21:00:28.686141Z",
     "shell.execute_reply": "2025-01-28T21:00:28.684826Z",
     "shell.execute_reply.started": "2025-01-28T21:00:27.875346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI is a leading artificial intelligence research organization that aims to develop and promote friendly AI that benefits humanity. Founded in 2015, OpenAI is known for its cutting-edge AI models, including language models like GPT-3 and DALL-E, which have achieved state-of-the-art results in various AI tasks. The organization is committed to transparency, open-source development, and responsible AI practices, and its research and technologies have far-reaching implications for fields such as natural language processing, computer vision, and robotics.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "    model=model_name,\n",
    "    **param\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f18051be-6b7c-4d85-b11d-4b08fc78715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:28.688517Z",
     "iopub.status.busy": "2025-01-28T21:00:28.688096Z",
     "iopub.status.idle": "2025-01-28T21:00:29.556525Z",
     "shell.execute_reply": "2025-01-28T21:00:29.555822Z",
     "shell.execute_reply.started": "2025-01-28T21:00:28.688490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research organization that aims to develop and promote friendly AI that benefits humanity. Founded in 2015, OpenAI is known for its cutting-edge AI models, including language models like GPT-3 and DALL-E, which have achieved state-of-the-art results in various AI tasks. The organization is committed to transparency, open-source development, and responsible AI practices, and its research and technologies have far-reaching implications for fields such as natural language processing, computer vision, and robotics.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/groq\n",
    "response_l = completion(\n",
    "    model=f\"groq/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618955e-48ae-4f7c-8900-ca6d65fc79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87a7bf-e71d-43bb-bf78-1778ece36acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
