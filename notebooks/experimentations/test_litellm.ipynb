{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4e67ef-738a-44f6-8f69-5df41ec65b02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:31.399879Z",
     "iopub.status.busy": "2025-02-09T04:33:31.399576Z",
     "iopub.status.idle": "2025-02-09T04:33:31.404925Z",
     "shell.execute_reply": "2025-02-09T04:33:31.403983Z",
     "shell.execute_reply.started": "2025-02-09T04:33:31.399858Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s -- l.%(lineno)d: %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0c913b6-9110-4fb0-a6b8-2f67bcfb92e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:31.702297Z",
     "iopub.status.busy": "2025-02-09T04:33:31.701904Z",
     "iopub.status.idle": "2025-02-09T04:33:31.709577Z",
     "shell.execute_reply": "2025-02-09T04:33:31.707825Z",
     "shell.execute_reply.started": "2025-02-09T04:33:31.702267Z"
    }
   },
   "outputs": [],
   "source": [
    "#system_prompt = \"You are a university-level physics professor teaching a graduate course in Physics.\"\n",
    "system_prompt = \"You are kindergarden teacher who introduces elementary physics concetps to a group of 5 year old in a language that they can understand.\"\n",
    "prompt = \"Explain nuclear fusion in 5 sentences or less.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5225dea5-4737-4132-b26b-1ab60dd7141c",
   "metadata": {},
   "source": [
    "# Test GenAIModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac35b947-3a68-44e6-9a6d-a596cbb144c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:32.808376Z",
     "iopub.status.busy": "2025-02-09T04:33:32.807940Z",
     "iopub.status.idle": "2025-02-09T04:33:35.195872Z",
     "shell.execute_reply": "2025-02-09T04:33:35.195338Z",
     "shell.execute_reply.started": "2025-02-09T04:33:32.808341Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:33:34,337 - httpx - INFO -- l.1025: HTTP Request: GET https://raw.githubusercontent.com/BerriAI/litellm/main/model_prices_and_context_window.json \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from src.genai_model.genai_model import GenAIModel\n",
    "from src.utils.list import flatten_list_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfff21ec-a912-433b-8d00-c096ee201ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:35.197524Z",
     "iopub.status.busy": "2025-02-09T04:33:35.196723Z",
     "iopub.status.idle": "2025-02-09T04:33:35.209581Z",
     "shell.execute_reply": "2025-02-09T04:33:35.208929Z",
     "shell.execute_reply.started": "2025-02-09T04:33:35.197503Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:33:35,199 - src.genai_model.genai_model - INFO -- l.92: Found 6 models for model_type gemini-2.0\n",
      "2025-02-08 23:33:35,200 - src.genai_model.genai_model - INFO -- l.95: List of models included: ['gemini/gemini-2.0-flash-thinking-exp-01-21', 'openrouter/google/gemini-2.0-flash-thinking-exp:free', 'gemini/gemini-2.0-flash-thinking-exp-1219', 'openrouter/google/gemini-2.0-flash-thinking-exp-1219:free', 'gemini/gemini-2.0-flash-exp', 'openrouter/google/gemini-2.0-flash-exp:free']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-2.0-flash-thinking-exp-01-21',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp:free',\n",
       " 'gemini/gemini-2.0-flash-thinking-exp-1219',\n",
       " 'openrouter/google/gemini-2.0-flash-thinking-exp-1219:free',\n",
       " 'gemini/gemini-2.0-flash-exp',\n",
       " 'openrouter/google/gemini-2.0-flash-exp:free']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_model = GenAIModel(model_type=\"gemini-2.0\", system_promt=system_prompt)\n",
    "_model.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63103a8f-7179-438e-bc59-5577a619846b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:35.210987Z",
     "iopub.status.busy": "2025-02-09T04:33:35.210189Z",
     "iopub.status.idle": "2025-02-09T04:33:35.221095Z",
     "shell.execute_reply": "2025-02-09T04:33:35.219745Z",
     "shell.execute_reply.started": "2025-02-09T04:33:35.210964Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:33:35,212 - src.genai_model.genai_model - INFO -- l.92: Found 13 models for model_type large\n",
      "2025-02-08 23:33:35,214 - src.genai_model.genai_model - INFO -- l.95: List of models included: ['gemini/gemini-exp-1206', 'openrouter/google/gemini-exp-1206:free', 'gemini/gemini-exp-1121', 'openrouter/google/gemini-exp-1121:free', 'gemini/gemini-exp-1114', 'openrouter/google/gemini-exp-1114:free', 'gemini/gemini-1.5-pro-002', 'gemini/gemini-1.5-pro-exp-0827', 'openrouter/meta-llama/llama-3.1-405b-instruct:free', 'gemini/gemini-1.5-pro-001', 'mistral/mistral-large-2411', 'mistral/mistral-large-2407', 'mistral/mistral-large-2402']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gemini/gemini-exp-1206',\n",
       " 'openrouter/google/gemini-exp-1206:free',\n",
       " 'gemini/gemini-exp-1121',\n",
       " 'openrouter/google/gemini-exp-1121:free',\n",
       " 'gemini/gemini-exp-1114',\n",
       " 'openrouter/google/gemini-exp-1114:free',\n",
       " 'gemini/gemini-1.5-pro-002',\n",
       " 'gemini/gemini-1.5-pro-exp-0827',\n",
       " 'openrouter/meta-llama/llama-3.1-405b-instruct:free',\n",
       " 'gemini/gemini-1.5-pro-001',\n",
       " 'mistral/mistral-large-2411',\n",
       " 'mistral/mistral-large-2407',\n",
       " 'mistral/mistral-large-2402']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large = GenAIModel(model_type=\"large\", system_promt=system_prompt)\n",
    "model_large.list_of_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8cd4e8-7dbc-4c66-bad8-b8614cdf1de7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:35.225083Z",
     "iopub.status.busy": "2025-02-09T04:33:35.223258Z",
     "iopub.status.idle": "2025-02-09T04:33:37.414242Z",
     "shell.execute_reply": "2025-02-09T04:33:37.413214Z",
     "shell.execute_reply.started": "2025-02-09T04:33:35.225038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:33:35 - LiteLLM:INFO\u001b[0m: utils.py:2909 - \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-08 23:33:35,237 - LiteLLM - INFO -- l.2909: \n",
      "LiteLLM completion() model= gemini-exp-1206; provider = gemini\n",
      "2025-02-08 23:33:37,402 - httpx - INFO -- l.1025: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-exp-1206:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m23:33:37 - LiteLLM:INFO\u001b[0m: utils.py:1085 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-08 23:33:37,405 - LiteLLM - INFO -- l.1085: Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-5736a199-2068-4480-8467-f9d1d1906177', created=1739075615, model='gemini-exp-1206', object='chat.completion', system_fingerprint=None, choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Okay, class! Imagine you have two tiny little LEGO bricks, so small you can barely see them!  Nuclear fusion is like smashing those tiny LEGOs together *really, really* hard. When they stick together, they make a slightly bigger LEGO, and whoosh! A lot of energy, like a tiny firework, pops out! That energy is what makes the sun shine so bright and warm. It's like the sun is a giant LEGO-smashing machine!\\n\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=97, prompt_tokens=39, total_tokens=136, completion_tokens_details=None, prompt_tokens_details=None), vertex_ai_grounding_metadata=[], vertex_ai_safety_results=[], vertex_ai_citation_metadata=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_large.completion(user_prompt=prompt, parameters={\"temperature\": 0.5, \"top_p\": 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9710aa8-94c8-4f26-b71c-af2d8f71c755",
   "metadata": {},
   "source": [
    "# Test LiteLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79bda238-758d-4ad8-9c82-12ff0cd5300d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:37.415257Z",
     "iopub.status.busy": "2025-02-09T04:33:37.415029Z",
     "iopub.status.idle": "2025-02-09T04:33:37.421060Z",
     "shell.execute_reply": "2025-02-09T04:33:37.418954Z",
     "shell.execute_reply.started": "2025-02-09T04:33:37.415237Z"
    }
   },
   "outputs": [],
   "source": [
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edbb2b57-06d0-4f17-b287-516d232a6a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:37.424751Z",
     "iopub.status.busy": "2025-02-09T04:33:37.423319Z",
     "iopub.status.idle": "2025-02-09T04:33:37.431278Z",
     "shell.execute_reply": "2025-02-09T04:33:37.429474Z",
     "shell.execute_reply.started": "2025-02-09T04:33:37.424719Z"
    }
   },
   "outputs": [],
   "source": [
    "list_of_models = {\n",
    "    \"Gemini\": \"gemini/gemini-1.5-pro-002\",\n",
    "    \"OpenRouter\": \"openrouter/meta-llama/llama-3.1-405b-instruct:free\",\n",
    "    \"Mistral\": \"mistral/mistral-large-2411\",\n",
    "    \"Groq\": \"groq/llama3-70b-8192\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd3b494-33f0-4076-b57e-6a0ca957b30e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:37.433883Z",
     "iopub.status.busy": "2025-02-09T04:33:37.433278Z",
     "iopub.status.idle": "2025-02-09T04:33:37.731791Z",
     "shell.execute_reply": "2025-02-09T04:33:37.729237Z",
     "shell.execute_reply.started": "2025-02-09T04:33:37.433843Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:33:37 - LiteLLM:INFO\u001b[0m: utils.py:2909 - \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n",
      "2025-02-08 23:33:37,439 - LiteLLM - INFO -- l.2909: \n",
      "LiteLLM completion() model= gemini-1.5-pro-002; provider = gemini\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "Using model gemini/gemini-1.5-pro-002 from Gemini:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-08 23:33:37,705 - httpx - INFO -- l.1025: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-002:generateContent?key=AIzaSyCTCGul8Epux8G_pMEdksxzJOBYwrrqUXY \"HTTP/1.1 503 Service Unavailable\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;31mGive Feedback / Get Help: https://github.com/BerriAI/litellm/issues/new\u001b[0m\n",
      "LiteLLM.Info: If you need to debug this error, use `litellm._turn_on_debug()'.\n",
      "\n",
      "The model failed, raising the following exception: litellm.InternalServerError: litellm.InternalServerError: VertexAIException - {\n",
      "  \"error\": {\n",
      "    \"code\": 503,\n",
      "    \"message\": \"The model is overloaded. Please try again later.\",\n",
      "    \"status\": \"UNAVAILABLE\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"temperature\": 0.5}\n",
    "\n",
    "for provider, model in list_of_models.items():\n",
    "    print(\"=\"*25)\n",
    "    print(f\"Using model {model} from {provider}:\\n\")\n",
    "    try:\n",
    "        response_l = completion(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            **parameters\n",
    "        )\n",
    "        print(response_l['choices'][0].message.content)\n",
    "    except Exception as e:\n",
    "        print(f\"The model failed, raising the following exception: {e}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bba9c2-dab7-4830-82fd-1fc7658c252b",
   "metadata": {},
   "source": [
    "# Test fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b68ad5f-68c7-446a-bc2e-e9d2da8f78f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:47.975510Z",
     "iopub.status.busy": "2025-02-09T04:33:47.975098Z",
     "iopub.status.idle": "2025-02-09T04:33:49.065578Z",
     "shell.execute_reply": "2025-02-09T04:33:49.063699Z",
     "shell.execute_reply.started": "2025-02-09T04:33:47.975424Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m23:33:47 - LiteLLM:INFO\u001b[0m: utils.py:2909 - \n",
      "LiteLLM completion() model= llama3-70b-8192; provider = groq\n",
      "2025-02-08 23:33:47,982 - LiteLLM - INFO -- l.2909: \n",
      "LiteLLM completion() model= llama3-70b-8192; provider = groq\n",
      "2025-02-08 23:33:49,030 - httpx - INFO -- l.1740: HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-02-08 23:33:49,037 - asyncio - ERROR -- l.1785: Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-9' coro=<Logging.async_success_handler() running at /usr/local/lib/python3.11/site-packages/litellm/litellm_core_utils/litellm_logging.py:1515>>\n",
      "/usr/local/lib/python3.11/asyncio/base_events.py:679: RuntimeWarning: coroutine 'Logging.async_success_handler' was never awaited\n",
      "  self._ready.clear()\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "\u001b[92m23:33:49 - LiteLLM:INFO\u001b[0m: utils.py:1085 - Wrapper: Completed Call, calling success_handler\n",
      "2025-02-08 23:33:49,056 - LiteLLM - INFO -- l.1085: Wrapper: Completed Call, calling success_handler\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Oh boy, are you ready for a cool secret about the sun?\n",
      "\n",
      "You know how we need to eat food to have energy to play? Well, the sun is like a super-big eater that eats special tiny things called atoms!\n",
      "\n",
      "When the sun eats these atoms, it squeezes them together really, really tight to make even more energy! This is called nuclear fusion.\n",
      "\n",
      "It's like a big hug for the atoms, and it makes the sun shine super bright and warm for us! Isn't that amazing?\"\n"
     ]
    }
   ],
   "source": [
    "ll_models = list(list_of_models.values())\n",
    "response_l = completion(\n",
    "    model=ll_models[-1],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    fallbacks=ll_models[:-1],\n",
    ")\n",
    "print(response_l['choices'][0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11cce687-be34-441d-945f-18b593c3b32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:33:55.246278Z",
     "iopub.status.busy": "2025-02-09T04:33:55.244995Z",
     "iopub.status.idle": "2025-02-09T04:33:55.256117Z",
     "shell.execute_reply": "2025-02-09T04:33:55.254889Z",
     "shell.execute_reply.started": "2025-02-09T04:33:55.246236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelResponse(id='chatcmpl-6d16b4e0-f9d0-4f93-9344-4b5da5d2c546', created=1739075628, model='groq/llama3-70b-8192', object='chat.completion', system_fingerprint='fp_753a4aecf6', choices=[Choices(finish_reason='stop', index=0, message=Message(content='\"Oh boy, are you ready for a cool secret about the sun?\\n\\nYou know how we need to eat food to have energy to play? Well, the sun is like a super-big eater that eats special tiny things called atoms!\\n\\nWhen the sun eats these atoms, it squeezes them together really, really tight to make even more energy! This is called nuclear fusion.\\n\\nIt\\'s like a big hug for the atoms, and it makes the sun shine super bright and warm for us! Isn\\'t that amazing?\"', role='assistant', tool_calls=None, function_call=None, provider_specific_fields=None))], usage=Usage(completion_tokens=103, prompt_tokens=55, total_tokens=158, completion_tokens_details=None, prompt_tokens_details=None, queue_time=0.232687438, prompt_time=0.005881921, completion_time=0.305952521, total_time=0.311834442), x_groq={'id': 'req_01jkmfrbb2f53beqj1t84ew9ye'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6da1891d-599d-4c80-be8b-b7b730385406",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-09T04:34:22.892371Z",
     "iopub.status.busy": "2025-02-09T04:34:22.891937Z",
     "iopub.status.idle": "2025-02-09T04:34:22.900475Z",
     "shell.execute_reply": "2025-02-09T04:34:22.898870Z",
     "shell.execute_reply.started": "2025-02-09T04:34:22.892291Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'groq/llama3-70b-8192'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce21dba7-d218-4131-a014-49892a9af702",
   "metadata": {},
   "source": [
    "# Compare Gemini and Groq models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95993511-577f-4132-abda-1a21be446986",
   "metadata": {},
   "source": [
    "## Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31e8545f-28c4-4e8c-a009-1476b7e480c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-29T02:42:10.718515Z",
     "iopub.status.busy": "2025-01-29T02:42:10.718134Z",
     "iopub.status.idle": "2025-01-29T02:42:13.587027Z",
     "shell.execute_reply": "2025-01-29T02:42:13.586251Z",
     "shell.execute_reply.started": "2025-01-29T02:42:10.718464Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
      "* 'fields' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "genai.configure(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b96bfb0-a3f4-447e-a5d9-c7b75ab23f6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:57.152219Z",
     "iopub.status.busy": "2025-01-28T20:59:57.151832Z",
     "iopub.status.idle": "2025-01-28T20:59:57.158810Z",
     "shell.execute_reply": "2025-01-28T20:59:57.157196Z",
     "shell.execute_reply.started": "2025-01-28T20:59:57.152191Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"gemini-1.5-flash\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2be53e0a-e5b4-414d-beb7-b94bb9ee0078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:57.859923Z",
     "iopub.status.busy": "2025-01-28T20:59:57.859328Z",
     "iopub.status.idle": "2025-01-28T20:59:58.626254Z",
     "shell.execute_reply": "2025-01-28T20:59:58.624962Z",
     "shell.execute_reply.started": "2025-01-28T20:59:57.859897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e492321-bf28-46a9-9297-2db44bded706",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:59:58.630575Z",
     "iopub.status.busy": "2025-01-28T20:59:58.629294Z",
     "iopub.status.idle": "2025-01-28T20:59:59.552332Z",
     "shell.execute_reply": "2025-01-28T20:59:59.551195Z",
     "shell.execute_reply.started": "2025-01-28T20:59:58.630528Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/gemini\n",
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ea8bc-dc58-4fcb-af05-0960f696b203",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Check reproducibility in the case temperature=0.0 and top_p < 1.0\n",
    "In the case top_p = 1.0, I would still get some stochasticity, probably since temperature=0.0 is approximated algorithmically (using eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1d2e76f-6035-4fee-a34d-4d02035f93e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:37.955872Z",
     "iopub.status.busy": "2025-01-28T20:53:37.955465Z",
     "iopub.status.idle": "2025-01-28T20:53:38.837304Z",
     "shell.execute_reply": "2025-01-28T20:53:38.835959Z",
     "shell.execute_reply.started": "2025-01-28T20:53:37.955841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1c79a17-1e4a-45df-a65f-599da71c07b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:39.587496Z",
     "iopub.status.busy": "2025-01-28T20:53:39.587117Z",
     "iopub.status.idle": "2025-01-28T20:53:40.349271Z",
     "shell.execute_reply": "2025-01-28T20:53:40.347870Z",
     "shell.execute_reply.started": "2025-01-28T20:53:39.587468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name)\n",
    "response_g = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config = genai.GenerationConfig(**param)\n",
    ")\n",
    "response_g.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b7272d8-7d12-47f5-bc70-3bfc698766a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T20:53:40.941653Z",
     "iopub.status.busy": "2025-01-28T20:53:40.941148Z",
     "iopub.status.idle": "2025-01-28T20:53:41.791465Z",
     "shell.execute_reply": "2025-01-28T20:53:41.789924Z",
     "shell.execute_reply.started": "2025-01-28T20:53:40.941623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research company that develops and promotes friendly AI.  They create cutting-edge models like GPT, DALL-E, and others,  available through APIs and research publications, aiming to benefit humanity.  Their mission is to ensure that artificial general intelligence (AGI) benefits all of humankind.\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_l = completion(\n",
    "    model=f\"gemini/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a329a4-ae1f-4b97-8987-2712976bafb6",
   "metadata": {},
   "source": [
    "## Compare Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "47305b29-b45e-4181-b9b4-9581b878a088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:27.516968Z",
     "iopub.status.busy": "2025-01-28T21:00:27.516558Z",
     "iopub.status.idle": "2025-01-28T21:00:27.524554Z",
     "shell.execute_reply": "2025-01-28T21:00:27.523009Z",
     "shell.execute_reply.started": "2025-01-28T21:00:27.516939Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "param = {\"temperature\": 0.0, \"top_p\": 0.1}\n",
    "prompt = \"Describe OpenAI in a few sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a035767f-fe04-4414-8b5e-9933d86287f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:27.875371Z",
     "iopub.status.busy": "2025-01-28T21:00:27.875073Z",
     "iopub.status.idle": "2025-01-28T21:00:28.686141Z",
     "shell.execute_reply": "2025-01-28T21:00:28.684826Z",
     "shell.execute_reply.started": "2025-01-28T21:00:27.875346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI is a leading artificial intelligence research organization that aims to develop and promote friendly AI that benefits humanity. Founded in 2015, OpenAI is known for its cutting-edge AI models, including language models like GPT-3 and DALL-E, which have achieved state-of-the-art results in various AI tasks. The organization is committed to transparency, open-source development, and responsible AI practices, and its research and technologies have far-reaching implications for fields such as natural language processing, computer vision, and robotics.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt,}],\n",
    "    model=model_name,\n",
    "    **param\n",
    ")\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f18051be-6b7c-4d85-b11d-4b08fc78715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-28T21:00:28.688517Z",
     "iopub.status.busy": "2025-01-28T21:00:28.688096Z",
     "iopub.status.idle": "2025-01-28T21:00:29.556525Z",
     "shell.execute_reply": "2025-01-28T21:00:29.555822Z",
     "shell.execute_reply.started": "2025-01-28T21:00:28.688490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenAI is a leading artificial intelligence research organization that aims to develop and promote friendly AI that benefits humanity. Founded in 2015, OpenAI is known for its cutting-edge AI models, including language models like GPT-3 and DALL-E, which have achieved state-of-the-art results in various AI tasks. The organization is committed to transparency, open-source development, and responsible AI practices, and its research and technologies have far-reaching implications for fields such as natural language processing, computer vision, and robotics.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://docs.litellm.ai/docs/providers/groq\n",
    "response_l = completion(\n",
    "    model=f\"groq/{model_name}\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    **param\n",
    ")\n",
    "response_l['choices'][0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618955e-48ae-4f7c-8900-ca6d65fc79ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f87a7bf-e71d-43bb-bf78-1778ece36acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
